{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99fa1366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchcrf import CRF\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from torch_model_base import TorchModelBase\n",
    "from torch_rnn_classifier import TorchRNNDataset, TorchRNNClassifier, TorchRNNModel\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37f28abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('annotations2.jsonl') as jsonl_file:\n",
    "    # note: after running data-preprocessing.ipynb this file already has token-level labels\n",
    "    lines = jsonl_file.readlines()\n",
    "annot = [json.loads(line) for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "384cb2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get data into format that TorchRNN expects:\n",
    "X=[] \n",
    "y=[]\n",
    "for j in range(0,len(annot)):\n",
    "    a = annot[j]['tokens']\n",
    "    auxX = []\n",
    "    auxy = []\n",
    "    if annot[j]['spans']!=[]: # are there annot for this example?\n",
    "        for i in range(0,len(a)):\n",
    "            #token_element = (a[i]['text'],a[i]['label'])\n",
    "            auxX.append(a[i]['text'])\n",
    "            auxy.append(a[i]['label'])\n",
    "        X.append(auxX)\n",
    "        y.append(auxy)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "#X_train, X_test, y_train, y_test = X[:120], X[120:], y[:120], y[120:]\n",
    "vocab = sorted({w for seq in X for w in seq}) + [\"$UNK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b3410a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.75\n",
    "train_test_split = round(0.75*len(X) - 0.5) # -0.5 => floor\n",
    "idx = [i for i in range(0,len(X))]\n",
    "idx_shuffle = shuffle(idx,random_state=0)\n",
    "X_shuffle, y_shuffle = [X[auxIdx] for auxIdx in idx_shuffle], [y[auxIdx] for auxIdx in idx_shuffle]\n",
    "X_train, X_test, y_train, y_test = X_shuffle[:train_test_split], X_shuffle[train_test_split:], y_shuffle[:train_test_split], y_shuffle[train_test_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "008b403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload modules\n",
    "import torch_rnn_classifier, torch_model_base\n",
    "import importlib\n",
    "importlib.reload(torch_model_base)\n",
    "importlib.reload(torch_rnn_classifier)\n",
    "from torch_model_base import TorchModelBase\n",
    "from torch_rnn_classifier import TorchRNNClassifier, TorchRNNModel, TorchRNNDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afcb94f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchRNNSequenceLabeler(TorchRNNClassifier):\n",
    "\n",
    "    def build_graph(self):\n",
    "        rnn = TorchRNNModel(\n",
    "            vocab_size=len(self.vocab),\n",
    "            embedding=self.embedding,\n",
    "            use_embedding=self.use_embedding,\n",
    "            embed_dim=self.embed_dim,\n",
    "            rnn_cell_class=self.rnn_cell_class,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            bidirectional=self.bidirectional,\n",
    "            freeze_embedding=self.freeze_embedding)\n",
    "        model = TorchSequenceLabeler(\n",
    "            rnn=rnn,\n",
    "            output_dim=self.n_classes_)\n",
    "        self.embed_dim = rnn.embed_dim\n",
    "        return model\n",
    "\n",
    "    def build_dataset(self, X, y=None):\n",
    "        X, seq_lengths = self._prepare_sequences(X)\n",
    "        if y is None:\n",
    "            return TorchRNNDataset(X, seq_lengths)\n",
    "        else:\n",
    "            # These are the changes from a regular classifier. All\n",
    "            # concern the fact that our labels are sequences of labels.\n",
    "            self.classes_ = sorted({x for seq in y for x in seq})\n",
    "            self.n_classes_ = len(self.classes_)\n",
    "            class2index = dict(zip(self.classes_, range(self.n_classes_)))\n",
    "            # `y` is a list of tensors of different length. Our Dataset\n",
    "            # class will turn it into a padding tensor for processing.\n",
    "            y = [torch.tensor([class2index[label] for label in seq])\n",
    "                 for seq in y]\n",
    "            return TorchRNNDataset(X, seq_lengths, y)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        seq_lengths = [len(ex) for ex in X]\n",
    "        # The base class does the heavy lifting:\n",
    "        preds = self._predict(X)\n",
    "        # Trim to the actual sequence lengths:\n",
    "        preds = [p[: l] for p, l in zip(preds, seq_lengths)]\n",
    "        # Use `softmax`; the model doesn't do this because the loss\n",
    "        # function does it internally.\n",
    "        probs = [torch.softmax(seq, dim=1) for seq in preds]\n",
    "        return probs\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        return [[self.classes_[i] for i in seq.argmax(axis=1)] for seq in probs]\n",
    "\n",
    "    def score(self, X, y):\n",
    "        preds = self.predict(X)\n",
    "        flat_preds = [x for seq in preds for x in seq]\n",
    "        flat_y = [x for seq in y for x in seq]\n",
    "        return utils.safe_macro_f1(flat_y, flat_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22147492",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchSequenceLabeler(nn.Module):\n",
    "    def __init__(self, rnn, output_dim):\n",
    "        super().__init__()\n",
    "        self.rnn = rnn\n",
    "        self.output_dim = output_dim\n",
    "        if self.rnn.bidirectional:\n",
    "            self.classifier_dim = self.rnn.hidden_dim * 2\n",
    "        else:\n",
    "            self.classifier_dim = self.rnn.hidden_dim\n",
    "        self.classifier_layer = nn.Linear(\n",
    "            self.classifier_dim, self.output_dim)\n",
    "\n",
    "    def forward(self, X, seq_lengths):\n",
    "        outputs, state = self.rnn(X, seq_lengths)\n",
    "        outputs, seq_length = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "            outputs, batch_first=True)\n",
    "        logits = self.classifier_layer(outputs)\n",
    "        # During training, we need to swap the dimensions of logits\n",
    "        # to accommodate `nn.CrossEntropyLoss`:\n",
    "        if self.training:\n",
    "            return logits.transpose(1, 2)\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af30259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_mod = TorchRNNSequenceLabeler(\n",
    "    vocab,\n",
    "    early_stopping=True,\n",
    "    eta=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "176d21f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 25. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 2.1324784755706787"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.43 s\n"
     ]
    }
   ],
   "source": [
    "%time _ = seq_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c60724b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = seq_mod.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4b962dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6224368103752443\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "DATUM_VERBUECHERUNG      0.133     0.273     0.179        55\n",
      "      DATUM_VERTRAG      0.000     0.000     0.000        62\n",
      "            FLAECHE      0.000     0.000     0.000        38\n",
      "        GESAMTPREIS      0.000     0.000     0.000        29\n",
      "           IMMO_TYP      0.105     0.298     0.156        47\n",
      "            KAEUFER      0.000     0.000     0.000        33\n",
      "                  O      0.859     0.722     0.784      1525\n",
      "                ORT      0.159     0.576     0.249        59\n",
      "            QMPREIS      0.012     0.048     0.020        21\n",
      "            STRASSE      0.086     0.273     0.130        44\n",
      "   TERRASSENGROESSE      0.000     0.000     0.000         8\n",
      "         VERKAEUFER      0.000     0.000     0.000        62\n",
      "\n",
      "           accuracy                          0.594      1983\n",
      "          macro avg      0.113     0.182     0.126      1983\n",
      "       weighted avg      0.673     0.594     0.622      1983\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasco\\anaconda3\\envs\\xcs224u\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass labels=['DATUM_VERBUECHERUNG', 'DATUM_VERTRAG', 'FLAECHE', 'GESAMTPREIS', 'IMMO_TYP', 'KAEUFER', 'O', 'ORT', 'QMPREIS', 'STRASSE', 'TERRASSENGROESSE', 'VERKAEUFER'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "C:\\Users\\vasco\\anaconda3\\envs\\xcs224u\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "labels = sorted({aux_y for seq in y for aux_y in seq})\n",
    "print(metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels))\n",
    "#sorted_labels = sorted(\n",
    "#    classes,\n",
    "#    key=lambda name: (name[1:], name[0])\n",
    "#)\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels, digits=3\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46bc54ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T14:09:14.437937Z",
     "start_time": "2022-04-05T14:09:14.435854Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.metrics import classification_report, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#from torch_model_base import TorchModelBase\n",
    "#from torch_shallow_neural_classifier import TorchShallowNeuralClassifier\n",
    "from torch_rnn_classifier import TorchRNNDataset, TorchRNNClassifier, TorchRNNModel\n",
    "import utils\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df4daa5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T14:09:15.484474Z",
     "start_time": "2022-04-05T14:09:15.482134Z"
    }
   },
   "outputs": [],
   "source": [
    "# refresh torch rnn classifier:\n",
    "import importlib\n",
    "import torch_rnn_classifier\n",
    "importlib.reload(torch_rnn_classifier)\n",
    "from torch_rnn_classifier import TorchRNNDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c519f11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T14:09:16.709996Z",
     "start_time": "2022-04-05T14:09:16.708344Z"
    }
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebc5fbf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T14:09:17.642169Z",
     "start_time": "2022-04-05T14:09:17.631218Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('annotations2.jsonl') as jsonl_file:\n",
    "    # note: after running data-preprocessing.ipynb this file already has token-level labels\n",
    "    lines = jsonl_file.readlines()\n",
    "annot = [json.loads(line) for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62fbb470",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T14:09:19.716289Z",
     "start_time": "2022-04-05T14:09:19.711785Z"
    }
   },
   "outputs": [],
   "source": [
    "# now get data into format that TorchRNN expects:\n",
    "X=[] \n",
    "y=[]\n",
    "for j in range(0,len(annot)):\n",
    "    a = annot[j]['tokens']\n",
    "    auxX = []\n",
    "    auxy = []\n",
    "    if annot[j]['spans']!=[]: # are there annot for this example?\n",
    "        for i in range(0,len(a)):\n",
    "            #token_element = (a[i]['text'],a[i]['label'])\n",
    "            auxX.append(a[i]['text'])\n",
    "            auxy.append(a[i]['label'])\n",
    "        X.append(auxX)\n",
    "        y.append(auxy)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_train, X_test, y_train, y_test = X[:120], X[120:], y[:120], y[120:]\n",
    "vocab = sorted({w for seq in X_train for w in seq}) + [\"$UNK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8b5c9ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T14:09:21.200245Z",
     "start_time": "2022-04-05T14:09:21.197753Z"
    }
   },
   "outputs": [],
   "source": [
    "# reload vsm module\n",
    "import torch_rnn_classifier, torch_model_base\n",
    "import importlib\n",
    "importlib.reload(torch_model_base)\n",
    "importlib.reload(torch_rnn_classifier)\n",
    "from torch_model_base import TorchModelBase\n",
    "from torch_rnn_classifier import TorchRNNClassifier, TorchRNNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a33711db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T14:09:42.614144Z",
     "start_time": "2022-04-05T14:09:42.607537Z"
    }
   },
   "outputs": [],
   "source": [
    "class TorchRNNSequenceLabeler(TorchRNNClassifier):\n",
    "\n",
    "    def build_graph(self): # uses this build_graph instead of TorchRNNClassifier.build_graph\n",
    "        print(\"here0\")\n",
    "        rnn = TorchRNNModel(\n",
    "            vocab_size=len(self.vocab),\n",
    "            embedding=self.embedding,\n",
    "            use_embedding=self.use_embedding,\n",
    "            embed_dim=self.embed_dim,\n",
    "            rnn_cell_class=self.rnn_cell_class,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            bidirectional=self.bidirectional,\n",
    "            freeze_embedding=self.freeze_embedding)\n",
    "        print(\"here02\")\n",
    "        model = TorchSequenceLabeler( # this defines self.model\n",
    "            rnn=rnn,\n",
    "            output_dim=self.n_classes_)\n",
    "        self.embed_dim = rnn.embed_dim\n",
    "        return model\n",
    "\n",
    "    def build_dataset(self, X, y=None):\n",
    "        START_TAG = \"<START>\"\n",
    "        STOP_TAG = \"<STOP>\"\n",
    "        X, seq_lengths = self._prepare_sequences(X) # converts tokens into tokenIds\n",
    "        if y is None:\n",
    "            return TorchRNNDataset(X, seq_lengths)\n",
    "        else:\n",
    "            # These are the changes from a regular classifier. All\n",
    "            # concern the fact that our labels are sequences of labels.\n",
    "            self.classes_ = sorted({x for seq in y for x in seq})\n",
    "            self.classes_.append(START_TAG) # add start and stop tags\n",
    "            self.classes_.append(STOP_TAG)\n",
    "            self.n_classes_ = len(self.classes_)\n",
    "            class2index = dict(zip(self.classes_, range(self.n_classes_)))\n",
    "            # `y` is a list of tensors of different length. Our Dataset\n",
    "            # class will turn it into a padding tensor for processing.\n",
    "            y = [torch.tensor([class2index[label] for label in seq])\n",
    "                 for seq in y] # converts labels to indices\n",
    "            return TorchRNNDataset(X, seq_lengths, y)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        seq_lengths = [len(ex) for ex in X]\n",
    "        # The base class does the heavy lifting:\n",
    "        preds = self._predict(X)\n",
    "        # Trim to the actual sequence lengths:\n",
    "        preds = [p[: l] for p, l in zip(preds, seq_lengths)]\n",
    "        # Use `softmax`; the model doesn't do this because the loss\n",
    "        # function does it internally.\n",
    "        probs = [torch.softmax(seq, dim=1) for seq in preds]\n",
    "        return probs\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        return [[self.classes_[i] for i in seq.argmax(axis=1)] for seq in probs] # seq.argmax(axis=1) gives index of col that maximizes softmax prob\n",
    "        # see difference vs TorchRNNClassifier.predict\n",
    "\n",
    "    def score(self, X, y):\n",
    "        preds = self.predict(X)\n",
    "        flat_preds = [x for seq in preds for x in seq]\n",
    "        flat_y = [x for seq in y for x in seq]\n",
    "        return utils.safe_macro_f1(flat_y, flat_preds)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "class TorchSequenceLabeler(nn.Module): # no self.hidden_layer or self.classifier_activation as TorchRNNClassifierModel\n",
    "    def __init__(self, rnn, output_dim):\n",
    "        print(\"here021\")\n",
    "        super().__init__()\n",
    "        self.rnn = rnn\n",
    "        self.output_dim = output_dim\n",
    "        if self.rnn.bidirectional:\n",
    "            self.classifier_dim = self.rnn.hidden_dim * 2\n",
    "        else:\n",
    "            self.classifier_dim = self.rnn.hidden_dim\n",
    "        self.classifier_layer = nn.Linear(\n",
    "            self.classifier_dim, self.output_dim)\n",
    "\n",
    "    def forward(self, X, seq_lengths): # X is (noExsInBatch,MaxLen)=(108,117), seq_lengths is the number of tokens in each example in each batch\n",
    "        # this is the forward method of self.model\n",
    "        print(\"here2\")\n",
    "        outputs, state = self.rnn(X, seq_lengths) # X is (batchSize, maxLen of exs in batch); outputs is (noTokensInEx,hiddDim), state is ((batch_size,1,hiddDim),(batch_size,1,hiddDim)) = (finalHiddState,finalCellState) \n",
    "        #print(outputs.data.shape)\n",
    "        #print(state[0].data.shape)\n",
    "        #print(state[1].data.shape)\n",
    "        outputs, seq_length = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "            outputs, batch_first=True) # outputs is (batchSize,MaxLen of examples in batch,hidden_dim); seq_length is noTokenInEx for each ex in batch\n",
    "        #print(outputs.data.shape)\n",
    "        #print(seq_length)\n",
    "        logits = self.classifier_layer(outputs) # this is an FCL from hidden_dim to output_dim (NoLabelClasses)\n",
    "        # logits are (108,117,12) or (1,11,5) = (batchSize,MaxLen of examples in batch,noLabelClasses) noLabelClasses include Start + End\n",
    "        # During training, we need to swap the dimensions of logits\n",
    "        # to accommodate `nn.CrossEntropyLoss`:\n",
    "        print(logits)\n",
    "        if self.training:\n",
    "            return logits.transpose(1, 2) # transpose dimensions 1 and 2 w/ each other (3d array) # outputs (108,12,117) or (1,5,11)\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe4012cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T14:09:44.647289Z",
     "start_time": "2022-04-05T14:09:44.607881Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_mod = TorchRNNSequenceLabeler(\n",
    "    vocab,\n",
    "    early_stopping=True,\n",
    "    eta=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fbfe505",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T14:09:50.797119Z",
     "start_time": "2022-04-05T14:09:50.795189Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = [\"the wall street journal reported today that apple corporation made money\".split(),\"georgia tech is a university in georgia\".split()]\n",
    "y_train = [\"B I I I O O O B I O O\".split(),\"B I O O O O B\".split()]\n",
    "vocab = sorted({w for seq in X_train for w in seq}) + [\"$UNK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66a47009",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T14:19:33.091561Z",
     "start_time": "2022-04-05T14:19:33.087437Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wall</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>street</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>journal</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reported</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>today</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>that</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>apple</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>corporation</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>made</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>money</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              X  y\n",
       "0           the  B\n",
       "1          wall  I\n",
       "2        street  I\n",
       "3       journal  I\n",
       "4      reported  O\n",
       "5         today  O\n",
       "6          that  O\n",
       "7         apple  B\n",
       "8   corporation  I\n",
       "9          made  O\n",
       "10        money  O"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(X_train[0], y_train[0])), columns=[\"X\", \"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8f210b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T14:20:45.492367Z",
     "start_time": "2022-04-05T14:20:45.342841Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 20. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 1.0853766202926636"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here00\n",
      "here0\n",
      "here01\n",
      "here02\n",
      "here021\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0468,  0.1913, -0.0816, -0.0243, -0.0453],\n",
      "         [-0.0522,  0.1927, -0.1355, -0.0581, -0.0249],\n",
      "         [-0.0612,  0.1893, -0.1723, -0.0763, -0.0242],\n",
      "         [-0.0678,  0.1864, -0.1940, -0.0844, -0.0285],\n",
      "         [-0.0721,  0.1843, -0.2059, -0.0873, -0.0331],\n",
      "         [-0.0746,  0.1827, -0.2124, -0.0880, -0.0368],\n",
      "         [-0.0761,  0.1816, -0.2160, -0.0877, -0.0395],\n",
      "         [-0.0770,  0.1808, -0.2178, -0.0872, -0.0414],\n",
      "         [-0.0776,  0.1801, -0.2187, -0.0867, -0.0427],\n",
      "         [-0.0779,  0.1796, -0.2192, -0.0862, -0.0435],\n",
      "         [-0.0782,  0.1794, -0.2195, -0.0859, -0.0440]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0490,  0.2121, -0.0366, -0.0381, -0.0686],\n",
      "         [-0.0529,  0.2263, -0.0614, -0.0797, -0.0595],\n",
      "         [-0.0598,  0.2306, -0.0799, -0.1025, -0.0643],\n",
      "         [-0.0649,  0.2325, -0.0902, -0.1135, -0.0713],\n",
      "         [-0.0680,  0.2335, -0.0953, -0.1182, -0.0773],\n",
      "         [-0.0572,  0.2272, -0.0479, -0.0082, -0.1971],\n",
      "         [-0.0712,  0.2532, -0.0274, -0.0623, -0.1187]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0490,  0.2121, -0.0366, -0.0381, -0.0686],\n",
      "         [-0.0529,  0.2263, -0.0614, -0.0797, -0.0595],\n",
      "         [-0.0598,  0.2306, -0.0799, -0.1025, -0.0643],\n",
      "         [-0.0649,  0.2325, -0.0902, -0.1135, -0.0713],\n",
      "         [-0.0680,  0.2335, -0.0953, -0.1182, -0.0773],\n",
      "         [-0.0699,  0.2339, -0.0975, -0.1200, -0.0818],\n",
      "         [-0.0709,  0.2341, -0.0984, -0.1205, -0.0849],\n",
      "         [-0.0716,  0.2342, -0.0986, -0.1205, -0.0871],\n",
      "         [-0.0721,  0.2341, -0.0984, -0.1204, -0.0885],\n",
      "         [-0.0723,  0.2341, -0.0982, -0.1201, -0.0895],\n",
      "         [-0.0724,  0.2341, -0.0981, -0.1199, -0.0901]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0514,  0.2332,  0.0073, -0.0526, -0.0919],\n",
      "         [-0.0539,  0.2602,  0.0108, -0.1020, -0.0942],\n",
      "         [-0.0587,  0.2724,  0.0102, -0.1292, -0.1044],\n",
      "         [-0.0622,  0.2792,  0.0109, -0.1430, -0.1141],\n",
      "         [-0.0643,  0.2832,  0.0127, -0.1495, -0.1214],\n",
      "         [-0.0518,  0.2512,  0.0173, -0.0325, -0.2168],\n",
      "         [-0.0706,  0.2906,  0.0577, -0.0876, -0.1546]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0514,  0.2332,  0.0073, -0.0526, -0.0919],\n",
      "         [-0.0539,  0.2602,  0.0108, -0.1020, -0.0942],\n",
      "         [-0.0587,  0.2724,  0.0102, -0.1292, -0.1044],\n",
      "         [-0.0622,  0.2792,  0.0109, -0.1430, -0.1141],\n",
      "         [-0.0643,  0.2832,  0.0127, -0.1495, -0.1214],\n",
      "         [-0.0654,  0.2856,  0.0146, -0.1524, -0.1266],\n",
      "         [-0.0661,  0.2871,  0.0163, -0.1537, -0.1300],\n",
      "         [-0.0664,  0.2879,  0.0178, -0.1541, -0.1324],\n",
      "         [-0.0667,  0.2884,  0.0189, -0.1542, -0.1340],\n",
      "         [-0.0668,  0.2888,  0.0197, -0.1542, -0.1351],\n",
      "         [-0.0669,  0.2890,  0.0204, -0.1542, -0.1358]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0538,  0.2549,  0.0500, -0.0673, -0.1159],\n",
      "         [-0.0546,  0.2951,  0.0812, -0.1246, -0.1300],\n",
      "         [-0.0573,  0.3152,  0.0980, -0.1561, -0.1460],\n",
      "         [-0.0591,  0.3267,  0.1096, -0.1723, -0.1585],\n",
      "         [-0.0600,  0.3337,  0.1180, -0.1804, -0.1672],\n",
      "         [-0.0463,  0.2755,  0.0810, -0.0569, -0.2371],\n",
      "         [-0.0695,  0.3295,  0.1410, -0.1129, -0.1917]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0538,  0.2549,  0.0500, -0.0673, -0.1159],\n",
      "         [-0.0546,  0.2951,  0.0812, -0.1246, -0.1300],\n",
      "         [-0.0573,  0.3152,  0.0980, -0.1561, -0.1460],\n",
      "         [-0.0591,  0.3267,  0.1096, -0.1723, -0.1585],\n",
      "         [-0.0600,  0.3337,  0.1180, -0.1804, -0.1672],\n",
      "         [-0.0604,  0.3381,  0.1240, -0.1844, -0.1730],\n",
      "         [-0.0605,  0.3407,  0.1283, -0.1863, -0.1769],\n",
      "         [-0.0606,  0.3423,  0.1312, -0.1872, -0.1794],\n",
      "         [-0.0607,  0.3433,  0.1333, -0.1876, -0.1812],\n",
      "         [-0.0608,  0.3440,  0.1347, -0.1879, -0.1824],\n",
      "         [-0.0607,  0.3444,  0.1356, -0.1879, -0.1831]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0563,  0.2771,  0.0917, -0.0825, -0.1407],\n",
      "         [-0.0554,  0.3307,  0.1501, -0.1477, -0.1672],\n",
      "         [-0.0557,  0.3586,  0.1841, -0.1834, -0.1892],\n",
      "         [-0.0557,  0.3749,  0.2062, -0.2020, -0.2046],\n",
      "         [-0.0553,  0.3847,  0.2210, -0.2115, -0.2147],\n",
      "         [-0.0404,  0.3001,  0.1435, -0.0818, -0.2583],\n",
      "         [-0.0680,  0.3695,  0.2230, -0.1390, -0.2300]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0563,  0.2771,  0.0917, -0.0825, -0.1407],\n",
      "         [-0.0554,  0.3307,  0.1501, -0.1477, -0.1672],\n",
      "         [-0.0557,  0.3586,  0.1841, -0.1834, -0.1892],\n",
      "         [-0.0557,  0.3749,  0.2062, -0.2020, -0.2046],\n",
      "         [-0.0553,  0.3847,  0.2210, -0.2115, -0.2147],\n",
      "         [-0.0549,  0.3907,  0.2309, -0.2165, -0.2213],\n",
      "         [-0.0546,  0.3944,  0.2376, -0.2191, -0.2255],\n",
      "         [-0.0544,  0.3968,  0.2419, -0.2205, -0.2283],\n",
      "         [-0.0542,  0.3983,  0.2449, -0.2212, -0.2300],\n",
      "         [-0.0542,  0.3992,  0.2469, -0.2216, -0.2313],\n",
      "         [-0.0541,  0.3998,  0.2482, -0.2219, -0.2321]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0587,  0.2997,  0.1326, -0.0980, -0.1658],\n",
      "         [-0.0558,  0.3668,  0.2179, -0.1713, -0.2051],\n",
      "         [-0.0538,  0.4025,  0.2688, -0.2112, -0.2334],\n",
      "         [-0.0518,  0.4232,  0.3012, -0.2321, -0.2517],\n",
      "         [-0.0502,  0.4356,  0.3221, -0.2430, -0.2632],\n",
      "         [-0.0342,  0.3249,  0.2054, -0.1071, -0.2799],\n",
      "         [-0.0659,  0.4103,  0.3042, -0.1657, -0.2689]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0587,  0.2997,  0.1326, -0.0980, -0.1658],\n",
      "         [-0.0558,  0.3668,  0.2179, -0.1713, -0.2051],\n",
      "         [-0.0538,  0.4025,  0.2688, -0.2112, -0.2334],\n",
      "         [-0.0518,  0.4232,  0.3012, -0.2321, -0.2517],\n",
      "         [-0.0502,  0.4356,  0.3221, -0.2430, -0.2632],\n",
      "         [-0.0490,  0.4432,  0.3358, -0.2488, -0.2704],\n",
      "         [-0.0481,  0.4479,  0.3447, -0.2519, -0.2749],\n",
      "         [-0.0476,  0.4508,  0.3505, -0.2538, -0.2778],\n",
      "         [-0.0473,  0.4526,  0.3542, -0.2548, -0.2796],\n",
      "         [-0.0471,  0.4538,  0.3567, -0.2554, -0.2808],\n",
      "         [-0.0470,  0.4545,  0.3583, -0.2558, -0.2817]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0608,  0.3228,  0.1732, -0.1139, -0.1912],\n",
      "         [-0.0561,  0.4034,  0.2853, -0.1955, -0.2435],\n",
      "         [-0.0516,  0.4467,  0.3528, -0.2397, -0.2781],\n",
      "         [-0.0478,  0.4714,  0.3952, -0.2629, -0.2994],\n",
      "         [-0.0449,  0.4862,  0.4221, -0.2752, -0.3121],\n",
      "         [-0.0275,  0.3499,  0.2674, -0.1334, -0.3020],\n",
      "         [-0.0635,  0.4518,  0.3853, -0.1935, -0.3083]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0608,  0.3228,  0.1732, -0.1139, -0.1912],\n",
      "         [-0.0561,  0.4034,  0.2853, -0.1955, -0.2435],\n",
      "         [-0.0516,  0.4467,  0.3528, -0.2397, -0.2781],\n",
      "         [-0.0478,  0.4714,  0.3952, -0.2629, -0.2994],\n",
      "         [-0.0449,  0.4862,  0.4221, -0.2752, -0.3121],\n",
      "         [-0.0428,  0.4951,  0.4392, -0.2818, -0.3198],\n",
      "         [-0.0414,  0.5006,  0.4503, -0.2855, -0.3244],\n",
      "         [-0.0406,  0.5040,  0.4573, -0.2877, -0.3274],\n",
      "         [-0.0401,  0.5062,  0.4619, -0.2890, -0.3294],\n",
      "         [-0.0398,  0.5075,  0.4648, -0.2899, -0.3305],\n",
      "         [-0.0397,  0.5084,  0.4668, -0.2903, -0.3314]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0626,  0.3461,  0.2131, -0.1304, -0.2168],\n",
      "         [-0.0560,  0.4402,  0.3521, -0.2207, -0.2824],\n",
      "         [-0.0492,  0.4906,  0.4361, -0.2693, -0.3234],\n",
      "         [-0.0434,  0.5191,  0.4883, -0.2949, -0.3475],\n",
      "         [-0.0392,  0.5357,  0.5208, -0.3085, -0.3613],\n",
      "         [-0.0203,  0.3748,  0.3299, -0.1609, -0.3246],\n",
      "         [-0.0605,  0.4935,  0.4665, -0.2230, -0.3483]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0626,  0.3461,  0.2131, -0.1304, -0.2168],\n",
      "         [-0.0560,  0.4402,  0.3521, -0.2207, -0.2824],\n",
      "         [-0.0492,  0.4906,  0.4361, -0.2693, -0.3234],\n",
      "         [-0.0434,  0.5191,  0.4883, -0.2949, -0.3475],\n",
      "         [-0.0392,  0.5357,  0.5208, -0.3085, -0.3613],\n",
      "         [-0.0363,  0.5458,  0.5413, -0.3160, -0.3694],\n",
      "         [-0.0346,  0.5519,  0.5543, -0.3203, -0.3741],\n",
      "         [-0.0334,  0.5557,  0.5625, -0.3228, -0.3770],\n",
      "         [-0.0327,  0.5581,  0.5678, -0.3244, -0.3788],\n",
      "         [-0.0322,  0.5595,  0.5712, -0.3254, -0.3800],\n",
      "         [-0.0320,  0.5605,  0.5734, -0.3260, -0.3808]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0642,  0.3696,  0.2532, -0.1474, -0.2423],\n",
      "         [-0.0557,  0.4771,  0.4191, -0.2468, -0.3214],\n",
      "         [-0.0465,  0.5341,  0.5196, -0.3001, -0.3687],\n",
      "         [-0.0389,  0.5658,  0.5813, -0.3281, -0.3953],\n",
      "         [-0.0334,  0.5841,  0.6194, -0.3431, -0.4101],\n",
      "         [-0.0125,  0.3995,  0.3939, -0.1898, -0.3475],\n",
      "         [-0.0570,  0.5351,  0.5488, -0.2543, -0.3884]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0642,  0.3696,  0.2532, -0.1474, -0.2423],\n",
      "         [-0.0557,  0.4771,  0.4191, -0.2468, -0.3214],\n",
      "         [-0.0465,  0.5341,  0.5196, -0.3001, -0.3687],\n",
      "         [-0.0389,  0.5658,  0.5813, -0.3281, -0.3953],\n",
      "         [-0.0334,  0.5841,  0.6194, -0.3431, -0.4101],\n",
      "         [-0.0298,  0.5949,  0.6430, -0.3514, -0.4185],\n",
      "         [-0.0275,  0.6014,  0.6577, -0.3562, -0.4232],\n",
      "         [-0.0260,  0.6054,  0.6672, -0.3591, -0.4260],\n",
      "         [-0.0251,  0.6079,  0.6732, -0.3609, -0.4277],\n",
      "         [-0.0245,  0.6094,  0.6771, -0.3621, -0.4288],\n",
      "         [-0.0242,  0.6105,  0.6795, -0.3629, -0.4295]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0659,  0.3932,  0.2928, -0.1650, -0.2679],\n",
      "         [-0.0556,  0.5139,  0.4859, -0.2739, -0.3605],\n",
      "         [-0.0442,  0.5771,  0.6029, -0.3321, -0.4140],\n",
      "         [-0.0348,  0.6114,  0.6739, -0.3627, -0.4431],\n",
      "         [-0.0282,  0.6308,  0.7172, -0.3790, -0.4588],\n",
      "         [-0.0044,  0.4237,  0.4591, -0.2200, -0.3708],\n",
      "         [-0.0536,  0.5764,  0.6318, -0.2874, -0.4287]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0659,  0.3932,  0.2928, -0.1650, -0.2679],\n",
      "         [-0.0556,  0.5139,  0.4859, -0.2739, -0.3605],\n",
      "         [-0.0442,  0.5771,  0.6029, -0.3321, -0.4140],\n",
      "         [-0.0348,  0.6114,  0.6739, -0.3627, -0.4431],\n",
      "         [-0.0282,  0.6308,  0.7172, -0.3790, -0.4588],\n",
      "         [-0.0238,  0.6421,  0.7438, -0.3881, -0.4673],\n",
      "         [-0.0210,  0.6489,  0.7605, -0.3933, -0.4721],\n",
      "         [-0.0191,  0.6529,  0.7710, -0.3967, -0.4747],\n",
      "         [-0.0181,  0.6556,  0.7776, -0.3987, -0.4763],\n",
      "         [-0.0174,  0.6571,  0.7818, -0.4000, -0.4772],\n",
      "         [-0.0170,  0.6581,  0.7847, -0.4009, -0.4779]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0672,  0.4171,  0.3321, -0.1832, -0.2934],\n",
      "         [-0.0554,  0.5508,  0.5526, -0.3022, -0.3998],\n",
      "         [-0.0418,  0.6197,  0.6859, -0.3655, -0.4594],\n",
      "         [-0.0308,  0.6563,  0.7661, -0.3986, -0.4909],\n",
      "         [-0.0231,  0.6764,  0.8144, -0.4163, -0.5074],\n",
      "         [ 0.0041,  0.4479,  0.5262, -0.2517, -0.3947],\n",
      "         [-0.0498,  0.6176,  0.7161, -0.3224, -0.4694]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0672,  0.4171,  0.3321, -0.1832, -0.2934],\n",
      "         [-0.0554,  0.5508,  0.5526, -0.3022, -0.3998],\n",
      "         [-0.0418,  0.6197,  0.6859, -0.3655, -0.4594],\n",
      "         [-0.0308,  0.6563,  0.7661, -0.3986, -0.4909],\n",
      "         [-0.0231,  0.6764,  0.8144, -0.4163, -0.5074],\n",
      "         [-0.0182,  0.6878,  0.8439, -0.4261, -0.5162],\n",
      "         [-0.0148,  0.6946,  0.8623, -0.4320, -0.5208],\n",
      "         [-0.0128,  0.6987,  0.8738, -0.4354, -0.5234],\n",
      "         [-0.0115,  0.7011,  0.8811, -0.4376, -0.5247],\n",
      "         [-0.0106,  0.7027,  0.8858, -0.4390, -0.5256],\n",
      "         [-0.0101,  0.7037,  0.8889, -0.4401, -0.5262]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0689,  0.4416,  0.3707, -0.2020, -0.3191],\n",
      "         [-0.0558,  0.5882,  0.6187, -0.3313, -0.4394],\n",
      "         [-0.0403,  0.6623,  0.7684, -0.4001, -0.5054],\n",
      "         [-0.0278,  0.7007,  0.8575, -0.4358, -0.5393],\n",
      "         [-0.0192,  0.7210,  0.9107, -0.4547, -0.5565],\n",
      "         [ 0.0123,  0.4724,  0.5950, -0.2848, -0.4196],\n",
      "         [-0.0466,  0.6587,  0.8011, -0.3592, -0.5111]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0689,  0.4416,  0.3707, -0.2020, -0.3191],\n",
      "         [-0.0558,  0.5882,  0.6187, -0.3313, -0.4394],\n",
      "         [-0.0403,  0.6623,  0.7684, -0.4001, -0.5054],\n",
      "         [-0.0278,  0.7007,  0.8575, -0.4358, -0.5393],\n",
      "         [-0.0192,  0.7210,  0.9107, -0.4547, -0.5565],\n",
      "         [-0.0134,  0.7325,  0.9431, -0.4653, -0.5653],\n",
      "         [-0.0097,  0.7391,  0.9632, -0.4713, -0.5700],\n",
      "         [-0.0073,  0.7430,  0.9757, -0.4750, -0.5724],\n",
      "         [-0.0059,  0.7453,  0.9837, -0.4775, -0.5737],\n",
      "         [-0.0050,  0.7467,  0.9888, -0.4790, -0.5743],\n",
      "         [-0.0043,  0.7476,  0.9922, -0.4799, -0.5747]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0707,  0.4667,  0.4085, -0.2213, -0.3447],\n",
      "         [-0.0565,  0.6266,  0.6839, -0.3615, -0.4793],\n",
      "         [-0.0392,  0.7056,  0.8498, -0.4358, -0.5515],\n",
      "         [-0.0254,  0.7449,  0.9478, -0.4743, -0.5877],\n",
      "         [-0.0157,  0.7656,  1.0059, -0.4944, -0.6058],\n",
      "         [ 0.0204,  0.4974,  0.6654, -0.3191, -0.4454],\n",
      "         [-0.0433,  0.7004,  0.8869, -0.3979, -0.5532]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-7.0687e-02,  4.6669e-01,  4.0847e-01, -2.2128e-01, -3.4471e-01],\n",
      "         [-5.6457e-02,  6.2655e-01,  6.8388e-01, -3.6155e-01, -4.7926e-01],\n",
      "         [-3.9155e-02,  7.0561e-01,  8.4985e-01, -4.3584e-01, -5.5154e-01],\n",
      "         [-2.5418e-02,  7.4492e-01,  9.4776e-01, -4.7429e-01, -5.8768e-01],\n",
      "         [-1.5720e-02,  7.6558e-01,  1.0059e+00, -4.9442e-01, -6.0580e-01],\n",
      "         [-9.3360e-03,  7.7663e-01,  1.0411e+00, -5.0557e-01, -6.1481e-01],\n",
      "         [-5.3677e-03,  7.8272e-01,  1.0627e+00, -5.1199e-01, -6.1935e-01],\n",
      "         [-2.7636e-03,  7.8617e-01,  1.0763e+00, -5.1577e-01, -6.2163e-01],\n",
      "         [-1.1616e-03,  7.8817e-01,  1.0849e+00, -5.1826e-01, -6.2276e-01],\n",
      "         [-4.9591e-05,  7.8947e-01,  1.0907e+00, -5.1998e-01, -6.2325e-01],\n",
      "         [ 7.5206e-04,  7.9034e-01,  1.0944e+00, -5.2101e-01, -6.2352e-01]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0723,  0.4929,  0.4450, -0.2408, -0.3706],\n",
      "         [-0.0571,  0.6662,  0.7478, -0.3923, -0.5200],\n",
      "         [-0.0380,  0.7498,  0.9299, -0.4723, -0.5986],\n",
      "         [-0.0227,  0.7899,  1.0366, -0.5133, -0.6372],\n",
      "         [-0.0120,  0.8100,  1.0996, -0.5347, -0.6560],\n",
      "         [ 0.0286,  0.5233,  0.7372, -0.3543, -0.4728],\n",
      "         [-0.0397,  0.7424,  0.9730, -0.4378, -0.5967]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-7.2265e-02,  4.9290e-01,  4.4503e-01, -2.4076e-01, -3.7055e-01],\n",
      "         [-5.7062e-02,  6.6621e-01,  7.4781e-01, -3.9230e-01, -5.1997e-01],\n",
      "         [-3.7977e-02,  7.4976e-01,  9.2992e-01, -4.7226e-01, -5.9861e-01],\n",
      "         [-2.2677e-02,  7.8994e-01,  1.0366e+00, -5.1331e-01, -6.3717e-01],\n",
      "         [-1.1975e-02,  8.0996e-01,  1.0996e+00, -5.3468e-01, -6.5598e-01],\n",
      "         [-5.1482e-03,  8.2036e-01,  1.1374e+00, -5.4635e-01, -6.6510e-01],\n",
      "         [-6.6698e-04,  8.2605e-01,  1.1608e+00, -5.5297e-01, -6.6966e-01],\n",
      "         [ 2.3931e-03,  8.2876e-01,  1.1754e+00, -5.5693e-01, -6.7164e-01],\n",
      "         [ 4.1708e-03,  8.3040e-01,  1.1848e+00, -5.5950e-01, -6.7267e-01],\n",
      "         [ 5.5155e-03,  8.3137e-01,  1.1910e+00, -5.6106e-01, -6.7300e-01],\n",
      "         [ 6.2017e-03,  8.3197e-01,  1.1951e+00, -5.6233e-01, -6.7324e-01]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0731,  0.5201,  0.4801, -0.2605, -0.3964],\n",
      "         [-0.0568,  0.7073,  0.8098, -0.4237, -0.5608],\n",
      "         [-0.0358,  0.7948,  1.0081, -0.5095, -0.6459],\n",
      "         [-0.0189,  0.8353,  1.1236, -0.5533, -0.6868],\n",
      "         [-0.0073,  0.8544,  1.1914, -0.5758, -0.7063],\n",
      "         [ 0.0376,  0.5498,  0.8102, -0.3901, -0.5015],\n",
      "         [-0.0344,  0.7849,  1.0594, -0.4789, -0.6409]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-7.3147e-02,  5.2012e-01,  4.8008e-01, -2.6048e-01, -3.9639e-01],\n",
      "         [-5.6846e-02,  7.0727e-01,  8.0982e-01, -4.2366e-01, -5.6078e-01],\n",
      "         [-3.5771e-02,  7.9480e-01,  1.0081e+00, -5.0949e-01, -6.4587e-01],\n",
      "         [-1.8875e-02,  8.3530e-01,  1.1236e+00, -5.5325e-01, -6.8676e-01],\n",
      "         [-7.2634e-03,  8.5444e-01,  1.1914e+00, -5.7581e-01, -7.0632e-01],\n",
      "         [ 5.9749e-04,  8.6386e-01,  1.2321e+00, -5.8803e-01, -7.1563e-01],\n",
      "         [ 5.6511e-03,  8.6827e-01,  1.2570e+00, -5.9469e-01, -7.1992e-01],\n",
      "         [ 8.9775e-03,  8.7063e-01,  1.2729e+00, -5.9886e-01, -7.2183e-01],\n",
      "         [ 1.1061e-02,  8.7178e-01,  1.2831e+00, -6.0139e-01, -7.2280e-01],\n",
      "         [ 1.2562e-02,  8.7230e-01,  1.2898e+00, -6.0308e-01, -7.2310e-01],\n",
      "         [ 1.3428e-02,  8.7251e-01,  1.2942e+00, -6.0411e-01, -7.2297e-01]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-7.2929e-02,  5.4848e-01,  5.1346e-01, -2.8055e-01, -4.2223e-01],\n",
      "         [-5.5133e-02,  7.4964e-01,  8.6968e-01, -4.5564e-01, -6.0194e-01],\n",
      "         [-3.1545e-02,  8.4103e-01,  1.0842e+00, -5.4757e-01, -6.9362e-01],\n",
      "         [-1.2701e-02,  8.8114e-01,  1.2087e+00, -5.9407e-01, -7.3693e-01],\n",
      "         [ 3.0898e-04,  8.9891e-01,  1.2811e+00, -6.1768e-01, -7.5707e-01],\n",
      "         [ 4.8019e-02,  5.7693e-01,  8.8401e-01, -4.2665e-01, -5.3156e-01],\n",
      "         [-2.6783e-02,  8.2760e-01,  1.1456e+00, -5.2131e-01, -6.8612e-01]]],\n",
      "       device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-7.2929e-02,  5.4848e-01,  5.1346e-01, -2.8055e-01, -4.2223e-01],\n",
      "         [-5.5133e-02,  7.4964e-01,  8.6968e-01, -4.5564e-01, -6.0194e-01],\n",
      "         [-3.1545e-02,  8.4103e-01,  1.0842e+00, -5.4757e-01, -6.9362e-01],\n",
      "         [-1.2701e-02,  8.8114e-01,  1.2087e+00, -5.9407e-01, -7.3693e-01],\n",
      "         [ 3.0898e-04,  8.9891e-01,  1.2811e+00, -6.1768e-01, -7.5707e-01],\n",
      "         [ 9.0814e-03,  9.0697e-01,  1.3248e+00, -6.3025e-01, -7.6657e-01],\n",
      "         [ 1.4683e-02,  9.1036e-01,  1.3514e+00, -6.3716e-01, -7.7074e-01],\n",
      "         [ 1.8518e-02,  9.1173e-01,  1.3685e+00, -6.4114e-01, -7.7263e-01],\n",
      "         [ 2.0993e-02,  9.1218e-01,  1.3795e+00, -6.4373e-01, -7.7317e-01],\n",
      "         [ 2.2569e-02,  9.1219e-01,  1.3867e+00, -6.4544e-01, -7.7340e-01],\n",
      "         [ 2.3698e-02,  9.1220e-01,  1.3917e+00, -6.4666e-01, -7.7339e-01]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0714,  0.5780,  0.5449, -0.3008, -0.4478],\n",
      "         [-0.0513,  0.7937,  0.9272, -0.4880, -0.6433],\n",
      "         [-0.0249,  0.8884,  1.1578, -0.5863, -0.7416],\n",
      "         [-0.0035,  0.9276,  1.2910, -0.6354, -0.7870],\n",
      "         [ 0.0111,  0.9438,  1.3686, -0.6598, -0.8080],\n",
      "         [ 0.0605,  0.6049,  0.9584, -0.4636, -0.5629],\n",
      "         [-0.0161,  0.8705,  1.2309, -0.5645, -0.7321]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0714,  0.5780,  0.5449, -0.3008, -0.4478],\n",
      "         [-0.0513,  0.7937,  0.9272, -0.4880, -0.6433],\n",
      "         [-0.0249,  0.8884,  1.1578, -0.5863, -0.7416],\n",
      "         [-0.0035,  0.9276,  1.2910, -0.6354, -0.7870],\n",
      "         [ 0.0111,  0.9438,  1.3686, -0.6598, -0.8080],\n",
      "         [ 0.0211,  0.9503,  1.4151, -0.6728, -0.8175],\n",
      "         [ 0.0274,  0.9523,  1.4435, -0.6797, -0.8216],\n",
      "         [ 0.0317,  0.9528,  1.4619, -0.6839, -0.8234],\n",
      "         [ 0.0346,  0.9524,  1.4737, -0.6863, -0.8238],\n",
      "         [ 0.0364,  0.9520,  1.4815, -0.6880, -0.8238],\n",
      "         [ 0.0378,  0.9513,  1.4869, -0.6890, -0.8237]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0684,  0.6086,  0.5741, -0.3211, -0.4731],\n",
      "         [-0.0455,  0.8393,  0.9814, -0.5206, -0.6844],\n",
      "         [-0.0158,  0.9371,  1.2276, -0.6252, -0.7893],\n",
      "         [ 0.0085,  0.9753,  1.3699, -0.6771, -0.8371],\n",
      "         [ 0.0253,  0.9894,  1.4525, -0.7026, -0.8587],\n",
      "         [ 0.0748,  0.6338,  1.0323, -0.5011, -0.5959],\n",
      "         [-0.0020,  0.9141,  1.3151, -0.6083, -0.7789]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0684,  0.6086,  0.5741, -0.3211, -0.4731],\n",
      "         [-0.0455,  0.8393,  0.9814, -0.5206, -0.6844],\n",
      "         [-0.0158,  0.9371,  1.2276, -0.6252, -0.7893],\n",
      "         [ 0.0085,  0.9753,  1.3699, -0.6771, -0.8371],\n",
      "         [ 0.0253,  0.9894,  1.4525, -0.7026, -0.8587],\n",
      "         [ 0.0363,  0.9937,  1.5017, -0.7157, -0.8683],\n",
      "         [ 0.0436,  0.9946,  1.5325, -0.7228, -0.8726],\n",
      "         [ 0.0485,  0.9938,  1.5518, -0.7266, -0.8741],\n",
      "         [ 0.0518,  0.9927,  1.5647, -0.7291, -0.8745],\n",
      "         [ 0.0539,  0.9913,  1.5730, -0.7305, -0.8745],\n",
      "         [ 0.0556,  0.9902,  1.5789, -0.7317, -0.8741]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0639,  0.6404,  0.6009, -0.3413, -0.4980],\n",
      "         [-0.0374,  0.8867,  1.0320, -0.5534, -0.7253],\n",
      "         [-0.0037,  0.9878,  1.2938, -0.6645, -0.8372],\n",
      "         [ 0.0239,  1.0243,  1.4449, -0.7191, -0.8873],\n",
      "         [ 0.0430,  1.0360,  1.5327, -0.7456, -0.9095],\n",
      "         [ 0.0913,  0.6637,  1.1051, -0.5386, -0.6307],\n",
      "         [ 0.0155,  0.9580,  1.3970, -0.6525, -0.8265]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0639,  0.6404,  0.6009, -0.3413, -0.4980],\n",
      "         [-0.0374,  0.8867,  1.0320, -0.5534, -0.7253],\n",
      "         [-0.0037,  0.9878,  1.2938, -0.6645, -0.8372],\n",
      "         [ 0.0239,  1.0243,  1.4449, -0.7191, -0.8873],\n",
      "         [ 0.0430,  1.0360,  1.5327, -0.7456, -0.9095],\n",
      "         [ 0.0555,  1.0382,  1.5850, -0.7587, -0.9193],\n",
      "         [ 0.0639,  1.0371,  1.6175, -0.7656, -0.9234],\n",
      "         [ 0.0695,  1.0352,  1.6382, -0.7692, -0.9249],\n",
      "         [ 0.0732,  1.0331,  1.6520, -0.7717, -0.9253],\n",
      "         [ 0.0756,  1.0311,  1.6610, -0.7730, -0.9250],\n",
      "         [ 0.0774,  1.0294,  1.6673, -0.7740, -0.9246]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0581,  0.6731,  0.6251, -0.3613, -0.5222],\n",
      "         [-0.0277,  0.9359,  1.0787, -0.5856, -0.7656],\n",
      "         [ 0.0101,  1.0403,  1.3552, -0.7033, -0.8843],\n",
      "         [ 0.0416,  1.0747,  1.5153, -0.7607, -0.9367],\n",
      "         [ 0.0633,  1.0838,  1.6081, -0.7881, -0.9598],\n",
      "         [ 0.1096,  0.6949,  1.1757, -0.5756, -0.6668],\n",
      "         [ 0.0362,  1.0027,  1.4760, -0.6964, -0.8743]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0581,  0.6731,  0.6251, -0.3613, -0.5222],\n",
      "         [-0.0277,  0.9359,  1.0787, -0.5856, -0.7656],\n",
      "         [ 0.0101,  1.0403,  1.3552, -0.7033, -0.8843],\n",
      "         [ 0.0416,  1.0747,  1.5153, -0.7607, -0.9367],\n",
      "         [ 0.0633,  1.0838,  1.6081, -0.7881, -0.9598],\n",
      "         [ 0.0778,  1.0837,  1.6637, -0.8014, -0.9698],\n",
      "         [ 0.0873,  1.0807,  1.6981, -0.8080, -0.9741],\n",
      "         [ 0.0935,  1.0775,  1.7202, -0.8115, -0.9754],\n",
      "         [ 0.0978,  1.0742,  1.7348, -0.8136, -0.9755],\n",
      "         [ 0.1006,  1.0714,  1.7446, -0.8148, -0.9753],\n",
      "         [ 0.1027,  1.0693,  1.7515, -0.8155, -0.9749]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0512,  0.7068,  0.6463, -0.3810, -0.5460],\n",
      "         [-0.0164,  0.9873,  1.1204, -0.6175, -0.8058],\n",
      "         [ 0.0259,  1.0951,  1.4109, -0.7416, -0.9316],\n",
      "         [ 0.0614,  1.1275,  1.5798, -0.8022, -0.9864],\n",
      "         [ 0.0861,  1.1334,  1.6779, -0.8307, -1.0102],\n",
      "         [ 0.1297,  0.7282,  1.2436, -0.6126, -0.7049],\n",
      "         [ 0.0596,  1.0486,  1.5511, -0.7403, -0.9232]]], device='cuda:0')\n",
      "CPU times: user 126 ms, sys: 23.2 ms, total: 149 ms\n",
      "Wall time: 148 ms\n"
     ]
    }
   ],
   "source": [
    "%time _ = seq_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4d6a156",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T14:11:54.771750Z",
     "start_time": "2022-04-05T14:11:54.740082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here2\n",
      "here21\n",
      "tensor([[[ 0.0533, -0.0668,  0.0509, -0.1268, -0.0599],\n",
      "         [ 0.0757, -0.0614,  0.1302, -0.1578, -0.0358],\n",
      "         [ 0.0825, -0.0630,  0.1838, -0.1707, -0.0218],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920]],\n",
      "\n",
      "        [[ 0.0533, -0.0668,  0.0509, -0.1268, -0.0599],\n",
      "         [ 0.0757, -0.0614,  0.1302, -0.1578, -0.0358],\n",
      "         [ 0.0825, -0.0630,  0.1838, -0.1707, -0.0218],\n",
      "         [ 0.0855, -0.0644,  0.2189, -0.1760, -0.0134],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920]],\n",
      "\n",
      "        [[ 0.0533, -0.0668,  0.0509, -0.1268, -0.0599],\n",
      "         [ 0.0757, -0.0614,  0.1302, -0.1578, -0.0358],\n",
      "         [ 0.0825, -0.0630,  0.1838, -0.1707, -0.0218],\n",
      "         [ 0.0855, -0.0644,  0.2189, -0.1760, -0.0134],\n",
      "         [ 0.0873, -0.0644,  0.2421, -0.1783, -0.0081],\n",
      "         [ 0.0887, -0.0634,  0.2579, -0.1794, -0.0046],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920]],\n",
      "\n",
      "        [[ 0.0533, -0.0668,  0.0509, -0.1268, -0.0599],\n",
      "         [ 0.0757, -0.0614,  0.1302, -0.1578, -0.0358],\n",
      "         [ 0.0825, -0.0630,  0.1838, -0.1707, -0.0218],\n",
      "         [ 0.0855, -0.0644,  0.2189, -0.1760, -0.0134],\n",
      "         [ 0.0873, -0.0644,  0.2421, -0.1783, -0.0081],\n",
      "         [ 0.0887, -0.0634,  0.2579, -0.1794, -0.0046],\n",
      "         [ 0.0899, -0.0620,  0.2686, -0.1798, -0.0022],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920]],\n",
      "\n",
      "        [[ 0.0533, -0.0668,  0.0509, -0.1268, -0.0599],\n",
      "         [ 0.0757, -0.0614,  0.1302, -0.1578, -0.0358],\n",
      "         [ 0.0825, -0.0630,  0.1838, -0.1707, -0.0218],\n",
      "         [ 0.0855, -0.0644,  0.2189, -0.1760, -0.0134],\n",
      "         [ 0.0873, -0.0644,  0.2421, -0.1783, -0.0081],\n",
      "         [ 0.0887, -0.0634,  0.2579, -0.1794, -0.0046],\n",
      "         [ 0.0899, -0.0620,  0.2686, -0.1798, -0.0022],\n",
      "         [ 0.0911, -0.0604,  0.2761, -0.1798, -0.0005],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920]],\n",
      "\n",
      "        [[ 0.0533, -0.0668,  0.0509, -0.1268, -0.0599],\n",
      "         [ 0.0757, -0.0614,  0.1302, -0.1578, -0.0358],\n",
      "         [ 0.0825, -0.0630,  0.1838, -0.1707, -0.0218],\n",
      "         [ 0.0855, -0.0644,  0.2189, -0.1760, -0.0134],\n",
      "         [ 0.0873, -0.0644,  0.2421, -0.1783, -0.0081],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920]],\n",
      "\n",
      "        [[ 0.0533, -0.0668,  0.0509, -0.1268, -0.0599],\n",
      "         [ 0.0757, -0.0614,  0.1302, -0.1578, -0.0358],\n",
      "         [ 0.0825, -0.0630,  0.1838, -0.1707, -0.0218],\n",
      "         [ 0.0855, -0.0644,  0.2189, -0.1760, -0.0134],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920]],\n",
      "\n",
      "        [[ 0.0533, -0.0668,  0.0509, -0.1268, -0.0599],\n",
      "         [ 0.0757, -0.0614,  0.1302, -0.1578, -0.0358],\n",
      "         [ 0.0825, -0.0630,  0.1838, -0.1707, -0.0218],\n",
      "         [ 0.0855, -0.0644,  0.2189, -0.1760, -0.0134],\n",
      "         [ 0.0873, -0.0644,  0.2421, -0.1783, -0.0081],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920]],\n",
      "\n",
      "        [[ 0.0533, -0.0668,  0.0509, -0.1268, -0.0599],\n",
      "         [ 0.0757, -0.0614,  0.1302, -0.1578, -0.0358],\n",
      "         [ 0.0825, -0.0630,  0.1838, -0.1707, -0.0218],\n",
      "         [ 0.0855, -0.0644,  0.2189, -0.1760, -0.0134],\n",
      "         [ 0.0873, -0.0644,  0.2421, -0.1783, -0.0081],\n",
      "         [ 0.0887, -0.0634,  0.2579, -0.1794, -0.0046],\n",
      "         [ 0.0899, -0.0620,  0.2686, -0.1798, -0.0022],\n",
      "         [ 0.0911, -0.0604,  0.2761, -0.1798, -0.0005],\n",
      "         [ 0.0630, -0.1006,  0.2509, -0.1372, -0.1017],\n",
      "         [ 0.0803, -0.0680,  0.2470, -0.1644, -0.0288],\n",
      "         [ 0.0892, -0.0512,  0.2553, -0.1770, -0.0134]],\n",
      "\n",
      "        [[ 0.0533, -0.0668,  0.0509, -0.1268, -0.0599],\n",
      "         [ 0.0757, -0.0614,  0.1302, -0.1578, -0.0358],\n",
      "         [ 0.0825, -0.0630,  0.1838, -0.1707, -0.0218],\n",
      "         [ 0.0855, -0.0644,  0.2189, -0.1760, -0.0134],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920]],\n",
      "\n",
      "        [[ 0.0533, -0.0668,  0.0509, -0.1268, -0.0599],\n",
      "         [ 0.0757, -0.0614,  0.1302, -0.1578, -0.0358],\n",
      "         [ 0.0825, -0.0630,  0.1838, -0.1707, -0.0218],\n",
      "         [ 0.0855, -0.0644,  0.2189, -0.1760, -0.0134],\n",
      "         [ 0.0873, -0.0644,  0.2421, -0.1783, -0.0081],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920]]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['B', 'O', 'O'],\n",
       " ['B', 'O', 'O', 'O'],\n",
       " ['B', 'O', 'O', 'O', 'O', 'O'],\n",
       " ['B', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       " ['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       " ['B', 'O', 'O', 'O', 'O'],\n",
       " ['B', 'O', 'O', 'O'],\n",
       " ['B', 'O', 'O', 'O', 'O'],\n",
       " ['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       " ['B', 'O', 'O', 'O'],\n",
       " ['B', 'O', 'O', 'O', 'O']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_mod.predict(\"the wall street journal reported today that apple corporation made money\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "ceee1a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchcrf import CRF\n",
    "\n",
    "class TorchCRFSequenceLabeler(TorchRNNClassifier):\n",
    "\n",
    "    def build_graph(self): # uses this build_graph instead of TorchRNNClassifier.build_graph\n",
    "        print(\"here0\")\n",
    "        rnn = TorchRNNModel(\n",
    "            vocab_size=len(self.vocab),\n",
    "            embedding=self.embedding,\n",
    "            use_embedding=self.use_embedding,\n",
    "            embed_dim=self.embed_dim,\n",
    "            rnn_cell_class=self.rnn_cell_class,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            bidirectional=self.bidirectional,\n",
    "            freeze_embedding=self.freeze_embedding)\n",
    "        print(\"here02\")\n",
    "        model = TorchSequenceLabeler( # this defines self.model\n",
    "            rnn=rnn,\n",
    "            output_dim=self.n_classes_)\n",
    "        self.embed_dim = rnn.embed_dim\n",
    "        return model\n",
    "\n",
    "    def build_dataset(self, X, y=None):\n",
    "        START_TAG = \"<START>\"\n",
    "        STOP_TAG = \"<STOP>\"\n",
    "        X, seq_lengths = self._prepare_sequences(X) # converts tokens into tokenIds\n",
    "        if y is None:\n",
    "            return TorchCRFDataset(X, seq_lengths)\n",
    "            #return TorchRNNDataset(X, seq_lengths)\n",
    "        else:\n",
    "            # These are the changes from a regular classifier. All\n",
    "            # concern the fact that our labels are sequences of labels.\n",
    "            self.classes_ = sorted({x for seq in y for x in seq})\n",
    "            self.classes_.append(START_TAG) # add start and stop tags\n",
    "            self.classes_.append(STOP_TAG)\n",
    "            self.n_classes_ = len(self.classes_)\n",
    "            class2index = dict(zip(self.classes_, range(self.n_classes_)))\n",
    "            print(class2index)\n",
    "            # `y` is a list of tensors of different length. Our Dataset\n",
    "            # class will turn it into a padding tensor for processing.\n",
    "            y = [torch.tensor([class2index[label] for label in seq])\n",
    "                 for seq in y] # converts labels to indices\n",
    "            return TorchCRFDataset(X, seq_lengths, y)\n",
    "            #return TorchRNNDataset(X, seq_lengths, y)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        seq_lengths = [len(ex) for ex in X]\n",
    "        # The base class does the heavy lifting:\n",
    "        preds = self._predict(X)\n",
    "        # Trim to the actual sequence lengths:\n",
    "        preds = [p[: l] for p, l in zip(preds, seq_lengths)]\n",
    "        # Use `softmax`; the model doesn't do this because the loss\n",
    "        # function does it internally.\n",
    "        probs = [torch.softmax(seq, dim=1) for seq in preds]\n",
    "        return probs\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        return [[self.classes_[i] for i in seq.argmax(axis=1)] for seq in probs] # seq.argmax(axis=1) gives index of col that maximizes softmax prob\n",
    "        # see difference vs TorchRNNClassifier.predict\n",
    "\n",
    "    def score(self, X, y):\n",
    "        preds = self.predict(X)\n",
    "        flat_preds = [x for seq in preds for x in seq]\n",
    "        flat_y = [x for seq in y for x in seq]\n",
    "        return utils.safe_macro_f1(flat_y, flat_preds)\n",
    "\n",
    "\n",
    "class TorchCRFDataset(TorchRNNDataset):\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        \"\"\"\n",
    "        Format a batch of examples for use in both training and prediction.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : tuple of length 2 (prediction) or 3 (training)\n",
    "            The first element is the list of input sequences. The\n",
    "            second is the list of lengths for those sequences. The third,\n",
    "            where present, is the list of labels.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X : torch.Tensor, shape `(batch_size, max_batch_length)`\n",
    "            As padded by `torch.nn.utils.rnn.pad_sequence.\n",
    "\n",
    "        seq_lengths : torch.LongTensor, shape `(batch_size, )`\n",
    "\n",
    "        y : torch.LongTensor, shape `(batch_size, )`\n",
    "            Only for training. In the case where `y` cannot be turned into\n",
    "            a Tensor, we assume it is because it is a list of variable\n",
    "            length sequences and to use `torch.nn.utils.rnn.pad_sequence`.\n",
    "            The hope is that this will accomodate sequence prediction.\n",
    "\n",
    "        \"\"\"\n",
    "        batch_elements = list(zip(*batch))\n",
    "        X = batch_elements[0]\n",
    "        seq_lengths = batch_elements[1]\n",
    "        X = torch.nn.utils.rnn.pad_sequence(X, batch_first=True)\n",
    "        seq_lengths = torch.tensor(seq_lengths)\n",
    "        if len(batch_elements) == 3:\n",
    "            y = batch_elements[2]\n",
    "            # We can try to accommodate the case where `y` is a sequence\n",
    "            # loss with potentially different lengths by resorting to\n",
    "            # padding if creating a tensor is not possible:\n",
    "            try:\n",
    "                y = torch.tensor(y)\n",
    "            # except ValueError:\n",
    "            except TypeError:\n",
    "                y = torch.nn.utils.rnn.pad_sequence(y, batch_first=True, padding_value=3) # need to pad with STOP tag\n",
    "            return X, seq_lengths, y\n",
    "        else:\n",
    "            return X, seq_lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "f6014b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following converts words to indices and pads sequences\n",
    "seq_mod = TorchCRFSequenceLabeler(\n",
    "    vocab,\n",
    "    early_stopping=True,\n",
    "    eta=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ec885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [\"the wall street journal reported today that apple corporation made money\".split(),\"georgia tech is a university in georgia\".split()]\n",
    "y_train = [\"B I I I O O O B I O O\".split(),\"B I O O O O B\".split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "f43c9772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B': 0, 'I': 1, 'O': 2, '<START>': 3, '<STOP>': 4}\n",
      "tensor([[13, 16, 10,  6,  9, 14, 12,  1,  2,  7,  8],\n",
      "        [ 3, 11,  5,  0, 15,  4,  3,  0,  0,  0,  0]])\n",
      "tensor([[0, 1, 1, 1, 2, 2, 2, 0, 1, 2, 2],\n",
      "        [0, 1, 2, 2, 2, 2, 0, 3, 3, 3, 3]])\n",
      "tensor([11,  7])\n",
      "tensor([[ 1.7674, -0.0954,  0.1394, -1.5785],\n",
      "        [-0.3206, -0.2993,  1.8793, -0.0721],\n",
      "        [ 0.2753,  1.7163, -0.0561,  0.9107],\n",
      "        [-1.3924,  2.6891, -0.1110,  0.2927],\n",
      "        [ 2.0242, -0.0865,  0.0981, -1.2150],\n",
      "        [ 0.7312,  1.1718, -0.9274,  0.5451],\n",
      "        [ 0.2468,  1.1843, -0.7282,  1.1633],\n",
      "        [-0.0091, -0.8425,  0.1374,  0.9386],\n",
      "        [-1.8034, -1.3083,  0.4533,  1.1422],\n",
      "        [ 0.2486, -1.7754, -0.0255, -1.0233],\n",
      "        [ 0.1099, -0.6463,  0.4285,  1.4761]])\n",
      "tensor(-39.0331, grad_fn=<SumBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0139, -0.0122,  0.0277,  0.0049],\n",
      "        [ 0.0365, -0.0390, -0.0073, -0.0090],\n",
      "        [ 0.0145, -0.0004,  0.0874,  0.0311],\n",
      "        [-0.0372, -0.0604, -0.0168, -0.0431]], requires_grad=True)\n",
      "[[0, 1], [2, 3], [1, 1], [1, 3], [0, 2], [1, 2], [3, 3], [3, 0], [3, 3], [0, 1], [3, 1]]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "dataset = seq_mod.build_dataset(X_train, y_train) # not good ... is padding with zeros (=B's)\n",
    "dataloader = seq_mod._build_dataloader(dataset, shuffle=False) \n",
    "num_tags = 4\n",
    "model = CRF(num_tags)\n",
    "for batch_num, batch in enumerate(dataloader, start=1):\n",
    "    x=batch[0]\n",
    "    seq_length=batch[1]\n",
    "    y=batch[2] \n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(seq_length)\n",
    "batch_size=2\n",
    "emissions = torch.randn(batch_size, max(seq_length), num_tags)\n",
    "print(emissions[0])\n",
    "print(model(emissions,y)) # computes log likelihood\n",
    "#model.decode(emissions)\n",
    "a=model.transitions\n",
    "print(a)\n",
    "print(model.decode(emissions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "bdcc06e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6280/2061908090.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#print(tags.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memissions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\xcs224u\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\xcs224u\\lib\\site-packages\\torchcrf\\__init__.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, emissions, tags, mask, reduction)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0mreduction\u001b[0m \u001b[1;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mnone\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0motherwise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \"\"\"\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memissions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'none'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sum'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'token_mean'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'invalid reduction: {reduction}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\xcs224u\\lib\\site-packages\\torchcrf\\__init__.py\u001b[0m in \u001b[0;36m_validate\u001b[1;34m(self, emissions, tags, mask)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtags\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0memissions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m                 raise ValueError(\n\u001b[0;32m    156\u001b[0m                     \u001b[1;34m'the first two dimensions of emissions and tags must match, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "tags = a.sequences\n",
    "#print(tags.shape)\n",
    "model(emissions,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "d5c17e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "# note: this isn't exactly correct as training examples are shuffled (esp. max len of the smaller 12 ex batch is != 92)\n",
    "auxMax=0\n",
    "x_max_idx=108\n",
    "for i in range(0,min(len(X_train),x_max_idx)):\n",
    "    if len(X_train[i])>auxMax:\n",
    "        auxMax=len(X_train[i])\n",
    "print(auxMax)\n",
    "auxMax2=0\n",
    "x_min_idx=109\n",
    "for i in range(max(0,x_min_idx),len(X_train)):\n",
    "    if len(X_train[i])>auxMax2:\n",
    "        auxMax2=len(X_train[i])\n",
    "print(auxMax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cfe2a431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ORT', 'O', 'O', 'STRASSE', 'STRASSE', 'O', 'ORT', 'O', 'O', 'FLAECHE', 'O', 'O', 'IMMO_TYP', 'O', 'O', 'O', 'O', 'QMPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'VERKAEUFER', 'O', 'O', 'O', 'O', 'O', 'GESAMTPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERTRAG', 'DATUM_VERTRAG', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERBUECHERUNG', 'DATUM_VERBUECHERUNG', 'O']\n",
      "['KAEUFER', 'KAEUFER', 'O', 'O', 'KAEUFER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'IMMO_TYP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "y_pred = seq_mod.predict(X_test)\n",
    "print(y_test[0])\n",
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2960fed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=seq_mod.classes_\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d615f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfold all our data - NOTE: this means we don't care about per sentence results. \n",
    "# i.e. each classification is worth same regardless of sentence in which it occurs\n",
    "y_test_unfold = [y for element in y_test for y in element]\n",
    "y_pred_unfold = [y for element in y_pred for y in element]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "99efc2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ORT', 'O', 'O', 'STRASSE', 'STRASSE', 'O', 'ORT', 'O', 'O', 'FLAECHE']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(y_test_unfold[:10])\n",
    "print(y_pred_unfold[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5de61d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert y_test and y_pred into binary formats\n",
    "#from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7f4747c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                  O      0.808     0.888     0.846       643\n",
      "            KAEUFER      0.070     0.278     0.112        18\n",
      "DATUM_VERBUECHERUNG      0.000     0.000     0.000        25\n",
      "      DATUM_VERTRAG      1.000     0.037     0.071        27\n",
      "         VERKAEUFER      0.333     0.042     0.074        24\n",
      "   TERRASSENGROESSE      0.000     0.000     0.000         5\n",
      "        GESAMTPREIS      0.000     0.000     0.000        11\n",
      "            FLAECHE      0.000     0.000     0.000        15\n",
      "           IMMO_TYP      0.000     0.000     0.000        19\n",
      "            QMPREIS      0.000     0.000     0.000        10\n",
      "                ORT      0.000     0.000     0.000        26\n",
      "            STRASSE      0.118     0.125     0.121        16\n",
      "\n",
      "           accuracy                          0.691       839\n",
      "          macro avg      0.194     0.114     0.102       839\n",
      "       weighted avg      0.664     0.691     0.657       839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(\n",
    "    y_test_unfold, y_pred_unfold, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d9457a",
   "metadata": {},
   "source": [
    "Now try with leading \"B-\" and \"I-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a6f7276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## ONLY RUN IF WE WANT TO ADD LEADING \"B-\" / \"I-\" TO CLASS LABEL\n",
    "# now use above code and loop through all items of annot list:\n",
    "# addLeading=1 for \"Yes\" (i.e. add leading \"B-\",\"I-\" to annot); 0 for \"No\" (i.e. add labels to annot simply as they are)\n",
    "addLeading = 1\n",
    "\n",
    "if addLeading == 1:\n",
    "    for j in range(0,len(annot)):\n",
    "        a = annot[j]\n",
    "        # select list of dict of tokens w/ annnotations and add column w/ no. of words to each dict:\n",
    "        b = a['spans']\n",
    "        # add noWords to b dict. note: b is list of dicts w/ annotations; tokens not on this list don't have annotations\n",
    "        if b!=[]: #i.e. only try to add annotations to tokens if there are annotations to begin with\n",
    "            #print(b)\n",
    "            for i in range(0,len(annot[j]['tokens'])):\n",
    "                    # now break-up label into 1st occurrence (leading \"B-\") and subsequent occurrences (leading \"I-\") (only for non \"O\"'s)\n",
    "                    if annot[j]['tokens'][i]['label'] != \"O\":\n",
    "                        if i==0:\n",
    "                            annot[j]['tokens'][i]['label'] = \"B-\" + annot[j]['tokens'][i]['label']\n",
    "                        else: \n",
    "                            if annot[j]['tokens'][i]['label'] == annot[j]['tokens'][i-1]['label'][2:]: # need to remove the leading \"B-\" that we had already been added to c[i-1]\n",
    "                                annot[j]['tokens'][i]['label'] = \"I-\" + annot[j]['tokens'][i]['label']\n",
    "                            else:\n",
    "                                annot[j]['tokens'][i]['label'] = \"B-\" + annot[j]['tokens'][i]['label'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e6bd88ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get data into format that TorchRNN expects:\n",
    "X=[] \n",
    "y=[]\n",
    "for j in range(0,len(annot)):\n",
    "    a = annot[j]['tokens']\n",
    "    auxX = []\n",
    "    auxy = []\n",
    "    if annot[j]['spans']!=[]: # are there annot for this example?\n",
    "        for i in range(0,len(a)):\n",
    "            #token_element = (a[i]['text'],a[i]['label'])\n",
    "            auxX.append(a[i]['text'])\n",
    "            auxy.append(a[i]['label'])\n",
    "        X.append(auxX)\n",
    "        y.append(auxy)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_train, X_test, y_train, y_test = X[:120], X[120:], y[:120], y[120:]\n",
    "vocab = sorted({w for seq in X_train for w in seq}) + [\"$UNK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "353255ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DORNBIRN', 'In', 'der', 'Schulgasse', 'in', 'Dornbirn', 'hat', 'eine', '71,93', 'Quadratmeter', 'große', 'Wohnung', 'für', 'einen', 'Quadratmeterpreis', 'von', '5533,71', 'Euro', 'den', 'Besitzer', 'gewechselt', '.', 'Dieser', 'beinhaltet', 'auch', 'einen', 'Pkw-Abstellplatz', '.', 'Käufer', 'der', 'Wohnung', 'mit', '9,86', 'Quadratmetern', 'Terrasse', 'ist', 'die', 'ValLiLean', 'Beteiligungs-', 'und', 'Immobilienverwaltungs', 'GmbH', 'Beim', 'Verkäufer', 'handelt', 'es', 'sich', 'um', 'die', 'Karrenblick', 'Projekt', 'GmbH', ' ', 'Der', 'Kaufpreis', 'liegt', 'bei', '398.040', 'Euro', '.', 'Unterzeichnet', 'wurde', 'der', 'Kaufvertrag', 'am', '18.', 'September', '.', 'Die', 'Verbücherung', 'datiert', 'mit', 'Oktober', '2020', '.', '.', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "071c6a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 35. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 2.249159574508667"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.78 s\n",
      "['B-ORT', 'O', 'O', 'B-STRASSE', 'I-STRASSE', 'O', 'B-ORT', 'O', 'O', 'B-FLAECHE', 'O', 'O', 'B-IMMO_TYP', 'O', 'O', 'O', 'O', 'B-QMPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-VERKAEUFER', 'O', 'O', 'O', 'O', 'O', 'B-GESAMTPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATUM_VERTRAG', 'I-DATUM_VERTRAG', 'O', 'O', 'O', 'O', 'O', 'B-DATUM_VERBUECHERUNG', 'I-DATUM_VERBUECHERUNG', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "%time _ = seq_mod.fit(X_train, y_train)\n",
    "y_pred = seq_mod.predict(X_test)\n",
    "print(y_test[0])\n",
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "92a8a32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=seq_mod.classes_\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b338e92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfold all our data - NOTE: this means we don't care about per sentence results. \n",
    "# i.e. each classification is worth same regardless of sentence in which it occurs\n",
    "y_test_unfold = [y for element in y_test for y in element]\n",
    "y_pred_unfold = [y for element in y_pred for y in element]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "78515133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                    O      0.773     0.988     0.867       643\n",
      "B-DATUM_VERBUECHERUNG      0.000     0.000     0.000        13\n",
      "I-DATUM_VERBUECHERUNG      0.000     0.000     0.000        12\n",
      "      B-DATUM_VERTRAG      0.000     0.000     0.000        13\n",
      "      I-DATUM_VERTRAG      0.000     0.000     0.000        14\n",
      "            B-FLAECHE      0.000     0.000     0.000        15\n",
      "            I-FLAECHE      0.000     0.000     0.000         0\n",
      "        B-GESAMTPREIS      0.000     0.000     0.000        11\n",
      "        I-GESAMTPREIS      0.000     0.000     0.000         0\n",
      "           B-IMMO_TYP      0.000     0.000     0.000        19\n",
      "           I-IMMO_TYP      0.000     0.000     0.000         0\n",
      "            B-KAEUFER      0.000     0.000     0.000        10\n",
      "            I-KAEUFER      0.000     0.000     0.000         8\n",
      "                B-ORT      0.300     0.115     0.167        26\n",
      "            B-QMPREIS      0.000     0.000     0.000        10\n",
      "            I-QMPREIS      0.000     0.000     0.000         0\n",
      "            B-STRASSE      0.000     0.000     0.000        12\n",
      "            I-STRASSE      0.000     0.000     0.000         4\n",
      "   B-TERRASSENGROESSE      0.000     0.000     0.000         5\n",
      "         B-VERKAEUFER      0.000     0.000     0.000        13\n",
      "         I-VERKAEUFER      0.000     0.000     0.000        11\n",
      "\n",
      "            micro avg      0.760     0.760     0.760       839\n",
      "            macro avg      0.051     0.053     0.049       839\n",
      "         weighted avg      0.601     0.760     0.670       839\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasco\\anaconda3\\envs\\xcs224u\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(\n",
    "    y_test_unfold, y_pred_unfold, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0680fd70",
   "metadata": {},
   "source": [
    "Remove \"B-\" and \"I-\" (in case they are present in labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9a2de8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0,len(annot)):\n",
    "    a = annot[j]\n",
    "    b = a['spans']\n",
    "    if b!=[]: #i.e. only try to add annotations to tokens if there are annotations to begin with\n",
    "        for i in range(0,len(annot[j]['tokens'])):\n",
    "                if annot[j]['tokens'][i]['label'] != \"O\":\n",
    "                    if annot[j]['tokens'][i]['label'][:2]==\"B-\" or annot[j]['tokens'][i]['label'][:2]==\"I-\":\n",
    "                        annot[j]['tokens'][i]['label']=annot[j]['tokens'][i]['label'][2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f22b42",
   "metadata": {},
   "source": [
    "Try bi-directional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "147649d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_mod = TorchRNNSequenceLabeler(\n",
    "    vocab,\n",
    "    early_stopping=True,\n",
    "    eta=0.001,\n",
    "    bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "63ca2332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ORT', 'O', 'O', 'STRASSE', 'O', 'ORT', 'O', 'O', 'FLAECHE', 'O', 'O', 'IMMO_TYP', 'O', 'O', 'O', 'O', 'QMPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'TERRASSENGROESSE', 'O', 'O', 'O', 'O', 'KAEUFER', 'KAEUFER', 'KAEUFER', 'KAEUFER', 'KAEUFER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'VERKAEUFER', 'VERKAEUFER', 'VERKAEUFER', 'O', 'O', 'O', 'O', 'O', 'GESAMTPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERTRAG', 'DATUM_VERTRAG', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERBUECHERUNG', 'DATUM_VERBUECHERUNG', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8413a3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 18. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 2.1157665252685547"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.12 s\n"
     ]
    }
   ],
   "source": [
    "%time _ = seq_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8d5884c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ORT', 'O', 'O', 'STRASSE', 'STRASSE', 'O', 'ORT', 'O', 'O', 'FLAECHE', 'O', 'O', 'IMMO_TYP', 'O', 'O', 'O', 'O', 'QMPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'VERKAEUFER', 'O', 'O', 'O', 'O', 'O', 'GESAMTPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERTRAG', 'DATUM_VERTRAG', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERBUECHERUNG', 'DATUM_VERBUECHERUNG', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'IMMO_TYP', 'O', 'O', 'TERRASSENGROESSE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'TERRASSENGROESSE', 'TERRASSENGROESSE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                  O      0.760     0.893     0.821       643\n",
      "            KAEUFER      0.000     0.000     0.000        18\n",
      "DATUM_VERBUECHERUNG      0.000     0.000     0.000        25\n",
      "      DATUM_VERTRAG      0.000     0.000     0.000        27\n",
      "         VERKAEUFER      0.000     0.000     0.000        24\n",
      "   TERRASSENGROESSE      0.000     0.000     0.000         5\n",
      "        GESAMTPREIS      0.000     0.000     0.000        11\n",
      "            FLAECHE      0.000     0.000     0.000        15\n",
      "           IMMO_TYP      0.000     0.000     0.000        19\n",
      "            QMPREIS      0.000     0.000     0.000        10\n",
      "                ORT      0.000     0.000     0.000        26\n",
      "            STRASSE      0.000     0.000     0.000        16\n",
      "\n",
      "           accuracy                          0.684       839\n",
      "          macro avg      0.063     0.074     0.068       839\n",
      "       weighted avg      0.583     0.684     0.629       839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = seq_mod.predict(X_test)\n",
    "print(y_test[0])\n",
    "print(y_pred[0])\n",
    "\n",
    "labels=seq_mod.classes_\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "\n",
    "# unfold all our data - NOTE: this means we don't care about per sentence results. \n",
    "# i.e. each classification is worth same regardless of sentence in which it occurs\n",
    "y_test_unfold = [y for element in y_test for y in element]\n",
    "y_pred_unfold = [y for element in y_pred for y in element]\n",
    "\n",
    "print(classification_report(\n",
    "    y_test_unfold, y_pred_unfold, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195d592b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchtext2",
   "language": "python",
   "name": "torchtext2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

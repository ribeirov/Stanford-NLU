{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46bc54ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.metrics import classification_report, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#from torch_model_base import TorchModelBase\n",
    "#from torch_shallow_neural_classifier import TorchShallowNeuralClassifier\n",
    "from torch_rnn_classifier import TorchRNNDataset, TorchRNNClassifier, TorchRNNModel\n",
    "import utils\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df4daa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refresh torch rnn classifier:\n",
    "import importlib\n",
    "import torch_rnn_classifier\n",
    "importlib.reload(torch_rnn_classifier)\n",
    "from torch_rnn_classifier import TorchRNNDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c519f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ebc5fbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('annotations2.jsonl') as jsonl_file:\n",
    "    # note: after running data-preprocessing.ipynb this file already has token-level labels\n",
    "    lines = jsonl_file.readlines()\n",
    "annot = [json.loads(line) for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "62fbb470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get data into format that TorchRNN expects:\n",
    "X=[] \n",
    "y=[]\n",
    "for j in range(0,len(annot)):\n",
    "    a = annot[j]['tokens']\n",
    "    auxX = []\n",
    "    auxy = []\n",
    "    if annot[j]['spans']!=[]: # are there annot for this example?\n",
    "        for i in range(0,len(a)):\n",
    "            #token_element = (a[i]['text'],a[i]['label'])\n",
    "            auxX.append(a[i]['text'])\n",
    "            auxy.append(a[i]['label'])\n",
    "        X.append(auxX)\n",
    "        y.append(auxy)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_train, X_test, y_train, y_test = X[:120], X[120:], y[:120], y[120:]\n",
    "vocab = sorted({w for seq in X_train for w in seq}) + [\"$UNK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b8b5c9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload vsm module\n",
    "import torch_rnn_classifier, torch_model_base\n",
    "import importlib\n",
    "importlib.reload(torch_model_base)\n",
    "importlib.reload(torch_rnn_classifier)\n",
    "from torch_model_base import TorchModelBase\n",
    "from torch_rnn_classifier import TorchRNNClassifier, TorchRNNModel, TorchRNNDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a33711db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchRNNSequenceLabeler(TorchRNNClassifier):\n",
    "\n",
    "    def build_graph(self): # uses this build_graph instead of TorchRNNClassifier.build_graph\n",
    "        print(\"here0\")\n",
    "        rnn = TorchRNNModel(\n",
    "            vocab_size=len(self.vocab),\n",
    "            embedding=self.embedding,\n",
    "            use_embedding=self.use_embedding,\n",
    "            embed_dim=self.embed_dim,\n",
    "            rnn_cell_class=self.rnn_cell_class,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            bidirectional=self.bidirectional,\n",
    "            freeze_embedding=self.freeze_embedding)\n",
    "        print(\"here02\")\n",
    "        model = TorchSequenceLabeler( # this defines self.model\n",
    "            rnn=rnn,\n",
    "            output_dim=self.n_classes_)\n",
    "        self.embed_dim = rnn.embed_dim\n",
    "        return model\n",
    "\n",
    "    def build_dataset(self, X, y=None):\n",
    "        START_TAG = \"<START>\"\n",
    "        STOP_TAG = \"<STOP>\"\n",
    "        X, seq_lengths = self._prepare_sequences(X) # converts tokens into tokenIds\n",
    "        if y is None:\n",
    "            return TorchRNNDataset(X, seq_lengths)\n",
    "        else:\n",
    "            # These are the changes from a regular classifier. All\n",
    "            # concern the fact that our labels are sequences of labels.\n",
    "            self.classes_ = sorted({x for seq in y for x in seq})\n",
    "            self.classes_.append(START_TAG) # add start and stop tags\n",
    "            self.classes_.append(STOP_TAG)\n",
    "            self.n_classes_ = len(self.classes_)\n",
    "            class2index = dict(zip(self.classes_, range(self.n_classes_)))\n",
    "            # `y` is a list of tensors of different length. Our Dataset\n",
    "            # class will turn it into a padding tensor for processing.\n",
    "            y = [torch.tensor([class2index[label] for label in seq])\n",
    "                 for seq in y] # converts labels to indices\n",
    "            return TorchRNNDataset(X, seq_lengths, y)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        seq_lengths = [len(ex) for ex in X]\n",
    "        # The base class does the heavy lifting:\n",
    "        preds = self._predict(X)\n",
    "        # Trim to the actual sequence lengths:\n",
    "        preds = [p[: l] for p, l in zip(preds, seq_lengths)]\n",
    "        # Use `softmax`; the model doesn't do this because the loss\n",
    "        # function does it internally.\n",
    "        probs = [torch.softmax(seq, dim=1) for seq in preds]\n",
    "        return probs\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        return [[self.classes_[i] for i in seq.argmax(axis=1)] for seq in probs] # seq.argmax(axis=1) gives index of col that maximizes softmax prob\n",
    "        # see difference vs TorchRNNClassifier.predict\n",
    "\n",
    "    def score(self, X, y):\n",
    "        preds = self.predict(X)\n",
    "        flat_preds = [x for seq in preds for x in seq]\n",
    "        flat_y = [x for seq in y for x in seq]\n",
    "        return utils.safe_macro_f1(flat_y, flat_preds)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "class TorchSequenceLabeler(nn.Module): # no self.hidden_layer or self.classifier_activation as TorchRNNClassifierModel\n",
    "    def __init__(self, rnn, output_dim):\n",
    "        print(\"here021\")\n",
    "        super().__init__()\n",
    "        self.rnn = rnn\n",
    "        self.output_dim = output_dim\n",
    "        if self.rnn.bidirectional:\n",
    "            self.classifier_dim = self.rnn.hidden_dim * 2\n",
    "        else:\n",
    "            self.classifier_dim = self.rnn.hidden_dim\n",
    "        self.classifier_layer = nn.Linear(\n",
    "            self.classifier_dim, self.output_dim)\n",
    "\n",
    "    def forward(self, X, seq_lengths): # X is (noExsInBatch,MaxLen)=(108,117), seq_lengths is the number of tokens in each example in each batch\n",
    "        # this is the forward method of self.model\n",
    "        print(\"here2\")\n",
    "        outputs, state = self.rnn(X, seq_lengths) # X is (batchSize, maxLen of exs in batch); outputs is (noTokensInEx,hiddDim), state is ((batch_size,1,hiddDim),(batch_size,1,hiddDim)) = (finalHiddState,finalCellState) \n",
    "        #print(outputs.data.shape)\n",
    "        #print(state[0].data.shape)\n",
    "        #print(state[1].data.shape)\n",
    "        outputs, seq_length = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "            outputs, batch_first=True) # outputs is (batchSize,MaxLen of examples in batch,hidden_dim); seq_length is noTokenInEx for each ex in batch\n",
    "        #print(outputs.data.shape)\n",
    "        #print(seq_length)\n",
    "        logits = self.classifier_layer(outputs) # this is an FCL from hidden_dim to output_dim (NoLabelClasses)\n",
    "        # logits are (108,117,12) or (1,11,5) = (batchSize,MaxLen of examples in batch,noLabelClasses) noLabelClasses include Start + End\n",
    "        # During training, we need to swap the dimensions of logits\n",
    "        # to accommodate `nn.CrossEntropyLoss`:\n",
    "        print(logits)\n",
    "        if self.training:\n",
    "            return logits.transpose(1, 2) # transpose dimensions 1 and 2 w/ each other (3d array) # outputs (108,12,117) or (1,5,11)\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdd5c84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [\"the wall street journal reported today that apple corporation made money\".split(),\"georgia tech is a university in georgia\".split()]\n",
    "y_train = [\"B I I I O O O B I O O\".split(),\"B I O O O O B\".split()]\n",
    "vocab = sorted({w for seq in X_train for w in seq}) + [\"$UNK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe4012cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_mod = TorchRNNSequenceLabeler(\n",
    "    vocab,\n",
    "    early_stopping=True,\n",
    "    eta=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8f210b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here00\n",
      "here0\n",
      "here01\n",
      "here02\n",
      "here021\n",
      "batch1\n",
      "here2\n",
      "here21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished epoch 10 of 1000; error is 1.3484532833099365"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3627, -0.0571,  0.1751, -0.1338,  0.0219],\n",
      "         [-0.0976,  0.0181,  0.0332, -0.0325,  0.1119],\n",
      "         [-0.2014,  0.0605,  0.1298, -0.0567,  0.0970],\n",
      "         [-0.2015,  0.1037,  0.0392, -0.0535,  0.0768],\n",
      "         [-0.0959,  0.0611,  0.0748, -0.1305,  0.1798],\n",
      "         [-0.1551,  0.0170,  0.0991, -0.1830,  0.0736],\n",
      "         [-0.0786,  0.0709,  0.0116, -0.0523, -0.1000],\n",
      "         [-0.1403,  0.1220, -0.0602, -0.0288,  0.1099],\n",
      "         [-0.2416,  0.1540,  0.1170,  0.0194,  0.1142],\n",
      "         [-0.2535, -0.0141,  0.0446,  0.1006,  0.1224],\n",
      "         [-0.1576, -0.1045,  0.1067,  0.0832,  0.1514]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1249, -0.0782,  0.0023, -0.0520,  0.1311],\n",
      "         [-0.0366,  0.0341,  0.0813, -0.1528,  0.0561],\n",
      "         [-0.0623,  0.1088,  0.0040, -0.1438,  0.1385],\n",
      "         [-0.1064,  0.0313,  0.1009, -0.0774,  0.0317],\n",
      "         [-0.2064,  0.0638,  0.1199,  0.0804,  0.0294],\n",
      "         [-0.1743,  0.0478,  0.0579,  0.1129, -0.0346],\n",
      "         [-0.1604, -0.0311, -0.0346,  0.0556,  0.0728]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-3.4811e-01, -4.9334e-02,  1.7122e-01, -1.3973e-01,  1.7148e-02],\n",
      "         [-9.9666e-02,  4.2356e-02,  4.2966e-02, -4.4054e-02,  9.6089e-02],\n",
      "         [-2.0156e-01,  8.6886e-02,  1.3601e-01, -6.3019e-02,  8.3773e-02],\n",
      "         [-2.0545e-01,  1.2941e-01,  4.9187e-02, -6.6033e-02,  5.8716e-02],\n",
      "         [-1.0480e-01,  6.6132e-02,  1.0596e-01, -1.4588e-01,  1.6261e-01],\n",
      "         [-1.6771e-01,  1.4023e-02,  1.3858e-01, -1.9643e-01,  5.9927e-02],\n",
      "         [-8.0451e-02,  6.1311e-02,  4.5406e-02, -6.5957e-02, -1.1155e-01],\n",
      "         [-1.1958e-01,  1.2353e-01, -4.1184e-02, -4.2967e-02,  9.9297e-02],\n",
      "         [-2.4195e-01,  1.6821e-01,  1.4462e-01, -2.0862e-07,  9.5562e-02],\n",
      "         [-2.6309e-01, -1.0023e-02,  8.7816e-02,  7.8723e-02,  1.0641e-01],\n",
      "         [-1.6708e-01, -1.0616e-01,  1.5685e-01,  6.3674e-02,  1.3334e-01]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1214, -0.0777,  0.0040, -0.0544,  0.1285],\n",
      "         [-0.0394,  0.0326,  0.0932, -0.1598,  0.0499],\n",
      "         [-0.0601,  0.1132,  0.0083, -0.1460,  0.1339],\n",
      "         [-0.1090,  0.0367,  0.1113, -0.0818,  0.0256],\n",
      "         [-0.2059,  0.0713,  0.1329,  0.0694,  0.0192],\n",
      "         [-0.1757,  0.0546,  0.0655,  0.1071, -0.0404],\n",
      "         [-0.1580, -0.0291, -0.0287,  0.0506,  0.0683]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.3336, -0.0417,  0.1674, -0.1465,  0.0118],\n",
      "         [-0.1017,  0.0669,  0.0526, -0.0555,  0.0804],\n",
      "         [-0.2019,  0.1133,  0.1424, -0.0693,  0.0704],\n",
      "         [-0.2096,  0.1556,  0.0589, -0.0791,  0.0403],\n",
      "         [-0.1139,  0.0713,  0.1370, -0.1616,  0.1453],\n",
      "         [-0.1803,  0.0112,  0.1778, -0.2095,  0.0463],\n",
      "         [-0.0823,  0.0518,  0.0789, -0.0796, -0.1233],\n",
      "         [-0.0990,  0.1257, -0.0222, -0.0567,  0.0890],\n",
      "         [-0.2426,  0.1833,  0.1713, -0.0191,  0.0767],\n",
      "         [-0.2729, -0.0052,  0.1305,  0.0580,  0.0910],\n",
      "         [-0.1768, -0.1077,  0.2062,  0.0460,  0.1162]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1180, -0.0772,  0.0057, -0.0568,  0.1259],\n",
      "         [-0.0424,  0.0310,  0.1050, -0.1667,  0.0436],\n",
      "         [-0.0581,  0.1174,  0.0125, -0.1482,  0.1295],\n",
      "         [-0.1116,  0.0418,  0.1217, -0.0862,  0.0194],\n",
      "         [-0.2058,  0.0787,  0.1458,  0.0584,  0.0088],\n",
      "         [-0.1772,  0.0613,  0.0728,  0.1015, -0.0463],\n",
      "         [-0.1555, -0.0271, -0.0230,  0.0459,  0.0638]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-3.1909e-01, -3.3850e-02,  1.6368e-01, -1.5353e-01,  6.2391e-03],\n",
      "         [-1.0363e-01,  9.1719e-02,  6.2039e-02, -6.6828e-02,  6.4597e-02],\n",
      "         [-2.0247e-01,  1.3982e-01,  1.4880e-01, -7.5503e-02,  5.6975e-02],\n",
      "         [-2.1408e-01,  1.8240e-01,  6.8538e-02, -9.2229e-02,  2.1676e-02],\n",
      "         [-1.2304e-01,  7.6723e-02,  1.6807e-01, -1.7727e-01,  1.2800e-01],\n",
      "         [-1.9282e-01,  8.4953e-03,  2.1659e-01, -2.2231e-01,  3.2772e-02],\n",
      "         [-8.4275e-02,  4.2127e-02,  1.1233e-01, -9.3372e-02, -1.3519e-01],\n",
      "         [-7.8755e-02,  1.2830e-01, -3.7891e-03, -7.0046e-02,  7.8906e-02],\n",
      "         [-2.4376e-01,  1.9895e-01,  1.9742e-01, -3.8035e-02,  5.7753e-02],\n",
      "         [-2.8327e-01, -2.2906e-04,  1.7290e-01,  3.7832e-02,  7.5776e-02],\n",
      "         [-1.8686e-01, -1.0928e-01,  2.5507e-01,  2.9269e-02,  9.9390e-02]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1145, -0.0767,  0.0073, -0.0591,  0.1232],\n",
      "         [-0.0455,  0.0294,  0.1168, -0.1734,  0.0371],\n",
      "         [-0.0561,  0.1215,  0.0167, -0.1503,  0.1251],\n",
      "         [-0.1143,  0.0466,  0.1320, -0.0905,  0.0130],\n",
      "         [-0.2058,  0.0860,  0.1586,  0.0474, -0.0019],\n",
      "         [-0.1786,  0.0682,  0.0799,  0.0960, -0.0524],\n",
      "         [-0.1531, -0.0251, -0.0174,  0.0412,  0.0591]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.3047, -0.0258,  0.1599, -0.1607,  0.0005],\n",
      "         [-0.1055,  0.1169,  0.0711, -0.0782,  0.0487],\n",
      "         [-0.2034,  0.1667,  0.1551, -0.0818,  0.0433],\n",
      "         [-0.2190,  0.2097,  0.0781, -0.1054,  0.0027],\n",
      "         [-0.1324,  0.0824,  0.1992, -0.1930,  0.1105],\n",
      "         [-0.2053,  0.0059,  0.2552, -0.2350,  0.0192],\n",
      "         [-0.0862,  0.0326,  0.1457, -0.1072, -0.1472],\n",
      "         [-0.0588,  0.1312,  0.0142, -0.0829,  0.0690],\n",
      "         [-0.2452,  0.2154,  0.2231, -0.0567,  0.0388],\n",
      "         [-0.2942,  0.0051,  0.2152,  0.0181,  0.0607],\n",
      "         [-0.1972, -0.1108,  0.3036,  0.0130,  0.0827]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1110, -0.0763,  0.0088, -0.0613,  0.1207],\n",
      "         [-0.0487,  0.0278,  0.1285, -0.1800,  0.0304],\n",
      "         [-0.0542,  0.1256,  0.0208, -0.1524,  0.1209],\n",
      "         [-0.1170,  0.0513,  0.1424, -0.0949,  0.0066],\n",
      "         [-0.2060,  0.0933,  0.1715,  0.0362, -0.0130],\n",
      "         [-0.1802,  0.0751,  0.0867,  0.0906, -0.0589],\n",
      "         [-0.1507, -0.0230, -0.0120,  0.0366,  0.0543]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.2903, -0.0176,  0.1562, -0.1680, -0.0055],\n",
      "         [-0.1072,  0.1425,  0.0797, -0.0895,  0.0327],\n",
      "         [-0.2046,  0.1939,  0.1614, -0.0880,  0.0294],\n",
      "         [-0.2244,  0.2377,  0.0875, -0.1187, -0.0166],\n",
      "         [-0.1421,  0.0882,  0.2304, -0.2087,  0.0929],\n",
      "         [-0.2179,  0.0034,  0.2937, -0.2478,  0.0054],\n",
      "         [-0.0883,  0.0232,  0.1792, -0.1211, -0.1593],\n",
      "         [-0.0390,  0.1344,  0.0318, -0.0955,  0.0593],\n",
      "         [-0.2470,  0.2327,  0.2482, -0.0751,  0.0196],\n",
      "         [-0.3056,  0.0109,  0.2574, -0.0012,  0.0455],\n",
      "         [-0.2077, -0.1124,  0.3521, -0.0028,  0.0660]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-1.0740e-01, -7.5998e-02,  1.0238e-02, -6.3312e-02,  1.1822e-01],\n",
      "         [-5.1961e-02,  2.6226e-02,  1.4023e-01, -1.8657e-01,  2.3460e-02],\n",
      "         [-5.2332e-02,  1.2967e-01,  2.4860e-02, -1.5436e-01,  1.1663e-01],\n",
      "         [-1.1980e-01,  5.5834e-02,  1.5283e-01, -9.9243e-02, -8.5793e-06],\n",
      "         [-2.0610e-01,  1.0049e-01,  1.8430e-01,  2.4865e-02, -2.4282e-02],\n",
      "         [-1.8164e-01,  8.2339e-02,  9.3394e-02,  8.5102e-02, -6.5430e-02],\n",
      "         [-1.4815e-01, -2.0915e-02, -6.7356e-03,  3.2134e-02,  4.9501e-02]]],\n",
      "       device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-2.7608e-01, -9.3125e-03,  1.5258e-01, -1.7527e-01, -1.1473e-02],\n",
      "         [-1.0872e-01,  1.6845e-01,  8.8016e-02, -1.0098e-01,  1.6510e-02],\n",
      "         [-2.0604e-01,  2.2146e-01,  1.6762e-01, -9.4358e-02,  1.5243e-02],\n",
      "         [-2.3027e-01,  2.6626e-01,  9.7012e-02, -1.3203e-01, -3.6169e-02],\n",
      "         [-1.5236e-01,  9.4300e-02,  2.6185e-01, -2.2458e-01,  7.5039e-02],\n",
      "         [-2.3063e-01,  1.1417e-03,  3.3234e-01, -2.6076e-01, -8.6631e-03],\n",
      "         [-9.0614e-02,  1.4114e-02,  2.1292e-01, -1.3523e-01, -1.7166e-01],\n",
      "         [-1.9360e-02,  1.3802e-01,  4.9146e-02, -1.0795e-01,  4.9693e-02],\n",
      "         [-2.4886e-01,  2.5087e-01,  2.7308e-01, -9.3592e-02,  2.6453e-04],\n",
      "         [-3.1754e-01,  1.7162e-02,  2.9969e-01, -2.0476e-02,  3.0145e-02],\n",
      "         [-2.1855e-01, -1.1397e-01,  4.0062e-01, -1.8414e-02,  4.9129e-02]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1037, -0.0758,  0.0116, -0.0652,  0.1159],\n",
      "         [-0.0553,  0.0247,  0.1520, -0.1931,  0.0164],\n",
      "         [-0.0505,  0.1337,  0.0289, -0.1563,  0.1124],\n",
      "         [-0.1226,  0.0603,  0.1633, -0.1036, -0.0067],\n",
      "         [-0.2062,  0.1078,  0.1971,  0.0135, -0.0358],\n",
      "         [-0.1831,  0.0898,  0.0999,  0.0796, -0.0721],\n",
      "         [-0.1455, -0.0188, -0.0016,  0.0277,  0.0447]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-2.6189e-01, -9.4128e-04,  1.4906e-01, -1.8256e-01, -1.7512e-02],\n",
      "         [-1.1013e-01,  1.9479e-01,  9.6077e-02, -1.1258e-01,  9.8243e-05],\n",
      "         [-2.0778e-01,  2.4954e-01,  1.7391e-01, -1.0081e-01,  7.1754e-04],\n",
      "         [-2.3655e-01,  2.9561e-01,  1.0660e-01, -1.4558e-01, -5.6148e-02],\n",
      "         [-1.6310e-01,  1.0063e-01,  2.9373e-01, -2.4061e-01,  5.6900e-02],\n",
      "         [-2.4364e-01, -9.7675e-04,  3.7131e-01, -2.7410e-01, -2.3087e-02],\n",
      "         [-9.3218e-02,  5.2660e-03,  2.4709e-01, -1.4972e-01, -1.8435e-01],\n",
      "         [ 2.6169e-04,  1.4193e-01,  6.6427e-02, -1.2029e-01,  4.0122e-02],\n",
      "         [-2.5090e-01,  2.6988e-01,  2.9773e-01, -1.1214e-01, -1.9451e-02],\n",
      "         [-3.2993e-01,  2.3984e-02,  3.4236e-01, -3.9766e-02,  1.4400e-02],\n",
      "         [-2.2961e-01, -1.1542e-01,  4.4937e-01, -3.3948e-02,  3.2030e-02]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0999, -0.0756,  0.0129, -0.0670,  0.1137],\n",
      "         [-0.0586,  0.0233,  0.1638, -0.1996,  0.0091],\n",
      "         [-0.0488,  0.1376,  0.0329, -0.1582,  0.1082],\n",
      "         [-0.1254,  0.0648,  0.1738, -0.1080, -0.0134],\n",
      "         [-0.2063,  0.1151,  0.2100,  0.0020, -0.0474],\n",
      "         [-0.1845,  0.0975,  0.1062,  0.0740, -0.0790],\n",
      "         [-0.1428, -0.0168,  0.0035,  0.0233,  0.0399]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.2477,  0.0075,  0.1456, -0.1898, -0.0236],\n",
      "         [-0.1114,  0.2216,  0.1040, -0.1243, -0.0166],\n",
      "         [-0.2098,  0.2782,  0.1803, -0.1074, -0.0142],\n",
      "         [-0.2433,  0.3258,  0.1164, -0.1594, -0.0766],\n",
      "         [-0.1744,  0.1073,  0.3262, -0.2569,  0.0384],\n",
      "         [-0.2570, -0.0029,  0.4107, -0.2879, -0.0379],\n",
      "         [-0.0962, -0.0033,  0.2818, -0.1647, -0.1975],\n",
      "         [ 0.0199,  0.1462,  0.0837, -0.1327,  0.0305],\n",
      "         [-0.2531,  0.2898,  0.3223, -0.1309, -0.0396],\n",
      "         [-0.3428,  0.0314,  0.3856, -0.0593, -0.0018],\n",
      "         [-0.2410, -0.1167,  0.4986, -0.0495,  0.0146]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0959, -0.0756,  0.0141, -0.0687,  0.1117],\n",
      "         [-0.0620,  0.0219,  0.1757, -0.2063,  0.0018],\n",
      "         [-0.0471,  0.1416,  0.0369, -0.1601,  0.1039],\n",
      "         [-0.1282,  0.0694,  0.1843, -0.1125, -0.0202],\n",
      "         [-0.2064,  0.1227,  0.2230, -0.0095, -0.0592],\n",
      "         [-0.1859,  0.1056,  0.1125,  0.0683, -0.0859],\n",
      "         [-0.1400, -0.0146,  0.0086,  0.0189,  0.0351]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.2336,  0.0159,  0.1423, -0.1971, -0.0296],\n",
      "         [-0.1126,  0.2488,  0.1117, -0.1363, -0.0335],\n",
      "         [-0.2120,  0.3075,  0.1869, -0.1143, -0.0295],\n",
      "         [-0.2504,  0.3569,  0.1265, -0.1736, -0.0975],\n",
      "         [-0.1862,  0.1143,  0.3594, -0.2736,  0.0195],\n",
      "         [-0.2707, -0.0045,  0.4508, -0.3022, -0.0532],\n",
      "         [-0.0995, -0.0117,  0.3170, -0.1801, -0.2111],\n",
      "         [ 0.0397,  0.1508,  0.1012, -0.1452,  0.0208],\n",
      "         [-0.2554,  0.3105,  0.3469, -0.1499, -0.0603],\n",
      "         [-0.3561,  0.0395,  0.4296, -0.0793, -0.0187],\n",
      "         [-0.2527, -0.1179,  0.5484, -0.0653, -0.0033]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0918, -0.0756,  0.0152, -0.0703,  0.1098],\n",
      "         [-0.0653,  0.0206,  0.1875, -0.2129, -0.0058],\n",
      "         [-0.0454,  0.1455,  0.0408, -0.1621,  0.0997],\n",
      "         [-0.1310,  0.0740,  0.1949, -0.1169, -0.0271],\n",
      "         [-0.2066,  0.1305,  0.2359, -0.0210, -0.0710],\n",
      "         [-0.1873,  0.1140,  0.1186,  0.0627, -0.0930],\n",
      "         [-0.1372, -0.0125,  0.0137,  0.0144,  0.0304]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-2.1955e-01,  2.4439e-02,  1.3903e-01, -2.0440e-01, -3.5735e-02],\n",
      "         [-1.1360e-01,  2.7662e-01,  1.1936e-01, -1.4848e-01, -5.0803e-02],\n",
      "         [-2.1457e-01,  3.3745e-01,  1.9360e-01, -1.2135e-01, -4.5274e-02],\n",
      "         [-2.5795e-01,  3.8902e-01,  1.3685e-01, -1.8814e-01, -1.1910e-01],\n",
      "         [-1.9849e-01,  1.2182e-01,  3.9350e-01, -2.9065e-01,  7.8984e-05],\n",
      "         [-2.8495e-01, -5.7783e-03,  4.9163e-01, -3.1701e-01, -6.9060e-02],\n",
      "         [-1.0314e-01, -1.9703e-02,  3.5300e-01, -1.9617e-01, -2.2524e-01],\n",
      "         [ 5.9611e-02,  1.5578e-01,  1.1884e-01, -1.5803e-01,  1.0880e-02],\n",
      "         [-2.5791e-01,  3.3224e-01,  3.7159e-01, -1.6938e-01, -8.1543e-02],\n",
      "         [-3.6995e-01,  4.8295e-02,  4.7450e-01, -9.9783e-02, -3.6249e-02],\n",
      "         [-2.6477e-01, -1.1877e-01,  5.9899e-01, -8.1428e-02, -2.1704e-02]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0876, -0.0757,  0.0163, -0.0719,  0.1080],\n",
      "         [-0.0686,  0.0194,  0.1994, -0.2197, -0.0134],\n",
      "         [-0.0439,  0.1495,  0.0447, -0.1640,  0.0955],\n",
      "         [-0.1339,  0.0788,  0.2054, -0.1214, -0.0340],\n",
      "         [-0.2068,  0.1385,  0.2489, -0.0326, -0.0830],\n",
      "         [-0.1888,  0.1228,  0.1246,  0.0570, -0.1003],\n",
      "         [-0.1343, -0.0102,  0.0187,  0.0100,  0.0256]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 17. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 1.1498440504074097"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.2055,  0.0330,  0.1358, -0.2117, -0.0419],\n",
      "         [-0.1146,  0.3050,  0.1270, -0.1609, -0.0685],\n",
      "         [-0.2174,  0.3682,  0.2005, -0.1287, -0.0615],\n",
      "         [-0.2659,  0.4222,  0.1476, -0.2032, -0.1413],\n",
      "         [-0.2114,  0.1298,  0.4285, -0.3082, -0.0199],\n",
      "         [-0.2997, -0.0067,  0.5334, -0.3325, -0.0855],\n",
      "         [-0.1073, -0.0274,  0.3898, -0.2129, -0.2400],\n",
      "         [ 0.0797,  0.1612,  0.1368, -0.1711,  0.0008],\n",
      "         [-0.2606,  0.3549,  0.3965, -0.1893, -0.1035],\n",
      "         [-0.3843,  0.0578,  0.5206, -0.1210, -0.0546],\n",
      "         [-0.2773, -0.1194,  0.6506, -0.0980, -0.0408]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0833, -0.0758,  0.0173, -0.0734,  0.1063],\n",
      "         [-0.0720,  0.0183,  0.2113, -0.2265, -0.0212],\n",
      "         [-0.0423,  0.1534,  0.0486, -0.1658,  0.0914],\n",
      "         [-0.1369,  0.0838,  0.2160, -0.1259, -0.0410],\n",
      "         [-0.2070,  0.1469,  0.2619, -0.0441, -0.0952],\n",
      "         [-0.1904,  0.1321,  0.1306,  0.0513, -0.1077],\n",
      "         [-0.1313, -0.0078,  0.0238,  0.0056,  0.0208]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1914,  0.0416,  0.1325, -0.2190, -0.0480],\n",
      "         [-0.1154,  0.3341,  0.1345, -0.1736, -0.0865],\n",
      "         [-0.2205,  0.3999,  0.2077, -0.1364, -0.0783],\n",
      "         [-0.2744,  0.4566,  0.1587, -0.2188, -0.1643],\n",
      "         [-0.2249,  0.1383,  0.4647, -0.3264, -0.0406],\n",
      "         [-0.3151, -0.0073,  0.5763, -0.3486, -0.1025],\n",
      "         [-0.1118, -0.0349,  0.4275, -0.2303, -0.2555],\n",
      "         [ 0.1000,  0.1670,  0.1551, -0.1846, -0.0097],\n",
      "         [-0.2635,  0.3787,  0.4216, -0.2097, -0.1261],\n",
      "         [-0.3993,  0.0681,  0.5679, -0.1430, -0.0738],\n",
      "         [-0.2904, -0.1198,  0.7034, -0.1151, -0.0606]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0789, -0.0760,  0.0182, -0.0747,  0.1048],\n",
      "         [-0.0753,  0.0173,  0.2232, -0.2334, -0.0292],\n",
      "         [-0.0409,  0.1574,  0.0524, -0.1677,  0.0872],\n",
      "         [-0.1399,  0.0890,  0.2267, -0.1305, -0.0482],\n",
      "         [-0.2074,  0.1557,  0.2749, -0.0556, -0.1075],\n",
      "         [-0.1920,  0.1418,  0.1366,  0.0455, -0.1154],\n",
      "         [-0.1284, -0.0053,  0.0288,  0.0011,  0.0160]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1774,  0.0502,  0.1293, -0.2264, -0.0542],\n",
      "         [-0.1163,  0.3639,  0.1420, -0.1866, -0.1050],\n",
      "         [-0.2240,  0.4325,  0.2151, -0.1444, -0.0957],\n",
      "         [-0.2834,  0.4923,  0.1703, -0.2350, -0.1882],\n",
      "         [-0.2391,  0.1474,  0.5020, -0.3452, -0.0620],\n",
      "         [-0.3312, -0.0074,  0.6205, -0.3655, -0.1203],\n",
      "         [-0.1169, -0.0420,  0.4664, -0.2484, -0.2717],\n",
      "         [ 0.1205,  0.1732,  0.1739, -0.1986, -0.0204],\n",
      "         [-0.2666,  0.4035,  0.4470, -0.2307, -0.1496],\n",
      "         [-0.4149,  0.0792,  0.6168, -0.1660, -0.0940],\n",
      "         [-0.3040, -0.1199,  0.7576, -0.1328, -0.0814]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0744, -0.0762,  0.0190, -0.0761,  0.1033],\n",
      "         [-0.0786,  0.0164,  0.2351, -0.2403, -0.0372],\n",
      "         [-0.0395,  0.1614,  0.0562, -0.1696,  0.0830],\n",
      "         [-0.1431,  0.0944,  0.2373, -0.1351, -0.0554],\n",
      "         [-0.2078,  0.1648,  0.2879, -0.0672, -0.1200],\n",
      "         [-0.1937,  0.1521,  0.1426,  0.0396, -0.1232],\n",
      "         [-0.1255, -0.0026,  0.0340, -0.0035,  0.0111]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1633,  0.0589,  0.1259, -0.2337, -0.0604],\n",
      "         [-0.1171,  0.3945,  0.1494, -0.2000, -0.1239],\n",
      "         [-0.2279,  0.4661,  0.2228, -0.1528, -0.1137],\n",
      "         [-0.2928,  0.5293,  0.1824, -0.2518, -0.2129],\n",
      "         [-0.2541,  0.1571,  0.5407, -0.3648, -0.0843],\n",
      "         [-0.3480, -0.0071,  0.6662, -0.3832, -0.1388],\n",
      "         [-0.1226, -0.0488,  0.5064, -0.2675, -0.2888],\n",
      "         [ 0.1411,  0.1799,  0.1932, -0.2131, -0.0316],\n",
      "         [-0.2699,  0.4294,  0.4728, -0.2523, -0.1739],\n",
      "         [-0.4311,  0.0911,  0.6673, -0.1901, -0.1152],\n",
      "         [-0.3182, -0.1196,  0.8134, -0.1514, -0.1031]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-6.9874e-02, -7.6489e-02,  1.9738e-02, -7.7314e-02,  1.0191e-01],\n",
      "         [-8.1982e-02,  1.5499e-02,  2.4691e-01, -2.4735e-01, -4.5454e-02],\n",
      "         [-3.8124e-02,  1.6543e-01,  5.9818e-02, -1.7153e-01,  7.8759e-02],\n",
      "         [-1.4631e-01,  1.0002e-01,  2.4804e-01, -1.3986e-01, -6.2757e-02],\n",
      "         [-2.0841e-01,  1.7444e-01,  3.0088e-01, -7.8829e-02, -1.3279e-01],\n",
      "         [-1.9550e-01,  1.6284e-01,  1.4858e-01,  3.3573e-02, -1.3137e-01],\n",
      "         [-1.2264e-01,  2.0712e-04,  3.9214e-02, -8.0946e-03,  6.1644e-03]]],\n",
      "       device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1493,  0.0677,  0.1225, -0.2411, -0.0667],\n",
      "         [-0.1179,  0.4259,  0.1567, -0.2137, -0.1433],\n",
      "         [-0.2321,  0.5009,  0.2308, -0.1616, -0.1323],\n",
      "         [-0.3029,  0.5678,  0.1950, -0.2693, -0.2386],\n",
      "         [-0.2699,  0.1675,  0.5808, -0.3852, -0.1075],\n",
      "         [-0.3657, -0.0062,  0.7135, -0.4019, -0.1583],\n",
      "         [-0.1289, -0.0553,  0.5478, -0.2875, -0.3068],\n",
      "         [ 0.1619,  0.1871,  0.2132, -0.2282, -0.0434],\n",
      "         [-0.2734,  0.4566,  0.4990, -0.2748, -0.1992],\n",
      "         [-0.4481,  0.1040,  0.7196, -0.2154, -0.1375],\n",
      "         [-0.3331, -0.1191,  0.8709, -0.1709, -0.1259]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0652, -0.0768,  0.0204, -0.0785,  0.1006],\n",
      "         [-0.0853,  0.0147,  0.2587, -0.2544, -0.0538],\n",
      "         [-0.0368,  0.1695,  0.0634, -0.1735,  0.0745],\n",
      "         [-0.1497,  0.1059,  0.2588, -0.1447, -0.0703],\n",
      "         [-0.2091,  0.1845,  0.3138, -0.0905, -0.1458],\n",
      "         [-0.1975,  0.1742,  0.1546,  0.0274, -0.1398],\n",
      "         [-0.1198,  0.0032,  0.0445, -0.0129,  0.0011]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1353,  0.0765,  0.1190, -0.2486, -0.0731],\n",
      "         [-0.1186,  0.4583,  0.1639, -0.2277, -0.1632],\n",
      "         [-0.2368,  0.5369,  0.2390, -0.1710, -0.1517],\n",
      "         [-0.3135,  0.6078,  0.2081, -0.2876, -0.2654],\n",
      "         [-0.2866,  0.1787,  0.6225, -0.4065, -0.1317],\n",
      "         [-0.3843, -0.0049,  0.7625, -0.4215, -0.1787],\n",
      "         [-0.1359, -0.0616,  0.5906, -0.3085, -0.3258],\n",
      "         [ 0.1829,  0.1948,  0.2338, -0.2441, -0.0557],\n",
      "         [-0.2772,  0.4850,  0.5256, -0.2981, -0.2255],\n",
      "         [-0.4657,  0.1177,  0.7737, -0.2421, -0.1611],\n",
      "         [-0.3488, -0.1181,  0.9303, -0.1914, -0.1499]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0605, -0.0772,  0.0209, -0.0796,  0.0994],\n",
      "         [-0.0887,  0.0140,  0.2704, -0.2615, -0.0623],\n",
      "         [-0.0356,  0.1737,  0.0668, -0.1754,  0.0702],\n",
      "         [-0.1531,  0.1121,  0.2696, -0.1496, -0.0780],\n",
      "         [-0.2099,  0.1951,  0.3266, -0.1023, -0.1591],\n",
      "         [-0.1996,  0.1861,  0.1608,  0.0211, -0.1486],\n",
      "         [-0.1171,  0.0064,  0.0500, -0.0178, -0.0042]]], device='cuda:0')\n",
      "Wall time: 6.97 s\n"
     ]
    }
   ],
   "source": [
    "%time _ = seq_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ceee1a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchcrf import CRF\n",
    "\n",
    "class TorchCRFSequenceLabeler(TorchRNNClassifier):\n",
    "\n",
    "    def build_graph(self): # uses this build_graph instead of TorchRNNClassifier.build_graph\n",
    "        print(\"here0\")\n",
    "        rnn = TorchRNNModel(\n",
    "            vocab_size=len(self.vocab),\n",
    "            embedding=self.embedding,\n",
    "            use_embedding=self.use_embedding,\n",
    "            embed_dim=self.embed_dim,\n",
    "            rnn_cell_class=self.rnn_cell_class,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            bidirectional=self.bidirectional,\n",
    "            freeze_embedding=self.freeze_embedding)\n",
    "        print(\"here02\")\n",
    "        model = CRF(num_tags)\n",
    "       # model = TorchSequenceLabeler( # this defines self.model\n",
    "       #     rnn=rnn,\n",
    "       #     output_dim=self.n_classes_)\n",
    "       # self.embed_dim = rnn.embed_dim\n",
    "        return model\n",
    "\n",
    "    def build_dataset(self, X, y=None):\n",
    "        START_TAG = \"<START>\"\n",
    "        STOP_TAG = \"<STOP>\"\n",
    "        X, seq_lengths = self._prepare_sequences(X) # converts tokens into tokenIds\n",
    "        if y is None:\n",
    "            return TorchRNNDataset(X, seq_lengths)\n",
    "        else:\n",
    "            # These are the changes from a regular classifier. All\n",
    "            # concern the fact that our labels are sequences of labels.\n",
    "            self.classes_ = sorted({x for seq in y for x in seq})\n",
    "            self.n_classes_ = len(self.classes_)\n",
    "            class2index = dict(zip(self.classes_, range(2,self.n_classes_+2))) # start at id=2\n",
    "            class2index[STOP_TAG]=0    # add start and stop tags (note: stop needs to be 0 as that is default for padding in collate_fn)\n",
    "            class2index[START_TAG]=1 \n",
    "            print(class2index)\n",
    "            # `y` is a list of tensors of different length. Our Dataset\n",
    "            # class will turn it into a padding tensor for processing.\n",
    "            y = [torch.tensor([class2index[label] for label in seq])\n",
    "                 for seq in y] # converts labels to indices\n",
    "            return TorchRNNDataset(X, seq_lengths, y)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        seq_lengths = [len(ex) for ex in X]\n",
    "        # The base class does the heavy lifting:\n",
    "        preds = self._predict(X)\n",
    "        # Trim to the actual sequence lengths:\n",
    "        preds = [p[: l] for p, l in zip(preds, seq_lengths)]\n",
    "        # Use `softmax`; the model doesn't do this because the loss\n",
    "        # function does it internally.\n",
    "        probs = [torch.softmax(seq, dim=1) for seq in preds]\n",
    "        return probs\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        return [[self.classes_[i] for i in seq.argmax(axis=1)] for seq in probs] # seq.argmax(axis=1) gives index of col that maximizes softmax prob\n",
    "        # see difference vs TorchRNNClassifier.predict\n",
    "\n",
    "    def score(self, X, y):\n",
    "        preds = self.predict(X)\n",
    "        flat_preds = [x for seq in preds for x in seq]\n",
    "        flat_y = [x for seq in y for x in seq]\n",
    "        return utils.safe_macro_f1(flat_y, flat_preds)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f6014b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following converts words to indices and pads sequences\n",
    "seq_mod = TorchCRFSequenceLabeler(\n",
    "    vocab,\n",
    "    early_stopping=True,\n",
    "    eta=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70ec885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [\"the wall street journal reported today that apple corporation made money\".split(),\"georgia tech is a university in georgia\".split()]\n",
    "y_train = [\"B I I I O O O B I O O\".split(),\"B I O O O O B\".split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f43c9772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B': 2, 'I': 3, 'O': 4, '<STOP>': 0, '<START>': 1}\n",
      "tensor([[13, 16, 10,  6,  9, 14, 12,  1,  2,  7,  8],\n",
      "        [ 3, 11,  5,  0, 15,  4,  3,  0,  0,  0,  0]])\n",
      "tensor([11,  7])\n",
      "tensor([[2, 3, 3, 3, 4, 4, 4, 2, 3, 4, 4],\n",
      "        [2, 3, 4, 4, 4, 4, 2, 0, 0, 0, 0]])\n",
      "tensor([11,  7])\n",
      "tensor([[ 0.0457,  0.1530, -0.4757, -1.8821, -0.7765],\n",
      "        [ 2.0242, -0.0865,  0.0981, -1.0373,  1.5748],\n",
      "        [-0.6298,  2.4070,  0.2786,  0.2468,  1.1843],\n",
      "        [-0.7282,  0.4415,  1.1651,  2.0154,  0.2152],\n",
      "        [-0.5242, -1.8034, -1.3083,  0.4533, -0.8696],\n",
      "        [-3.3312, -0.7479,  1.1173,  0.2981,  0.1099],\n",
      "        [-0.6463,  0.4285, -0.0075,  1.6734,  0.0103],\n",
      "        [ 0.9837,  0.8793, -1.4504, -1.1802,  1.3075],\n",
      "        [-1.1628,  0.1196, -0.1631,  0.6614,  1.1899],\n",
      "        [ 0.8165, -0.9135, -0.3538,  0.7639, -0.5890],\n",
      "        [-0.7636,  1.3352,  0.6043, -0.1034, -0.1512]])\n",
      "torch.Size([1, 11])\n",
      "tensor(-23.6227, grad_fn=<SumBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0277,  0.0049,  0.0365, -0.0390, -0.0073],\n",
      "        [-0.0090,  0.0145, -0.0004,  0.0874,  0.0311],\n",
      "        [-0.0372, -0.0604, -0.0168, -0.0431, -0.0320],\n",
      "        [ 0.0048,  0.0596,  0.0544, -0.0978,  0.0620],\n",
      "        [ 0.0279,  0.0949,  0.0660, -0.0911, -0.0951]], requires_grad=True)\n",
      "[[0], [0], [1], [3], [3], [2], [3], [4], [4], [0], [1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasco\\AppData\\Local\\Temp/ipykernel_17200/1289059235.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y=torch.tensor(y[1]).view(1,-1)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "dataset = seq_mod.build_dataset(X_train, y_train) \n",
    "dataloader = seq_mod._build_dataloader(dataset, shuffle=False) \n",
    "num_tags = 5\n",
    "model = CRF(num_tags)\n",
    "for batch_num, batch in enumerate(dataloader, start=1):\n",
    "    x=batch[0]   \n",
    "    print(x)\n",
    "    seq_length=batch[1]\n",
    "    print(seq_length)\n",
    "    y=batch[2] \n",
    "    print(y)\n",
    "    print(seq_length)\n",
    "batch_size=1\n",
    "emissions = torch.randn(batch_size, max(seq_length), num_tags)\n",
    "print(emissions[0])\n",
    "y=torch.tensor(y[1]).view(1,-1)\n",
    "print(y.shape)\n",
    "print(model(emissions,y)) # computes log likelihood\n",
    "#model.decode(emissions)\n",
    "a=model.transitions\n",
    "print(a)\n",
    "print(model.decode(emissions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ed9f4b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.5731, grad_fn=<SumBackward0>)\n",
      "tensor([[[-0.4519, -0.1661]]])\n",
      "tensor([[1]])\n",
      "Parameter containing:\n",
      "tensor([[-0.0941,  0.0600],\n",
      "        [-0.0206,  0.0509]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0515, -0.0441], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0194,  0.0469], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# this is where I matched my first model score (i.e. log likelihood of crf)\n",
    "torch.manual_seed(1)\n",
    "seq_length = 1  # maximum sequence length in a batch\n",
    "batch_size = 1  # number of samples in the batch\n",
    "num_tags=2\n",
    "model = CRF(num_tags,batch_first=True)\n",
    "#emissions = torch.randn(batch_size, seq_length, num_tags)\n",
    "#tags = torch.tensor([[0, 2, 3], [1, 4, 1]], dtype=torch.long)  # (batch_size, seq_length)\n",
    "emissions = torch.randn(1, seq_length, num_tags)\n",
    "\n",
    "tags = torch.tensor([[1]], dtype=torch.long)  \n",
    "print(model(emissions, tags))\n",
    "print(emissions)\n",
    "print(tags)\n",
    "print(model.transitions)\n",
    "print(model.start_transitions)\n",
    "print(model.end_transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "59964b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-8.3568, grad_fn=<SumBackward0>)\n",
      "[[3, 4, 3], [4, 1]]\n",
      "tensor(-2.7487, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# add mask vector so as to not to consider padding part of sequences\n",
    "# e.g. want to mask last zero of 2nd obs\n",
    "torch.manual_seed(1)\n",
    "seq_length = 3  # maximum sequence length in a batch\n",
    "batch_size = 2  # number of samples in the batch\n",
    "num_tags=5\n",
    "model = CRF(num_tags,batch_first=True)\n",
    "emissions = torch.randn(batch_size, seq_length, num_tags)\n",
    "tags = torch.tensor([[1, 2, 3], [1, 4, 0]], dtype=torch.long)  # (batch_size, seq_length)\n",
    "mask = torch.tensor([[1, 1, 1], [1, 1, 0]], dtype=torch.uint8) # i.e. mask 3rd token of 2nd example in batch\n",
    "# 1.\n",
    "print(model(emissions, tags, mask=mask)) # model log likelihood\n",
    "# 2.\n",
    "print(model.decode(emissions,mask=mask)) # most likely tag sequences\n",
    "# 3. inference:\n",
    "tags_test = torch.tensor([[1, 2, 3]], dtype=torch.long)  # (batch_size, seq_length)\n",
    "print(model.forward(emissions[0].unsqueeze(dim=0),tags_test)) # returns log likelihood of test tag sequence (larger no. means more likely)\n",
    "# note: need to use torch array w/ same no. of examples as tags_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "d5c17e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "# note: this isn't exactly correct as training examples are shuffled (esp. max len of the smaller 12 ex batch is != 92)\n",
    "auxMax=0\n",
    "x_max_idx=108\n",
    "for i in range(0,min(len(X_train),x_max_idx)):\n",
    "    if len(X_train[i])>auxMax:\n",
    "        auxMax=len(X_train[i])\n",
    "print(auxMax)\n",
    "auxMax2=0\n",
    "x_min_idx=109\n",
    "for i in range(max(0,x_min_idx),len(X_train)):\n",
    "    if len(X_train[i])>auxMax2:\n",
    "        auxMax2=len(X_train[i])\n",
    "print(auxMax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cfe2a431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ORT', 'O', 'O', 'STRASSE', 'STRASSE', 'O', 'ORT', 'O', 'O', 'FLAECHE', 'O', 'O', 'IMMO_TYP', 'O', 'O', 'O', 'O', 'QMPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'VERKAEUFER', 'O', 'O', 'O', 'O', 'O', 'GESAMTPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERTRAG', 'DATUM_VERTRAG', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERBUECHERUNG', 'DATUM_VERBUECHERUNG', 'O']\n",
      "['KAEUFER', 'KAEUFER', 'O', 'O', 'KAEUFER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'IMMO_TYP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "y_pred = seq_mod.predict(X_test)\n",
    "print(y_test[0])\n",
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2960fed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=seq_mod.classes_\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d615f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfold all our data - NOTE: this means we don't care about per sentence results. \n",
    "# i.e. each classification is worth same regardless of sentence in which it occurs\n",
    "y_test_unfold = [y for element in y_test for y in element]\n",
    "y_pred_unfold = [y for element in y_pred for y in element]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "99efc2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ORT', 'O', 'O', 'STRASSE', 'STRASSE', 'O', 'ORT', 'O', 'O', 'FLAECHE']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(y_test_unfold[:10])\n",
    "print(y_pred_unfold[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5de61d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert y_test and y_pred into binary formats\n",
    "#from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7f4747c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                  O      0.808     0.888     0.846       643\n",
      "            KAEUFER      0.070     0.278     0.112        18\n",
      "DATUM_VERBUECHERUNG      0.000     0.000     0.000        25\n",
      "      DATUM_VERTRAG      1.000     0.037     0.071        27\n",
      "         VERKAEUFER      0.333     0.042     0.074        24\n",
      "   TERRASSENGROESSE      0.000     0.000     0.000         5\n",
      "        GESAMTPREIS      0.000     0.000     0.000        11\n",
      "            FLAECHE      0.000     0.000     0.000        15\n",
      "           IMMO_TYP      0.000     0.000     0.000        19\n",
      "            QMPREIS      0.000     0.000     0.000        10\n",
      "                ORT      0.000     0.000     0.000        26\n",
      "            STRASSE      0.118     0.125     0.121        16\n",
      "\n",
      "           accuracy                          0.691       839\n",
      "          macro avg      0.194     0.114     0.102       839\n",
      "       weighted avg      0.664     0.691     0.657       839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(\n",
    "    y_test_unfold, y_pred_unfold, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d9457a",
   "metadata": {},
   "source": [
    "Now try with leading \"B-\" and \"I-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a6f7276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## ONLY RUN IF WE WANT TO ADD LEADING \"B-\" / \"I-\" TO CLASS LABEL\n",
    "# now use above code and loop through all items of annot list:\n",
    "# addLeading=1 for \"Yes\" (i.e. add leading \"B-\",\"I-\" to annot); 0 for \"No\" (i.e. add labels to annot simply as they are)\n",
    "addLeading = 1\n",
    "\n",
    "if addLeading == 1:\n",
    "    for j in range(0,len(annot)):\n",
    "        a = annot[j]\n",
    "        # select list of dict of tokens w/ annnotations and add column w/ no. of words to each dict:\n",
    "        b = a['spans']\n",
    "        # add noWords to b dict. note: b is list of dicts w/ annotations; tokens not on this list don't have annotations\n",
    "        if b!=[]: #i.e. only try to add annotations to tokens if there are annotations to begin with\n",
    "            #print(b)\n",
    "            for i in range(0,len(annot[j]['tokens'])):\n",
    "                    # now break-up label into 1st occurrence (leading \"B-\") and subsequent occurrences (leading \"I-\") (only for non \"O\"'s)\n",
    "                    if annot[j]['tokens'][i]['label'] != \"O\":\n",
    "                        if i==0:\n",
    "                            annot[j]['tokens'][i]['label'] = \"B-\" + annot[j]['tokens'][i]['label']\n",
    "                        else: \n",
    "                            if annot[j]['tokens'][i]['label'] == annot[j]['tokens'][i-1]['label'][2:]: # need to remove the leading \"B-\" that we had already been added to c[i-1]\n",
    "                                annot[j]['tokens'][i]['label'] = \"I-\" + annot[j]['tokens'][i]['label']\n",
    "                            else:\n",
    "                                annot[j]['tokens'][i]['label'] = \"B-\" + annot[j]['tokens'][i]['label'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e6bd88ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get data into format that TorchRNN expects:\n",
    "X=[] \n",
    "y=[]\n",
    "for j in range(0,len(annot)):\n",
    "    a = annot[j]['tokens']\n",
    "    auxX = []\n",
    "    auxy = []\n",
    "    if annot[j]['spans']!=[]: # are there annot for this example?\n",
    "        for i in range(0,len(a)):\n",
    "            #token_element = (a[i]['text'],a[i]['label'])\n",
    "            auxX.append(a[i]['text'])\n",
    "            auxy.append(a[i]['label'])\n",
    "        X.append(auxX)\n",
    "        y.append(auxy)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_train, X_test, y_train, y_test = X[:120], X[120:], y[:120], y[120:]\n",
    "vocab = sorted({w for seq in X_train for w in seq}) + [\"$UNK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "353255ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DORNBIRN', 'In', 'der', 'Schulgasse', 'in', 'Dornbirn', 'hat', 'eine', '71,93', 'Quadratmeter', 'große', 'Wohnung', 'für', 'einen', 'Quadratmeterpreis', 'von', '5533,71', 'Euro', 'den', 'Besitzer', 'gewechselt', '.', 'Dieser', 'beinhaltet', 'auch', 'einen', 'Pkw-Abstellplatz', '.', 'Käufer', 'der', 'Wohnung', 'mit', '9,86', 'Quadratmetern', 'Terrasse', 'ist', 'die', 'ValLiLean', 'Beteiligungs-', 'und', 'Immobilienverwaltungs', 'GmbH', 'Beim', 'Verkäufer', 'handelt', 'es', 'sich', 'um', 'die', 'Karrenblick', 'Projekt', 'GmbH', ' ', 'Der', 'Kaufpreis', 'liegt', 'bei', '398.040', 'Euro', '.', 'Unterzeichnet', 'wurde', 'der', 'Kaufvertrag', 'am', '18.', 'September', '.', 'Die', 'Verbücherung', 'datiert', 'mit', 'Oktober', '2020', '.', '.', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "071c6a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 35. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 2.249159574508667"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.78 s\n",
      "['B-ORT', 'O', 'O', 'B-STRASSE', 'I-STRASSE', 'O', 'B-ORT', 'O', 'O', 'B-FLAECHE', 'O', 'O', 'B-IMMO_TYP', 'O', 'O', 'O', 'O', 'B-QMPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-VERKAEUFER', 'O', 'O', 'O', 'O', 'O', 'B-GESAMTPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATUM_VERTRAG', 'I-DATUM_VERTRAG', 'O', 'O', 'O', 'O', 'O', 'B-DATUM_VERBUECHERUNG', 'I-DATUM_VERBUECHERUNG', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "%time _ = seq_mod.fit(X_train, y_train)\n",
    "y_pred = seq_mod.predict(X_test)\n",
    "print(y_test[0])\n",
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "92a8a32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=seq_mod.classes_\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b338e92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfold all our data - NOTE: this means we don't care about per sentence results. \n",
    "# i.e. each classification is worth same regardless of sentence in which it occurs\n",
    "y_test_unfold = [y for element in y_test for y in element]\n",
    "y_pred_unfold = [y for element in y_pred for y in element]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "78515133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                    O      0.773     0.988     0.867       643\n",
      "B-DATUM_VERBUECHERUNG      0.000     0.000     0.000        13\n",
      "I-DATUM_VERBUECHERUNG      0.000     0.000     0.000        12\n",
      "      B-DATUM_VERTRAG      0.000     0.000     0.000        13\n",
      "      I-DATUM_VERTRAG      0.000     0.000     0.000        14\n",
      "            B-FLAECHE      0.000     0.000     0.000        15\n",
      "            I-FLAECHE      0.000     0.000     0.000         0\n",
      "        B-GESAMTPREIS      0.000     0.000     0.000        11\n",
      "        I-GESAMTPREIS      0.000     0.000     0.000         0\n",
      "           B-IMMO_TYP      0.000     0.000     0.000        19\n",
      "           I-IMMO_TYP      0.000     0.000     0.000         0\n",
      "            B-KAEUFER      0.000     0.000     0.000        10\n",
      "            I-KAEUFER      0.000     0.000     0.000         8\n",
      "                B-ORT      0.300     0.115     0.167        26\n",
      "            B-QMPREIS      0.000     0.000     0.000        10\n",
      "            I-QMPREIS      0.000     0.000     0.000         0\n",
      "            B-STRASSE      0.000     0.000     0.000        12\n",
      "            I-STRASSE      0.000     0.000     0.000         4\n",
      "   B-TERRASSENGROESSE      0.000     0.000     0.000         5\n",
      "         B-VERKAEUFER      0.000     0.000     0.000        13\n",
      "         I-VERKAEUFER      0.000     0.000     0.000        11\n",
      "\n",
      "            micro avg      0.760     0.760     0.760       839\n",
      "            macro avg      0.051     0.053     0.049       839\n",
      "         weighted avg      0.601     0.760     0.670       839\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasco\\anaconda3\\envs\\xcs224u\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(\n",
    "    y_test_unfold, y_pred_unfold, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0680fd70",
   "metadata": {},
   "source": [
    "Remove \"B-\" and \"I-\" (in case they are present in labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9a2de8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0,len(annot)):\n",
    "    a = annot[j]\n",
    "    b = a['spans']\n",
    "    if b!=[]: #i.e. only try to add annotations to tokens if there are annotations to begin with\n",
    "        for i in range(0,len(annot[j]['tokens'])):\n",
    "                if annot[j]['tokens'][i]['label'] != \"O\":\n",
    "                    if annot[j]['tokens'][i]['label'][:2]==\"B-\" or annot[j]['tokens'][i]['label'][:2]==\"I-\":\n",
    "                        annot[j]['tokens'][i]['label']=annot[j]['tokens'][i]['label'][2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f22b42",
   "metadata": {},
   "source": [
    "Try bi-directional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "147649d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_mod = TorchRNNSequenceLabeler(\n",
    "    vocab,\n",
    "    early_stopping=True,\n",
    "    eta=0.001,\n",
    "    bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "63ca2332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ORT', 'O', 'O', 'STRASSE', 'O', 'ORT', 'O', 'O', 'FLAECHE', 'O', 'O', 'IMMO_TYP', 'O', 'O', 'O', 'O', 'QMPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'TERRASSENGROESSE', 'O', 'O', 'O', 'O', 'KAEUFER', 'KAEUFER', 'KAEUFER', 'KAEUFER', 'KAEUFER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'VERKAEUFER', 'VERKAEUFER', 'VERKAEUFER', 'O', 'O', 'O', 'O', 'O', 'GESAMTPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERTRAG', 'DATUM_VERTRAG', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERBUECHERUNG', 'DATUM_VERBUECHERUNG', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8413a3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 18. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 2.1157665252685547"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.12 s\n"
     ]
    }
   ],
   "source": [
    "%time _ = seq_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8d5884c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ORT', 'O', 'O', 'STRASSE', 'STRASSE', 'O', 'ORT', 'O', 'O', 'FLAECHE', 'O', 'O', 'IMMO_TYP', 'O', 'O', 'O', 'O', 'QMPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'VERKAEUFER', 'O', 'O', 'O', 'O', 'O', 'GESAMTPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERTRAG', 'DATUM_VERTRAG', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERBUECHERUNG', 'DATUM_VERBUECHERUNG', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'IMMO_TYP', 'O', 'O', 'TERRASSENGROESSE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'TERRASSENGROESSE', 'TERRASSENGROESSE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                  O      0.760     0.893     0.821       643\n",
      "            KAEUFER      0.000     0.000     0.000        18\n",
      "DATUM_VERBUECHERUNG      0.000     0.000     0.000        25\n",
      "      DATUM_VERTRAG      0.000     0.000     0.000        27\n",
      "         VERKAEUFER      0.000     0.000     0.000        24\n",
      "   TERRASSENGROESSE      0.000     0.000     0.000         5\n",
      "        GESAMTPREIS      0.000     0.000     0.000        11\n",
      "            FLAECHE      0.000     0.000     0.000        15\n",
      "           IMMO_TYP      0.000     0.000     0.000        19\n",
      "            QMPREIS      0.000     0.000     0.000        10\n",
      "                ORT      0.000     0.000     0.000        26\n",
      "            STRASSE      0.000     0.000     0.000        16\n",
      "\n",
      "           accuracy                          0.684       839\n",
      "          macro avg      0.063     0.074     0.068       839\n",
      "       weighted avg      0.583     0.684     0.629       839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = seq_mod.predict(X_test)\n",
    "print(y_test[0])\n",
    "print(y_pred[0])\n",
    "\n",
    "labels=seq_mod.classes_\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "\n",
    "# unfold all our data - NOTE: this means we don't care about per sentence results. \n",
    "# i.e. each classification is worth same regardless of sentence in which it occurs\n",
    "y_test_unfold = [y for element in y_test for y in element]\n",
    "y_pred_unfold = [y for element in y_pred for y in element]\n",
    "\n",
    "print(classification_report(\n",
    "    y_test_unfold, y_pred_unfold, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195d592b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

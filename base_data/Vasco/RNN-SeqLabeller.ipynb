{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "46bc54ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.metrics import classification_report, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#from torch_model_base import TorchModelBase\n",
    "#from torch_shallow_neural_classifier import TorchShallowNeuralClassifier\n",
    "from torch_rnn_classifier import TorchRNNDataset, TorchRNNClassifier, TorchRNNModel\n",
    "import utils\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "df4daa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refresh torch rnn classifier:\n",
    "import importlib\n",
    "import torch_rnn_classifier\n",
    "importlib.reload(torch_rnn_classifier)\n",
    "from torch_rnn_classifier import TorchRNNDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4c519f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ebc5fbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('annotations2.jsonl') as jsonl_file:\n",
    "    # note: after running data-preprocessing.ipynb this file already has token-level labels\n",
    "    lines = jsonl_file.readlines()\n",
    "annot = [json.loads(line) for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "62fbb470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get data into format that TorchRNN expects:\n",
    "X=[] \n",
    "y=[]\n",
    "for j in range(0,len(annot)):\n",
    "    a = annot[j]['tokens']\n",
    "    auxX = []\n",
    "    auxy = []\n",
    "    if annot[j]['spans']!=[]: # are there annot for this example?\n",
    "        for i in range(0,len(a)):\n",
    "            #token_element = (a[i]['text'],a[i]['label'])\n",
    "            auxX.append(a[i]['text'])\n",
    "            auxy.append(a[i]['label'])\n",
    "        X.append(auxX)\n",
    "        y.append(auxy)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_train, X_test, y_train, y_test = X[:120], X[120:], y[:120], y[120:]\n",
    "vocab = sorted({w for seq in X_train for w in seq}) + [\"$UNK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "b8b5c9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload vsm module\n",
    "import torch_rnn_classifier, torch_model_base\n",
    "import importlib\n",
    "importlib.reload(torch_model_base)\n",
    "importlib.reload(torch_rnn_classifier)\n",
    "from torch_model_base import TorchModelBase\n",
    "from torch_rnn_classifier import TorchRNNClassifier, TorchRNNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "a33711db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchRNNSequenceLabeler(TorchRNNClassifier):\n",
    "\n",
    "    def build_graph(self): # uses this build_graph instead of TorchRNNClassifier.build_graph\n",
    "        print(\"here0\")\n",
    "        rnn = TorchRNNModel(\n",
    "            vocab_size=len(self.vocab),\n",
    "            embedding=self.embedding,\n",
    "            use_embedding=self.use_embedding,\n",
    "            embed_dim=self.embed_dim,\n",
    "            rnn_cell_class=self.rnn_cell_class,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            bidirectional=self.bidirectional,\n",
    "            freeze_embedding=self.freeze_embedding)\n",
    "        print(\"here02\")\n",
    "        model = TorchSequenceLabeler( # this defines self.model\n",
    "            rnn=rnn,\n",
    "            output_dim=self.n_classes_)\n",
    "        self.embed_dim = rnn.embed_dim\n",
    "        return model\n",
    "\n",
    "    def build_dataset(self, X, y=None):\n",
    "        START_TAG = \"<START>\"\n",
    "        STOP_TAG = \"<STOP>\"\n",
    "        X, seq_lengths = self._prepare_sequences(X) # converts tokens into tokenIds\n",
    "        if y is None:\n",
    "            return TorchRNNDataset(X, seq_lengths)\n",
    "        else:\n",
    "            # These are the changes from a regular classifier. All\n",
    "            # concern the fact that our labels are sequences of labels.\n",
    "            self.classes_ = sorted({x for seq in y for x in seq})\n",
    "            self.classes_.append(START_TAG) # add start and stop tags\n",
    "            self.classes_.append(STOP_TAG)\n",
    "            self.n_classes_ = len(self.classes_)\n",
    "            class2index = dict(zip(self.classes_, range(self.n_classes_)))\n",
    "            # `y` is a list of tensors of different length. Our Dataset\n",
    "            # class will turn it into a padding tensor for processing.\n",
    "            y = [torch.tensor([class2index[label] for label in seq])\n",
    "                 for seq in y] # converts labels to indices\n",
    "            return TorchRNNDataset(X, seq_lengths, y)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        seq_lengths = [len(ex) for ex in X]\n",
    "        # The base class does the heavy lifting:\n",
    "        preds = self._predict(X)\n",
    "        # Trim to the actual sequence lengths:\n",
    "        preds = [p[: l] for p, l in zip(preds, seq_lengths)]\n",
    "        # Use `softmax`; the model doesn't do this because the loss\n",
    "        # function does it internally.\n",
    "        probs = [torch.softmax(seq, dim=1) for seq in preds]\n",
    "        return probs\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        return [[self.classes_[i] for i in seq.argmax(axis=1)] for seq in probs] # seq.argmax(axis=1) gives index of col that maximizes softmax prob\n",
    "        # see difference vs TorchRNNClassifier.predict\n",
    "\n",
    "    def score(self, X, y):\n",
    "        preds = self.predict(X)\n",
    "        flat_preds = [x for seq in preds for x in seq]\n",
    "        flat_y = [x for seq in y for x in seq]\n",
    "        return utils.safe_macro_f1(flat_y, flat_preds)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "class TorchSequenceLabeler(nn.Module): # no self.hidden_layer or self.classifier_activation as TorchRNNClassifierModel\n",
    "    def __init__(self, rnn, output_dim):\n",
    "        print(\"here021\")\n",
    "        super().__init__()\n",
    "        self.rnn = rnn\n",
    "        self.output_dim = output_dim\n",
    "        if self.rnn.bidirectional:\n",
    "            self.classifier_dim = self.rnn.hidden_dim * 2\n",
    "        else:\n",
    "            self.classifier_dim = self.rnn.hidden_dim\n",
    "        self.classifier_layer = nn.Linear(\n",
    "            self.classifier_dim, self.output_dim)\n",
    "\n",
    "    def forward(self, X, seq_lengths): # X is (noExsInBatch,MaxLen)=(108,117), seq_lengths is the number of tokens in each example in each batch\n",
    "        # this is the forward method of self.model\n",
    "        print(\"here2\")\n",
    "        outputs, state = self.rnn(X, seq_lengths) # X is (batchSize, maxLen of exs in batch); outputs is (noTokensInEx,hiddDim), state is ((batch_size,1,hiddDim),(batch_size,1,hiddDim)) = (finalHiddState,finalCellState) \n",
    "        #print(outputs.data.shape)\n",
    "        #print(state[0].data.shape)\n",
    "        #print(state[1].data.shape)\n",
    "        outputs, seq_length = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "            outputs, batch_first=True) # outputs is (batchSize,MaxLen of examples in batch,hidden_dim); seq_length is noTokenInEx for each ex in batch\n",
    "        #print(outputs.data.shape)\n",
    "        #print(seq_length)\n",
    "        logits = self.classifier_layer(outputs) # this is an FCL from hidden_dim to output_dim (NoLabelClasses)\n",
    "        # logits are (108,117,12) or (1,11,5) = (batchSize,MaxLen of examples in batch,noLabelClasses) noLabelClasses include Start + End\n",
    "        # During training, we need to swap the dimensions of logits\n",
    "        # to accommodate `nn.CrossEntropyLoss`:\n",
    "        print(logits)\n",
    "        if self.training:\n",
    "            return logits.transpose(1, 2) # transpose dimensions 1 and 2 w/ each other (3d array) # outputs (108,12,117) or (1,5,11)\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "fe4012cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_mod = TorchRNNSequenceLabeler(\n",
    "    vocab,\n",
    "    early_stopping=True,\n",
    "    eta=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "3fbfe505",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [\"the wall street journal reported today that apple corporation made money\".split(),\"georgia tech is a university in georgia\".split()]\n",
    "y_train = [\"B I I I O O O B I O O\".split(),\"B I O O O O B\".split()]\n",
    "vocab = sorted({w for seq in X_train for w in seq}) + [\"$UNK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "f8f210b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished epoch 10 of 1000; error is 1.4029343128204346"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here00\n",
      "here0\n",
      "here01\n",
      "here02\n",
      "here021\n",
      "batch1\n",
      "torch.Size([1, 11])\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.2399, -0.0224, -0.0213, -0.0005, -0.1509],\n",
      "         [-0.1316, -0.0595, -0.0764,  0.0700, -0.0456],\n",
      "         [-0.2347, -0.0014,  0.0452, -0.0353, -0.1309],\n",
      "         [-0.1426, -0.0207, -0.0946, -0.0184,  0.0561],\n",
      "         [-0.1651, -0.0403, -0.1215, -0.0240, -0.0005],\n",
      "         [-0.2332, -0.0415, -0.0030,  0.0584, -0.0996],\n",
      "         [-0.2050, -0.0167, -0.2476,  0.0387, -0.0482],\n",
      "         [-0.3610, -0.1026, -0.2309, -0.0352,  0.0119],\n",
      "         [-0.2131,  0.0170, -0.2668, -0.0118,  0.0735],\n",
      "         [-0.2191,  0.0600, -0.1574, -0.0023, -0.0059],\n",
      "         [-0.3117,  0.1004, -0.0814, -0.0763, -0.1603]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1854,  0.0020, -0.0929, -0.0867, -0.0215],\n",
      "         [-0.1376,  0.0498, -0.0629,  0.0898, -0.0303],\n",
      "         [-0.1646,  0.0838, -0.0876, -0.0125,  0.0865],\n",
      "         [-0.1216,  0.1102, -0.1367, -0.0865, -0.0619],\n",
      "         [-0.0189,  0.0900, -0.0310, -0.0972, -0.0825],\n",
      "         [-0.0424, -0.0398, -0.0507, -0.1578, -0.0630],\n",
      "         [-0.1124, -0.0400, -0.0707, -0.1460, -0.0469]]], device='cuda:0')\n",
      "batch1\n",
      "torch.Size([1, 11])\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.2219, -0.0151, -0.0296, -0.0074, -0.1558],\n",
      "         [-0.1261, -0.0312, -0.0829,  0.0579, -0.0538],\n",
      "         [-0.2364,  0.0265,  0.0455, -0.0497, -0.1466],\n",
      "         [-0.1462,  0.0082, -0.0795, -0.0323,  0.0403],\n",
      "         [-0.1736, -0.0303, -0.0921, -0.0405, -0.0135],\n",
      "         [-0.2452, -0.0413,  0.0393,  0.0395, -0.1178],\n",
      "         [-0.2061, -0.0206, -0.2083,  0.0185, -0.0638],\n",
      "         [-0.3457, -0.0986, -0.2115, -0.0567, -0.0032],\n",
      "         [-0.2152,  0.0304, -0.2469, -0.0303,  0.0609],\n",
      "         [-0.2281,  0.0642, -0.1232, -0.0225, -0.0225],\n",
      "         [-0.3208,  0.0994, -0.0451, -0.0974, -0.1816]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1835,  0.0062, -0.0950, -0.0868, -0.0221],\n",
      "         [-0.1388,  0.0549, -0.0573,  0.0840, -0.0352],\n",
      "         [-0.1646,  0.0870, -0.0826, -0.0179,  0.0829],\n",
      "         [-0.1243,  0.1142, -0.1349, -0.0889, -0.0628],\n",
      "         [-0.0221,  0.0938, -0.0318, -0.0970, -0.0821],\n",
      "         [-0.0453, -0.0333, -0.0516, -0.1563, -0.0633],\n",
      "         [-0.1140, -0.0327, -0.0737, -0.1444, -0.0464]]], device='cuda:0')\n",
      "batch1\n",
      "torch.Size([1, 11])\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.2041, -0.0078, -0.0381, -0.0138, -0.1607],\n",
      "         [-0.1210, -0.0027, -0.0898,  0.0462, -0.0616],\n",
      "         [-0.2381,  0.0536,  0.0453, -0.0636, -0.1625],\n",
      "         [-0.1502,  0.0368, -0.0649, -0.0456,  0.0248],\n",
      "         [-0.1827, -0.0204, -0.0632, -0.0568, -0.0263],\n",
      "         [-0.2570, -0.0414,  0.0813,  0.0202, -0.1362],\n",
      "         [-0.2073, -0.0241, -0.1694, -0.0024, -0.0796],\n",
      "         [-0.3306, -0.0948, -0.1925, -0.0778, -0.0187],\n",
      "         [-0.2175,  0.0434, -0.2274, -0.0486,  0.0481],\n",
      "         [-0.2372,  0.0680, -0.0898, -0.0423, -0.0390],\n",
      "         [-0.3295,  0.0979, -0.0094, -0.1187, -0.2034]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1816,  0.0105, -0.0970, -0.0868, -0.0227],\n",
      "         [-0.1401,  0.0599, -0.0518,  0.0784, -0.0402],\n",
      "         [-0.1646,  0.0900, -0.0776, -0.0233,  0.0791],\n",
      "         [-0.1271,  0.1181, -0.1332, -0.0913, -0.0637],\n",
      "         [-0.0252,  0.0975, -0.0326, -0.0967, -0.0816],\n",
      "         [-0.0482, -0.0269, -0.0525, -0.1548, -0.0634],\n",
      "         [-0.1156, -0.0254, -0.0767, -0.1428, -0.0459]]], device='cuda:0')\n",
      "batch1\n",
      "torch.Size([1, 11])\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1865, -0.0005, -0.0465, -0.0200, -0.1654],\n",
      "         [-0.1161,  0.0255, -0.0968,  0.0349, -0.0691],\n",
      "         [-0.2400,  0.0804,  0.0452, -0.0774, -0.1783],\n",
      "         [-0.1545,  0.0648, -0.0507, -0.0586,  0.0095],\n",
      "         [-0.1919, -0.0111, -0.0345, -0.0732, -0.0391],\n",
      "         [-0.2690, -0.0419,  0.1232,  0.0006, -0.1548],\n",
      "         [-0.2085, -0.0279, -0.1307, -0.0236, -0.0957],\n",
      "         [-0.3160, -0.0914, -0.1737, -0.0987, -0.0343],\n",
      "         [-0.2198,  0.0558, -0.2081, -0.0666,  0.0350],\n",
      "         [-0.2465,  0.0714, -0.0567, -0.0619, -0.0556],\n",
      "         [-0.3384,  0.0959,  0.0263, -0.1400, -0.2256]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1796,  0.0147, -0.0990, -0.0868, -0.0233],\n",
      "         [-0.1414,  0.0648, -0.0464,  0.0730, -0.0452],\n",
      "         [-0.1647,  0.0927, -0.0726, -0.0286,  0.0752],\n",
      "         [-0.1300,  0.1220, -0.1318, -0.0937, -0.0646],\n",
      "         [-0.0284,  0.1012, -0.0334, -0.0963, -0.0811],\n",
      "         [-0.0511, -0.0206, -0.0533, -0.1532, -0.0635],\n",
      "         [-0.1171, -0.0183, -0.0796, -0.1410, -0.0453]]], device='cuda:0')\n",
      "batch1\n",
      "torch.Size([1, 11])\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1691,  0.0069, -0.0548, -0.0259, -0.1701],\n",
      "         [-0.1115,  0.0536, -0.1038,  0.0239, -0.0764],\n",
      "         [-0.2422,  0.1069,  0.0454, -0.0911, -0.1942],\n",
      "         [-0.1593,  0.0922, -0.0370, -0.0713, -0.0059],\n",
      "         [-0.2015, -0.0023, -0.0060, -0.0897, -0.0520],\n",
      "         [-0.2813, -0.0431,  0.1653, -0.0193, -0.1736],\n",
      "         [-0.2098, -0.0323, -0.0920, -0.0449, -0.1119],\n",
      "         [-0.3017, -0.0886, -0.1550, -0.1196, -0.0503],\n",
      "         [-0.2224,  0.0676, -0.1892, -0.0844,  0.0217],\n",
      "         [-0.2559,  0.0742, -0.0239, -0.0813, -0.0724],\n",
      "         [-0.3473,  0.0934,  0.0618, -0.1614, -0.2479]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1777,  0.0189, -0.1011, -0.0867, -0.0238],\n",
      "         [-0.1428,  0.0696, -0.0411,  0.0678, -0.0501],\n",
      "         [-0.1649,  0.0949, -0.0675, -0.0340,  0.0712],\n",
      "         [-0.1329,  0.1259, -0.1306, -0.0962, -0.0655],\n",
      "         [-0.0316,  0.1046, -0.0341, -0.0959, -0.0806],\n",
      "         [-0.0539, -0.0143, -0.0540, -0.1516, -0.0637],\n",
      "         [-0.1186, -0.0112, -0.0825, -0.1391, -0.0447]]], device='cuda:0')\n",
      "batch1\n",
      "torch.Size([1, 11])\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1520,  0.0144, -0.0628, -0.0316, -0.1747],\n",
      "         [-0.1072,  0.0816, -0.1109,  0.0133, -0.0836],\n",
      "         [-0.2448,  0.1331,  0.0457, -0.1047, -0.2102],\n",
      "         [-0.1646,  0.1192, -0.0235, -0.0839, -0.0213],\n",
      "         [-0.2114,  0.0058,  0.0225, -0.1064, -0.0652],\n",
      "         [-0.2939, -0.0449,  0.2076, -0.0395, -0.1928],\n",
      "         [-0.2112, -0.0373, -0.0532, -0.0664, -0.1284],\n",
      "         [-0.2878, -0.0865, -0.1363, -0.1404, -0.0666],\n",
      "         [-0.2251,  0.0789, -0.1704, -0.1021,  0.0083],\n",
      "         [-0.2655,  0.0765,  0.0088, -0.1008, -0.0895],\n",
      "         [-0.3566,  0.0904,  0.0972, -0.1828, -0.2705]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1757,  0.0230, -0.1033, -0.0865, -0.0243],\n",
      "         [-0.1444,  0.0741, -0.0360,  0.0629, -0.0549],\n",
      "         [-0.1650,  0.0967, -0.0622, -0.0394,  0.0671],\n",
      "         [-0.1358,  0.1298, -0.1297, -0.0987, -0.0664],\n",
      "         [-0.0348,  0.1079, -0.0348, -0.0955, -0.0800],\n",
      "         [-0.0567, -0.0082, -0.0546, -0.1501, -0.0640],\n",
      "         [-0.1200, -0.0042, -0.0854, -0.1373, -0.0442]]], device='cuda:0')\n",
      "batch1\n",
      "torch.Size([1, 11])\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1351,  0.0221, -0.0705, -0.0372, -0.1793],\n",
      "         [-0.1032,  0.1095, -0.1180,  0.0028, -0.0907],\n",
      "         [-0.2479,  0.1593,  0.0463, -0.1184, -0.2263],\n",
      "         [-0.1706,  0.1459, -0.0103, -0.0966, -0.0370],\n",
      "         [-0.2217,  0.0135,  0.0512, -0.1235, -0.0788],\n",
      "         [-0.3069, -0.0472,  0.2505, -0.0602, -0.2125],\n",
      "         [-0.2128, -0.0428, -0.0140, -0.0884, -0.1453],\n",
      "         [-0.2743, -0.0849, -0.1175, -0.1614, -0.0833],\n",
      "         [-0.2282,  0.0896, -0.1518, -0.1198, -0.0055],\n",
      "         [-0.2754,  0.0782,  0.0416, -0.1204, -0.1069],\n",
      "         [-0.3661,  0.0870,  0.1325, -0.2045, -0.2933]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1736,  0.0271, -0.1055, -0.0862, -0.0247],\n",
      "         [-0.1459,  0.0785, -0.0309,  0.0581, -0.0595],\n",
      "         [-0.1651,  0.0981, -0.0569, -0.0449,  0.0629],\n",
      "         [-0.1385,  0.1337, -0.1289, -0.1012, -0.0674],\n",
      "         [-0.0379,  0.1109, -0.0355, -0.0951, -0.0793],\n",
      "         [-0.0595, -0.0021, -0.0551, -0.1488, -0.0643],\n",
      "         [-0.1213,  0.0027, -0.0882, -0.1354, -0.0436]]], device='cuda:0')\n",
      "batch1\n",
      "torch.Size([1, 11])\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1183,  0.0298, -0.0782, -0.0426, -0.1839],\n",
      "         [-0.0997,  0.1373, -0.1251, -0.0074, -0.0977],\n",
      "         [-0.2513,  0.1855,  0.0471, -0.1322, -0.2426],\n",
      "         [-0.1770,  0.1723,  0.0027, -0.1095, -0.0530],\n",
      "         [-0.2325,  0.0208,  0.0802, -0.1411, -0.0928],\n",
      "         [-0.3204, -0.0499,  0.2940, -0.0815, -0.2326],\n",
      "         [-0.2147, -0.0489,  0.0256, -0.1108, -0.1627],\n",
      "         [-0.2611, -0.0840, -0.0984, -0.1825, -0.1006],\n",
      "         [-0.2316,  0.0999, -0.1332, -0.1378, -0.0196],\n",
      "         [-0.2857,  0.0795,  0.0745, -0.1404, -0.1248],\n",
      "         [-0.3759,  0.0831,  0.1680, -0.2264, -0.3164]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1716,  0.0312, -0.1078, -0.0859, -0.0250],\n",
      "         [-0.1475,  0.0826, -0.0258,  0.0535, -0.0640],\n",
      "         [-0.1651,  0.0991, -0.0514, -0.0503,  0.0587],\n",
      "         [-0.1411,  0.1376, -0.1281, -0.1038, -0.0683],\n",
      "         [-0.0409,  0.1136, -0.0360, -0.0947, -0.0787],\n",
      "         [-0.0622,  0.0040, -0.0555, -0.1476, -0.0647],\n",
      "         [-0.1226,  0.0095, -0.0911, -0.1337, -0.0430]]], device='cuda:0')\n",
      "batch1\n",
      "torch.Size([1, 11])\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1017,  0.0377, -0.0857, -0.0479, -0.1884],\n",
      "         [-0.0965,  0.1652, -0.1323, -0.0176, -0.1048],\n",
      "         [-0.2551,  0.2119,  0.0479, -0.1461, -0.2590],\n",
      "         [-0.1840,  0.1986,  0.0155, -0.1227, -0.0694],\n",
      "         [-0.2438,  0.0277,  0.1094, -0.1594, -0.1074],\n",
      "         [-0.3343, -0.0531,  0.3381, -0.1035, -0.2532],\n",
      "         [-0.2169, -0.0555,  0.0658, -0.1338, -0.1808],\n",
      "         [-0.2484, -0.0837, -0.0789, -0.2041, -0.1185],\n",
      "         [-0.2353,  0.1097, -0.1144, -0.1561, -0.0342],\n",
      "         [-0.2964,  0.0803,  0.1078, -0.1609, -0.1432],\n",
      "         [-0.3861,  0.0788,  0.2039, -0.2488, -0.3399]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1697,  0.0352, -0.1102, -0.0856, -0.0252],\n",
      "         [-0.1490,  0.0866, -0.0206,  0.0491, -0.0684],\n",
      "         [-0.1651,  0.0998, -0.0457, -0.0557,  0.0545],\n",
      "         [-0.1436,  0.1414, -0.1275, -0.1064, -0.0692],\n",
      "         [-0.0438,  0.1162, -0.0364, -0.0944, -0.0780],\n",
      "         [-0.0649,  0.0101, -0.0559, -0.1466, -0.0652],\n",
      "         [-0.1239,  0.0163, -0.0939, -0.1320, -0.0423]]], device='cuda:0')\n",
      "batch1\n",
      "torch.Size([1, 11])\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0852,  0.0457, -0.0931, -0.0530, -0.1930],\n",
      "         [-0.0936,  0.1932, -0.1395, -0.0277, -0.1119],\n",
      "         [-0.2591,  0.2386,  0.0489, -0.1604, -0.2757],\n",
      "         [-0.1915,  0.2248,  0.0281, -0.1363, -0.0863],\n",
      "         [-0.2556,  0.0344,  0.1392, -0.1783, -0.1226],\n",
      "         [-0.3489, -0.0566,  0.3831, -0.1262, -0.2744],\n",
      "         [-0.2196, -0.0626,  0.1067, -0.1574, -0.1996],\n",
      "         [-0.2360, -0.0841, -0.0590, -0.2261, -0.1371],\n",
      "         [-0.2395,  0.1192, -0.0955, -0.1748, -0.0494],\n",
      "         [-0.3076,  0.0806,  0.1416, -0.1821, -0.1623],\n",
      "         [-0.3967,  0.0741,  0.2402, -0.2717, -0.3637]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1677,  0.0392, -0.1126, -0.0852, -0.0253],\n",
      "         [-0.1506,  0.0904, -0.0154,  0.0447, -0.0727],\n",
      "         [-0.1650,  0.1001, -0.0400, -0.0612,  0.0502],\n",
      "         [-0.1459,  0.1451, -0.1269, -0.1090, -0.0701],\n",
      "         [-0.0465,  0.1185, -0.0366, -0.0941, -0.0773],\n",
      "         [-0.0675,  0.0161, -0.0561, -0.1458, -0.0658],\n",
      "         [-0.1252,  0.0231, -0.0966, -0.1305, -0.0417]]], device='cuda:0')\n",
      "batch1\n",
      "torch.Size([1, 11])\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0688,  0.0537, -0.1006, -0.0580, -0.1977],\n",
      "         [-0.0911,  0.2212, -0.1467, -0.0377, -0.1191],\n",
      "         [-0.2635,  0.2657,  0.0499, -0.1749, -0.2927],\n",
      "         [-0.1996,  0.2511,  0.0406, -0.1505, -0.1036],\n",
      "         [-0.2679,  0.0408,  0.1695, -0.1981, -0.1385],\n",
      "         [-0.3641, -0.0605,  0.4291, -0.1498, -0.2962],\n",
      "         [-0.2228, -0.0701,  0.1485, -0.1817, -0.2191],\n",
      "         [-0.2241, -0.0850, -0.0385, -0.2487, -0.1565],\n",
      "         [-0.2441,  0.1283, -0.0764, -0.1941, -0.0653],\n",
      "         [-0.3193,  0.0806,  0.1760, -0.2040, -0.1821],\n",
      "         [-0.4077,  0.0690,  0.2772, -0.2952, -0.3881]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 16. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 1.2363581657409668"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1657,  0.0433, -0.1151, -0.0848, -0.0254],\n",
      "         [-0.1522,  0.0940, -0.0102,  0.0404, -0.0769],\n",
      "         [-0.1649,  0.1002, -0.0340, -0.0667,  0.0458],\n",
      "         [-0.1481,  0.1489, -0.1262, -0.1117, -0.0711],\n",
      "         [-0.0491,  0.1208, -0.0368, -0.0939, -0.0767],\n",
      "         [-0.0702,  0.0222, -0.0563, -0.1452, -0.0665],\n",
      "         [-0.1264,  0.0298, -0.0993, -0.1290, -0.0411]]], device='cuda:0')\n",
      "batch1\n",
      "torch.Size([1, 11])\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0524,  0.0618, -0.1080, -0.0629, -0.2023],\n",
      "         [-0.0888,  0.2494, -0.1540, -0.0477, -0.1265],\n",
      "         [-0.2681,  0.2933,  0.0510, -0.1898, -0.3100],\n",
      "         [-0.2082,  0.2775,  0.0531, -0.1654, -0.1216],\n",
      "         [-0.2808,  0.0470,  0.2006, -0.2187, -0.1552],\n",
      "         [-0.3800, -0.0648,  0.4761, -0.1742, -0.3187],\n",
      "         [-0.2266, -0.0780,  0.1913, -0.2067, -0.2396],\n",
      "         [-0.2126, -0.0865, -0.0172, -0.2720, -0.1767],\n",
      "         [-0.2493,  0.1371, -0.0568, -0.2142, -0.0819],\n",
      "         [-0.3318,  0.0801,  0.2113, -0.2268, -0.2027],\n",
      "         [-0.4194,  0.0634,  0.3150, -0.3196, -0.4130]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1638,  0.0473, -0.1176, -0.0844, -0.0254],\n",
      "         [-0.1538,  0.0975, -0.0050,  0.0362, -0.0810],\n",
      "         [-0.1649,  0.1001, -0.0279, -0.0722,  0.0413],\n",
      "         [-0.1502,  0.1525, -0.1256, -0.1144, -0.0721],\n",
      "         [-0.0516,  0.1229, -0.0367, -0.0938, -0.0762],\n",
      "         [-0.0729,  0.0284, -0.0563, -0.1448, -0.0673],\n",
      "         [-0.1277,  0.0366, -0.1018, -0.1278, -0.0406]]], device='cuda:0')\n",
      "batch1\n",
      "torch.Size([1, 11])\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0360,  0.0699, -0.1154, -0.0675, -0.2071],\n",
      "         [-0.0868,  0.2777, -0.1612, -0.0577, -0.1340],\n",
      "         [-0.2730,  0.3214,  0.0523, -0.2051, -0.3277],\n",
      "         [-0.2174,  0.3041,  0.0655, -0.1811, -0.1403],\n",
      "         [-0.2944,  0.0531,  0.2324, -0.2404, -0.1729],\n",
      "         [-0.3968, -0.0696,  0.5243, -0.1997, -0.3420],\n",
      "         [-0.2311, -0.0864,  0.2352, -0.2327, -0.2611],\n",
      "         [-0.2015, -0.0886,  0.0048, -0.2961, -0.1980],\n",
      "         [-0.2551,  0.1455, -0.0368, -0.2351, -0.0994],\n",
      "         [-0.3451,  0.0793,  0.2475, -0.2507, -0.2243],\n",
      "         [-0.4317,  0.0574,  0.3538, -0.3449, -0.4387]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1618,  0.0514, -0.1202, -0.0840, -0.0253],\n",
      "         [-0.1554,  0.1008,  0.0002,  0.0320, -0.0851],\n",
      "         [-0.1648,  0.0998, -0.0217, -0.0777,  0.0368],\n",
      "         [-0.1522,  0.1561, -0.1249, -0.1171, -0.0731],\n",
      "         [-0.0541,  0.1249, -0.0365, -0.0938, -0.0758],\n",
      "         [-0.0755,  0.0345, -0.0561, -0.1446, -0.0683],\n",
      "         [-0.1289,  0.0433, -0.1042, -0.1267, -0.0401]]], device='cuda:0')\n",
      "batch1\n",
      "torch.Size([1, 11])\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0195,  0.0780, -0.1228, -0.0721, -0.2118],\n",
      "         [-0.0850,  0.3062, -0.1685, -0.0678, -0.1417],\n",
      "         [-0.2782,  0.3502,  0.0536, -0.2208, -0.3458],\n",
      "         [-0.2272,  0.3310,  0.0779, -0.1977, -0.1598],\n",
      "         [-0.3087,  0.0590,  0.2652, -0.2632, -0.1915],\n",
      "         [-0.4146, -0.0747,  0.5738, -0.2262, -0.3662],\n",
      "         [-0.2363, -0.0953,  0.2805, -0.2595, -0.2836],\n",
      "         [-0.1908, -0.0911,  0.0277, -0.3211, -0.2203],\n",
      "         [-0.2615,  0.1538, -0.0161, -0.2571, -0.1179],\n",
      "         [-0.3592,  0.0782,  0.2850, -0.2757, -0.2470],\n",
      "         [-0.4447,  0.0510,  0.3936, -0.3712, -0.4650]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1599,  0.0554, -0.1227, -0.0836, -0.0251],\n",
      "         [-0.1571,  0.1040,  0.0054,  0.0279, -0.0892],\n",
      "         [-0.1648,  0.0993, -0.0152, -0.0833,  0.0322],\n",
      "         [-0.1541,  0.1597, -0.1242, -0.1198, -0.0742],\n",
      "         [-0.0564,  0.1268, -0.0362, -0.0940, -0.0756],\n",
      "         [-0.0782,  0.0408, -0.0558, -0.1447, -0.0694],\n",
      "         [-0.1301,  0.0501, -0.1065, -0.1257, -0.0397]]], device='cuda:0')\n",
      "batch1\n",
      "torch.Size([1, 11])\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0031,  0.0860, -0.1303, -0.0764, -0.2166],\n",
      "         [-0.0835,  0.3350, -0.1759, -0.0780, -0.1496],\n",
      "         [-0.2837,  0.3797,  0.0551, -0.2371, -0.3645],\n",
      "         [-0.2377,  0.3582,  0.0903, -0.2152, -0.1802],\n",
      "         [-0.3239,  0.0648,  0.2991, -0.2872, -0.2113],\n",
      "         [-0.4334, -0.0802,  0.6248, -0.2539, -0.3913],\n",
      "         [-0.2424, -0.1045,  0.3272, -0.2875, -0.3074],\n",
      "         [-0.1807, -0.0942,  0.0517, -0.3472, -0.2439],\n",
      "         [-0.2687,  0.1618,  0.0053, -0.2801, -0.1375],\n",
      "         [-0.3743,  0.0767,  0.3238, -0.3021, -0.2708],\n",
      "         [-0.4584,  0.0442,  0.4347, -0.3987, -0.4923]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1580,  0.0594, -0.1253, -0.0831, -0.0249],\n",
      "         [-0.1588,  0.1071,  0.0106,  0.0239, -0.0933],\n",
      "         [-0.1649,  0.0987, -0.0086, -0.0888,  0.0276],\n",
      "         [-0.1560,  0.1633, -0.1233, -0.1227, -0.0753],\n",
      "         [-0.0588,  0.1288, -0.0356, -0.0943, -0.0754],\n",
      "         [-0.0809,  0.0471, -0.0554, -0.1450, -0.0707],\n",
      "         [-0.1314,  0.0568, -0.1086, -0.1250, -0.0393]]], device='cuda:0')\n",
      "batch1\n",
      "torch.Size([1, 11])\n",
      "here2\n",
      "here21\n",
      "tensor([[[ 0.0134,  0.0941, -0.1379, -0.0807, -0.2215],\n",
      "         [-0.0823,  0.3639, -0.1832, -0.0882, -0.1577],\n",
      "         [-0.2894,  0.4100,  0.0568, -0.2539, -0.3836],\n",
      "         [-0.2489,  0.3859,  0.1030, -0.2337, -0.2015],\n",
      "         [-0.3399,  0.0705,  0.3343, -0.3125, -0.2322],\n",
      "         [-0.4533, -0.0860,  0.6773, -0.2828, -0.4174],\n",
      "         [-0.2494, -0.1143,  0.3755, -0.3166, -0.3324],\n",
      "         [-0.1710, -0.0976,  0.0768, -0.3745, -0.2686],\n",
      "         [-0.2768,  0.1695,  0.0275, -0.3046, -0.1582],\n",
      "         [-0.3906,  0.0749,  0.3641, -0.3300, -0.2959],\n",
      "         [-0.4731,  0.0369,  0.4773, -0.4275, -0.5205]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1560,  0.0635, -0.1280, -0.0827, -0.0246],\n",
      "         [-0.1606,  0.1101,  0.0158,  0.0199, -0.0974],\n",
      "         [-0.1650,  0.0979, -0.0018, -0.0943,  0.0229],\n",
      "         [-0.1579,  0.1668, -0.1224, -0.1256, -0.0766],\n",
      "         [-0.0611,  0.1306, -0.0347, -0.0948, -0.0754],\n",
      "         [-0.0836,  0.0535, -0.0547, -0.1455, -0.0722],\n",
      "         [-0.1326,  0.0635, -0.1105, -0.1244, -0.0391]]], device='cuda:0')\n",
      "Wall time: 266 ms\n"
     ]
    }
   ],
   "source": [
    "%time _ = seq_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "ceee1a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchcrf import CRF\n",
    "\n",
    "class TorchCRFSequenceLabeler(TorchRNNClassifier):\n",
    "\n",
    "    def build_graph(self): # uses this build_graph instead of TorchRNNClassifier.build_graph\n",
    "        print(\"here0\")\n",
    "        rnn = TorchRNNModel(\n",
    "            vocab_size=len(self.vocab),\n",
    "            embedding=self.embedding,\n",
    "            use_embedding=self.use_embedding,\n",
    "            embed_dim=self.embed_dim,\n",
    "            rnn_cell_class=self.rnn_cell_class,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            bidirectional=self.bidirectional,\n",
    "            freeze_embedding=self.freeze_embedding)\n",
    "        print(\"here02\")\n",
    "        model = TorchSequenceLabeler( # this defines self.model\n",
    "            rnn=rnn,\n",
    "            output_dim=self.n_classes_)\n",
    "        self.embed_dim = rnn.embed_dim\n",
    "        return model\n",
    "\n",
    "    def build_dataset(self, X, y=None):\n",
    "        START_TAG = \"<START>\"\n",
    "        STOP_TAG = \"<STOP>\"\n",
    "        X, seq_lengths = self._prepare_sequences(X) # converts tokens into tokenIds\n",
    "        if y is None:\n",
    "            return TorchCRFDataset(X, seq_lengths)\n",
    "            #return TorchRNNDataset(X, seq_lengths)\n",
    "        else:\n",
    "            # These are the changes from a regular classifier. All\n",
    "            # concern the fact that our labels are sequences of labels.\n",
    "            self.classes_ = sorted({x for seq in y for x in seq})\n",
    "            self.classes_.append(START_TAG) # add start and stop tags\n",
    "            self.classes_.append(STOP_TAG)\n",
    "            self.n_classes_ = len(self.classes_)\n",
    "            class2index = dict(zip(self.classes_, range(self.n_classes_)))\n",
    "            print(class2index)\n",
    "            # `y` is a list of tensors of different length. Our Dataset\n",
    "            # class will turn it into a padding tensor for processing.\n",
    "            y = [torch.tensor([class2index[label] for label in seq])\n",
    "                 for seq in y] # converts labels to indices\n",
    "            return TorchCRFDataset(X, seq_lengths, y)\n",
    "            #return TorchRNNDataset(X, seq_lengths, y)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        seq_lengths = [len(ex) for ex in X]\n",
    "        # The base class does the heavy lifting:\n",
    "        preds = self._predict(X)\n",
    "        # Trim to the actual sequence lengths:\n",
    "        preds = [p[: l] for p, l in zip(preds, seq_lengths)]\n",
    "        # Use `softmax`; the model doesn't do this because the loss\n",
    "        # function does it internally.\n",
    "        probs = [torch.softmax(seq, dim=1) for seq in preds]\n",
    "        return probs\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        return [[self.classes_[i] for i in seq.argmax(axis=1)] for seq in probs] # seq.argmax(axis=1) gives index of col that maximizes softmax prob\n",
    "        # see difference vs TorchRNNClassifier.predict\n",
    "\n",
    "    def score(self, X, y):\n",
    "        preds = self.predict(X)\n",
    "        flat_preds = [x for seq in preds for x in seq]\n",
    "        flat_y = [x for seq in y for x in seq]\n",
    "        return utils.safe_macro_f1(flat_y, flat_preds)\n",
    "\n",
    "\n",
    "class TorchCRFDataset(TorchRNNDataset):\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        \"\"\"\n",
    "        Format a batch of examples for use in both training and prediction.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : tuple of length 2 (prediction) or 3 (training)\n",
    "            The first element is the list of input sequences. The\n",
    "            second is the list of lengths for those sequences. The third,\n",
    "            where present, is the list of labels.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X : torch.Tensor, shape `(batch_size, max_batch_length)`\n",
    "            As padded by `torch.nn.utils.rnn.pad_sequence.\n",
    "\n",
    "        seq_lengths : torch.LongTensor, shape `(batch_size, )`\n",
    "\n",
    "        y : torch.LongTensor, shape `(batch_size, )`\n",
    "            Only for training. In the case where `y` cannot be turned into\n",
    "            a Tensor, we assume it is because it is a list of variable\n",
    "            length sequences and to use `torch.nn.utils.rnn.pad_sequence`.\n",
    "            The hope is that this will accomodate sequence prediction.\n",
    "\n",
    "        \"\"\"\n",
    "        batch_elements = list(zip(*batch))\n",
    "        X = batch_elements[0]\n",
    "        seq_lengths = batch_elements[1]\n",
    "        X = torch.nn.utils.rnn.pad_sequence(X, batch_first=True)\n",
    "        seq_lengths = torch.tensor(seq_lengths)\n",
    "        if len(batch_elements) == 3:\n",
    "            y = batch_elements[2]\n",
    "            # We can try to accommodate the case where `y` is a sequence\n",
    "            # loss with potentially different lengths by resorting to\n",
    "            # padding if creating a tensor is not possible:\n",
    "            try:\n",
    "                y = torch.tensor(y)\n",
    "            # except ValueError:\n",
    "            except TypeError:\n",
    "                y = torch.nn.utils.rnn.pad_sequence(y, batch_first=True, padding_value=3) # need to pad with STOP tag\n",
    "            return X, seq_lengths, y\n",
    "        else:\n",
    "            return X, seq_lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "f6014b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following converts words to indices and pads sequences\n",
    "seq_mod = TorchCRFSequenceLabeler(\n",
    "    vocab,\n",
    "    early_stopping=True,\n",
    "    eta=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ec885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [\"the wall street journal reported today that apple corporation made money\".split(),\"georgia tech is a university in georgia\".split()]\n",
    "y_train = [\"B I I I O O O B I O O\".split(),\"B I O O O O B\".split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "f43c9772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B': 0, 'I': 1, 'O': 2, '<START>': 3, '<STOP>': 4}\n",
      "tensor([[13, 16, 10,  6,  9, 14, 12,  1,  2,  7,  8],\n",
      "        [ 3, 11,  5,  0, 15,  4,  3,  0,  0,  0,  0]])\n",
      "tensor([[0, 1, 1, 1, 2, 2, 2, 0, 1, 2, 2],\n",
      "        [0, 1, 2, 2, 2, 2, 0, 3, 3, 3, 3]])\n",
      "tensor([11,  7])\n",
      "tensor([[ 1.7674, -0.0954,  0.1394, -1.5785],\n",
      "        [-0.3206, -0.2993,  1.8793, -0.0721],\n",
      "        [ 0.2753,  1.7163, -0.0561,  0.9107],\n",
      "        [-1.3924,  2.6891, -0.1110,  0.2927],\n",
      "        [ 2.0242, -0.0865,  0.0981, -1.2150],\n",
      "        [ 0.7312,  1.1718, -0.9274,  0.5451],\n",
      "        [ 0.2468,  1.1843, -0.7282,  1.1633],\n",
      "        [-0.0091, -0.8425,  0.1374,  0.9386],\n",
      "        [-1.8034, -1.3083,  0.4533,  1.1422],\n",
      "        [ 0.2486, -1.7754, -0.0255, -1.0233],\n",
      "        [ 0.1099, -0.6463,  0.4285,  1.4761]])\n",
      "tensor(-39.0331, grad_fn=<SumBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0139, -0.0122,  0.0277,  0.0049],\n",
      "        [ 0.0365, -0.0390, -0.0073, -0.0090],\n",
      "        [ 0.0145, -0.0004,  0.0874,  0.0311],\n",
      "        [-0.0372, -0.0604, -0.0168, -0.0431]], requires_grad=True)\n",
      "[[0, 1], [2, 3], [1, 1], [1, 3], [0, 2], [1, 2], [3, 3], [3, 0], [3, 3], [0, 1], [3, 1]]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "dataset = seq_mod.build_dataset(X_train, y_train) # not good ... is padding with zeros (=B's)\n",
    "dataloader = seq_mod._build_dataloader(dataset, shuffle=False) \n",
    "num_tags = 4\n",
    "model = CRF(num_tags)\n",
    "for batch_num, batch in enumerate(dataloader, start=1):\n",
    "    x=batch[0]\n",
    "    seq_length=batch[1]\n",
    "    y=batch[2] \n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(seq_length)\n",
    "batch_size=2\n",
    "emissions = torch.randn(batch_size, max(seq_length), num_tags)\n",
    "print(emissions[0])\n",
    "print(model(emissions,y)) # computes log likelihood\n",
    "#model.decode(emissions)\n",
    "a=model.transitions\n",
    "print(a)\n",
    "print(model.decode(emissions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "bdcc06e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6280/2061908090.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#print(tags.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memissions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\xcs224u\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\xcs224u\\lib\\site-packages\\torchcrf\\__init__.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, emissions, tags, mask, reduction)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0mreduction\u001b[0m \u001b[1;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mnone\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0motherwise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \"\"\"\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memissions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'none'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sum'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'token_mean'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'invalid reduction: {reduction}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\xcs224u\\lib\\site-packages\\torchcrf\\__init__.py\u001b[0m in \u001b[0;36m_validate\u001b[1;34m(self, emissions, tags, mask)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtags\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0memissions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m                 raise ValueError(\n\u001b[0;32m    156\u001b[0m                     \u001b[1;34m'the first two dimensions of emissions and tags must match, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "tags = a.sequences\n",
    "#print(tags.shape)\n",
    "model(emissions,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "d5c17e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "# note: this isn't exactly correct as training examples are shuffled (esp. max len of the smaller 12 ex batch is != 92)\n",
    "auxMax=0\n",
    "x_max_idx=108\n",
    "for i in range(0,min(len(X_train),x_max_idx)):\n",
    "    if len(X_train[i])>auxMax:\n",
    "        auxMax=len(X_train[i])\n",
    "print(auxMax)\n",
    "auxMax2=0\n",
    "x_min_idx=109\n",
    "for i in range(max(0,x_min_idx),len(X_train)):\n",
    "    if len(X_train[i])>auxMax2:\n",
    "        auxMax2=len(X_train[i])\n",
    "print(auxMax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cfe2a431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ORT', 'O', 'O', 'STRASSE', 'STRASSE', 'O', 'ORT', 'O', 'O', 'FLAECHE', 'O', 'O', 'IMMO_TYP', 'O', 'O', 'O', 'O', 'QMPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'VERKAEUFER', 'O', 'O', 'O', 'O', 'O', 'GESAMTPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERTRAG', 'DATUM_VERTRAG', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERBUECHERUNG', 'DATUM_VERBUECHERUNG', 'O']\n",
      "['KAEUFER', 'KAEUFER', 'O', 'O', 'KAEUFER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'IMMO_TYP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "y_pred = seq_mod.predict(X_test)\n",
    "print(y_test[0])\n",
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2960fed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=seq_mod.classes_\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d615f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfold all our data - NOTE: this means we don't care about per sentence results. \n",
    "# i.e. each classification is worth same regardless of sentence in which it occurs\n",
    "y_test_unfold = [y for element in y_test for y in element]\n",
    "y_pred_unfold = [y for element in y_pred for y in element]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "99efc2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ORT', 'O', 'O', 'STRASSE', 'STRASSE', 'O', 'ORT', 'O', 'O', 'FLAECHE']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(y_test_unfold[:10])\n",
    "print(y_pred_unfold[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5de61d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert y_test and y_pred into binary formats\n",
    "#from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7f4747c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                  O      0.808     0.888     0.846       643\n",
      "            KAEUFER      0.070     0.278     0.112        18\n",
      "DATUM_VERBUECHERUNG      0.000     0.000     0.000        25\n",
      "      DATUM_VERTRAG      1.000     0.037     0.071        27\n",
      "         VERKAEUFER      0.333     0.042     0.074        24\n",
      "   TERRASSENGROESSE      0.000     0.000     0.000         5\n",
      "        GESAMTPREIS      0.000     0.000     0.000        11\n",
      "            FLAECHE      0.000     0.000     0.000        15\n",
      "           IMMO_TYP      0.000     0.000     0.000        19\n",
      "            QMPREIS      0.000     0.000     0.000        10\n",
      "                ORT      0.000     0.000     0.000        26\n",
      "            STRASSE      0.118     0.125     0.121        16\n",
      "\n",
      "           accuracy                          0.691       839\n",
      "          macro avg      0.194     0.114     0.102       839\n",
      "       weighted avg      0.664     0.691     0.657       839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(\n",
    "    y_test_unfold, y_pred_unfold, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d9457a",
   "metadata": {},
   "source": [
    "Now try with leading \"B-\" and \"I-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a6f7276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## ONLY RUN IF WE WANT TO ADD LEADING \"B-\" / \"I-\" TO CLASS LABEL\n",
    "# now use above code and loop through all items of annot list:\n",
    "# addLeading=1 for \"Yes\" (i.e. add leading \"B-\",\"I-\" to annot); 0 for \"No\" (i.e. add labels to annot simply as they are)\n",
    "addLeading = 1\n",
    "\n",
    "if addLeading == 1:\n",
    "    for j in range(0,len(annot)):\n",
    "        a = annot[j]\n",
    "        # select list of dict of tokens w/ annnotations and add column w/ no. of words to each dict:\n",
    "        b = a['spans']\n",
    "        # add noWords to b dict. note: b is list of dicts w/ annotations; tokens not on this list don't have annotations\n",
    "        if b!=[]: #i.e. only try to add annotations to tokens if there are annotations to begin with\n",
    "            #print(b)\n",
    "            for i in range(0,len(annot[j]['tokens'])):\n",
    "                    # now break-up label into 1st occurrence (leading \"B-\") and subsequent occurrences (leading \"I-\") (only for non \"O\"'s)\n",
    "                    if annot[j]['tokens'][i]['label'] != \"O\":\n",
    "                        if i==0:\n",
    "                            annot[j]['tokens'][i]['label'] = \"B-\" + annot[j]['tokens'][i]['label']\n",
    "                        else: \n",
    "                            if annot[j]['tokens'][i]['label'] == annot[j]['tokens'][i-1]['label'][2:]: # need to remove the leading \"B-\" that we had already been added to c[i-1]\n",
    "                                annot[j]['tokens'][i]['label'] = \"I-\" + annot[j]['tokens'][i]['label']\n",
    "                            else:\n",
    "                                annot[j]['tokens'][i]['label'] = \"B-\" + annot[j]['tokens'][i]['label'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e6bd88ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get data into format that TorchRNN expects:\n",
    "X=[] \n",
    "y=[]\n",
    "for j in range(0,len(annot)):\n",
    "    a = annot[j]['tokens']\n",
    "    auxX = []\n",
    "    auxy = []\n",
    "    if annot[j]['spans']!=[]: # are there annot for this example?\n",
    "        for i in range(0,len(a)):\n",
    "            #token_element = (a[i]['text'],a[i]['label'])\n",
    "            auxX.append(a[i]['text'])\n",
    "            auxy.append(a[i]['label'])\n",
    "        X.append(auxX)\n",
    "        y.append(auxy)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_train, X_test, y_train, y_test = X[:120], X[120:], y[:120], y[120:]\n",
    "vocab = sorted({w for seq in X_train for w in seq}) + [\"$UNK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "353255ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DORNBIRN', 'In', 'der', 'Schulgasse', 'in', 'Dornbirn', 'hat', 'eine', '71,93', 'Quadratmeter', 'große', 'Wohnung', 'für', 'einen', 'Quadratmeterpreis', 'von', '5533,71', 'Euro', 'den', 'Besitzer', 'gewechselt', '.', 'Dieser', 'beinhaltet', 'auch', 'einen', 'Pkw-Abstellplatz', '.', 'Käufer', 'der', 'Wohnung', 'mit', '9,86', 'Quadratmetern', 'Terrasse', 'ist', 'die', 'ValLiLean', 'Beteiligungs-', 'und', 'Immobilienverwaltungs', 'GmbH', 'Beim', 'Verkäufer', 'handelt', 'es', 'sich', 'um', 'die', 'Karrenblick', 'Projekt', 'GmbH', ' ', 'Der', 'Kaufpreis', 'liegt', 'bei', '398.040', 'Euro', '.', 'Unterzeichnet', 'wurde', 'der', 'Kaufvertrag', 'am', '18.', 'September', '.', 'Die', 'Verbücherung', 'datiert', 'mit', 'Oktober', '2020', '.', '.', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "071c6a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 35. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 2.249159574508667"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.78 s\n",
      "['B-ORT', 'O', 'O', 'B-STRASSE', 'I-STRASSE', 'O', 'B-ORT', 'O', 'O', 'B-FLAECHE', 'O', 'O', 'B-IMMO_TYP', 'O', 'O', 'O', 'O', 'B-QMPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-VERKAEUFER', 'O', 'O', 'O', 'O', 'O', 'B-GESAMTPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATUM_VERTRAG', 'I-DATUM_VERTRAG', 'O', 'O', 'O', 'O', 'O', 'B-DATUM_VERBUECHERUNG', 'I-DATUM_VERBUECHERUNG', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "%time _ = seq_mod.fit(X_train, y_train)\n",
    "y_pred = seq_mod.predict(X_test)\n",
    "print(y_test[0])\n",
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "92a8a32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=seq_mod.classes_\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b338e92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfold all our data - NOTE: this means we don't care about per sentence results. \n",
    "# i.e. each classification is worth same regardless of sentence in which it occurs\n",
    "y_test_unfold = [y for element in y_test for y in element]\n",
    "y_pred_unfold = [y for element in y_pred for y in element]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "78515133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                    O      0.773     0.988     0.867       643\n",
      "B-DATUM_VERBUECHERUNG      0.000     0.000     0.000        13\n",
      "I-DATUM_VERBUECHERUNG      0.000     0.000     0.000        12\n",
      "      B-DATUM_VERTRAG      0.000     0.000     0.000        13\n",
      "      I-DATUM_VERTRAG      0.000     0.000     0.000        14\n",
      "            B-FLAECHE      0.000     0.000     0.000        15\n",
      "            I-FLAECHE      0.000     0.000     0.000         0\n",
      "        B-GESAMTPREIS      0.000     0.000     0.000        11\n",
      "        I-GESAMTPREIS      0.000     0.000     0.000         0\n",
      "           B-IMMO_TYP      0.000     0.000     0.000        19\n",
      "           I-IMMO_TYP      0.000     0.000     0.000         0\n",
      "            B-KAEUFER      0.000     0.000     0.000        10\n",
      "            I-KAEUFER      0.000     0.000     0.000         8\n",
      "                B-ORT      0.300     0.115     0.167        26\n",
      "            B-QMPREIS      0.000     0.000     0.000        10\n",
      "            I-QMPREIS      0.000     0.000     0.000         0\n",
      "            B-STRASSE      0.000     0.000     0.000        12\n",
      "            I-STRASSE      0.000     0.000     0.000         4\n",
      "   B-TERRASSENGROESSE      0.000     0.000     0.000         5\n",
      "         B-VERKAEUFER      0.000     0.000     0.000        13\n",
      "         I-VERKAEUFER      0.000     0.000     0.000        11\n",
      "\n",
      "            micro avg      0.760     0.760     0.760       839\n",
      "            macro avg      0.051     0.053     0.049       839\n",
      "         weighted avg      0.601     0.760     0.670       839\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasco\\anaconda3\\envs\\xcs224u\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(\n",
    "    y_test_unfold, y_pred_unfold, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0680fd70",
   "metadata": {},
   "source": [
    "Remove \"B-\" and \"I-\" (in case they are present in labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9a2de8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0,len(annot)):\n",
    "    a = annot[j]\n",
    "    b = a['spans']\n",
    "    if b!=[]: #i.e. only try to add annotations to tokens if there are annotations to begin with\n",
    "        for i in range(0,len(annot[j]['tokens'])):\n",
    "                if annot[j]['tokens'][i]['label'] != \"O\":\n",
    "                    if annot[j]['tokens'][i]['label'][:2]==\"B-\" or annot[j]['tokens'][i]['label'][:2]==\"I-\":\n",
    "                        annot[j]['tokens'][i]['label']=annot[j]['tokens'][i]['label'][2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f22b42",
   "metadata": {},
   "source": [
    "Try bi-directional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "147649d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_mod = TorchRNNSequenceLabeler(\n",
    "    vocab,\n",
    "    early_stopping=True,\n",
    "    eta=0.001,\n",
    "    bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "63ca2332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ORT', 'O', 'O', 'STRASSE', 'O', 'ORT', 'O', 'O', 'FLAECHE', 'O', 'O', 'IMMO_TYP', 'O', 'O', 'O', 'O', 'QMPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'TERRASSENGROESSE', 'O', 'O', 'O', 'O', 'KAEUFER', 'KAEUFER', 'KAEUFER', 'KAEUFER', 'KAEUFER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'VERKAEUFER', 'VERKAEUFER', 'VERKAEUFER', 'O', 'O', 'O', 'O', 'O', 'GESAMTPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERTRAG', 'DATUM_VERTRAG', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERBUECHERUNG', 'DATUM_VERBUECHERUNG', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8413a3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 18. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 2.1157665252685547"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.12 s\n"
     ]
    }
   ],
   "source": [
    "%time _ = seq_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8d5884c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ORT', 'O', 'O', 'STRASSE', 'STRASSE', 'O', 'ORT', 'O', 'O', 'FLAECHE', 'O', 'O', 'IMMO_TYP', 'O', 'O', 'O', 'O', 'QMPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'VERKAEUFER', 'O', 'O', 'O', 'O', 'O', 'GESAMTPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERTRAG', 'DATUM_VERTRAG', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERBUECHERUNG', 'DATUM_VERBUECHERUNG', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'IMMO_TYP', 'O', 'O', 'TERRASSENGROESSE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'TERRASSENGROESSE', 'TERRASSENGROESSE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                  O      0.760     0.893     0.821       643\n",
      "            KAEUFER      0.000     0.000     0.000        18\n",
      "DATUM_VERBUECHERUNG      0.000     0.000     0.000        25\n",
      "      DATUM_VERTRAG      0.000     0.000     0.000        27\n",
      "         VERKAEUFER      0.000     0.000     0.000        24\n",
      "   TERRASSENGROESSE      0.000     0.000     0.000         5\n",
      "        GESAMTPREIS      0.000     0.000     0.000        11\n",
      "            FLAECHE      0.000     0.000     0.000        15\n",
      "           IMMO_TYP      0.000     0.000     0.000        19\n",
      "            QMPREIS      0.000     0.000     0.000        10\n",
      "                ORT      0.000     0.000     0.000        26\n",
      "            STRASSE      0.000     0.000     0.000        16\n",
      "\n",
      "           accuracy                          0.684       839\n",
      "          macro avg      0.063     0.074     0.068       839\n",
      "       weighted avg      0.583     0.684     0.629       839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = seq_mod.predict(X_test)\n",
    "print(y_test[0])\n",
    "print(y_pred[0])\n",
    "\n",
    "labels=seq_mod.classes_\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "\n",
    "# unfold all our data - NOTE: this means we don't care about per sentence results. \n",
    "# i.e. each classification is worth same regardless of sentence in which it occurs\n",
    "y_test_unfold = [y for element in y_test for y in element]\n",
    "y_pred_unfold = [y for element in y_pred for y in element]\n",
    "\n",
    "print(classification_report(\n",
    "    y_test_unfold, y_pred_unfold, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195d592b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

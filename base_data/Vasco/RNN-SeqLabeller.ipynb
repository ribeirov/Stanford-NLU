{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 1,
>>>>>>> 0c5a7873868780eda6eb91e0ef7fcdf757aa2d1f
   "id": "46bc54ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T14:09:14.437937Z",
     "start_time": "2022-04-05T14:09:14.435854Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.metrics import classification_report, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#from torch_model_base import TorchModelBase\n",
    "#from torch_shallow_neural_classifier import TorchShallowNeuralClassifier\n",
    "from torch_rnn_classifier import TorchRNNDataset, TorchRNNClassifier, TorchRNNModel\n",
    "import utils\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 2,
>>>>>>> 0c5a7873868780eda6eb91e0ef7fcdf757aa2d1f
   "id": "df4daa5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T14:09:15.484474Z",
     "start_time": "2022-04-05T14:09:15.482134Z"
    }
   },
   "outputs": [],
   "source": [
    "# refresh torch rnn classifier:\n",
    "import importlib\n",
    "import torch_rnn_classifier\n",
    "importlib.reload(torch_rnn_classifier)\n",
    "from torch_rnn_classifier import TorchRNNDataset"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 3,
>>>>>>> 0c5a7873868780eda6eb91e0ef7fcdf757aa2d1f
   "id": "4c519f11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T14:09:16.709996Z",
     "start_time": "2022-04-05T14:09:16.708344Z"
    }
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebc5fbf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T14:09:17.642169Z",
     "start_time": "2022-04-05T14:09:17.631218Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('annotations2.jsonl') as jsonl_file:\n",
    "    # note: after running data-preprocessing.ipynb this file already has token-level labels\n",
    "    lines = jsonl_file.readlines()\n",
    "annot = [json.loads(line) for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62fbb470",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T14:09:19.716289Z",
     "start_time": "2022-04-05T14:09:19.711785Z"
    }
   },
   "outputs": [],
   "source": [
    "# now get data into format that TorchRNN expects:\n",
    "X=[] \n",
    "y=[]\n",
    "for j in range(0,len(annot)):\n",
    "    a = annot[j]['tokens']\n",
    "    auxX = []\n",
    "    auxy = []\n",
    "    if annot[j]['spans']!=[]: # are there annot for this example?\n",
    "        for i in range(0,len(a)):\n",
    "            #token_element = (a[i]['text'],a[i]['label'])\n",
    "            auxX.append(a[i]['text'])\n",
    "            auxy.append(a[i]['label'])\n",
    "        X.append(auxX)\n",
    "        y.append(auxy)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_train, X_test, y_train, y_test = X[:120], X[120:], y[:120], y[120:]\n",
    "vocab = sorted({w for seq in X_train for w in seq}) + [\"$UNK\"]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 65,
>>>>>>> 0c5a7873868780eda6eb91e0ef7fcdf757aa2d1f
   "id": "b8b5c9ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T14:09:21.200245Z",
     "start_time": "2022-04-05T14:09:21.197753Z"
    }
   },
   "outputs": [],
   "source": [
    "# reload vsm module\n",
    "import torch_rnn_classifier, torch_model_base\n",
    "import importlib\n",
    "importlib.reload(torch_model_base)\n",
    "importlib.reload(torch_rnn_classifier)\n",
    "from torch_model_base import TorchModelBase\n",
    "from torch_rnn_classifier import TorchRNNClassifier, TorchRNNModel, TorchRNNDataset"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 5,
>>>>>>> 0c5a7873868780eda6eb91e0ef7fcdf757aa2d1f
   "id": "a33711db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T14:09:42.614144Z",
     "start_time": "2022-04-05T14:09:42.607537Z"
    }
   },
   "outputs": [],
   "source": [
    "class TorchRNNSequenceLabeler(TorchRNNClassifier):\n",
    "\n",
    "    def build_graph(self): # uses this build_graph instead of TorchRNNClassifier.build_graph\n",
    "        print(\"here0\")\n",
    "        rnn = TorchRNNModel(\n",
    "            vocab_size=len(self.vocab),\n",
    "            embedding=self.embedding,\n",
    "            use_embedding=self.use_embedding,\n",
    "            embed_dim=self.embed_dim,\n",
    "            rnn_cell_class=self.rnn_cell_class,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            bidirectional=self.bidirectional,\n",
    "            freeze_embedding=self.freeze_embedding)\n",
    "        print(\"here02\")\n",
    "        model = TorchSequenceLabeler( # this defines self.model\n",
    "            rnn=rnn,\n",
    "            output_dim=self.n_classes_)\n",
    "        self.embed_dim = rnn.embed_dim\n",
    "        return model\n",
    "\n",
    "    def build_dataset(self, X, y=None):\n",
    "        START_TAG = \"<START>\"\n",
    "        STOP_TAG = \"<STOP>\"\n",
    "        X, seq_lengths = self._prepare_sequences(X) # converts tokens into tokenIds\n",
    "        if y is None:\n",
    "            return TorchRNNDataset(X, seq_lengths)\n",
    "        else:\n",
    "            # These are the changes from a regular classifier. All\n",
    "            # concern the fact that our labels are sequences of labels.\n",
    "            self.classes_ = sorted({x for seq in y for x in seq})\n",
    "            self.classes_.append(START_TAG) # add start and stop tags\n",
    "            self.classes_.append(STOP_TAG)\n",
    "            self.n_classes_ = len(self.classes_)\n",
    "            class2index = dict(zip(self.classes_, range(self.n_classes_)))\n",
    "            # `y` is a list of tensors of different length. Our Dataset\n",
    "            # class will turn it into a padding tensor for processing.\n",
    "            y = [torch.tensor([class2index[label] for label in seq])\n",
    "                 for seq in y] # converts labels to indices\n",
    "            return TorchRNNDataset(X, seq_lengths, y)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        seq_lengths = [len(ex) for ex in X]\n",
    "        # The base class does the heavy lifting:\n",
    "        preds = self._predict(X)\n",
    "        # Trim to the actual sequence lengths:\n",
    "        preds = [p[: l] for p, l in zip(preds, seq_lengths)]\n",
    "        # Use `softmax`; the model doesn't do this because the loss\n",
    "        # function does it internally.\n",
    "        probs = [torch.softmax(seq, dim=1) for seq in preds]\n",
    "        return probs\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        return [[self.classes_[i] for i in seq.argmax(axis=1)] for seq in probs] # seq.argmax(axis=1) gives index of col that maximizes softmax prob\n",
    "        # see difference vs TorchRNNClassifier.predict\n",
    "\n",
    "    def score(self, X, y):\n",
    "        preds = self.predict(X)\n",
    "        flat_preds = [x for seq in preds for x in seq]\n",
    "        flat_y = [x for seq in y for x in seq]\n",
    "        return utils.safe_macro_f1(flat_y, flat_preds)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "class TorchSequenceLabeler(nn.Module): # no self.hidden_layer or self.classifier_activation as TorchRNNClassifierModel\n",
    "    def __init__(self, rnn, output_dim):\n",
    "        print(\"here021\")\n",
    "        super().__init__()\n",
    "        self.rnn = rnn\n",
    "        self.output_dim = output_dim\n",
    "        if self.rnn.bidirectional:\n",
    "            self.classifier_dim = self.rnn.hidden_dim * 2\n",
    "        else:\n",
    "            self.classifier_dim = self.rnn.hidden_dim\n",
    "        self.classifier_layer = nn.Linear(\n",
    "            self.classifier_dim, self.output_dim)\n",
    "\n",
    "    def forward(self, X, seq_lengths): # X is (noExsInBatch,MaxLen)=(108,117), seq_lengths is the number of tokens in each example in each batch\n",
    "        # this is the forward method of self.model\n",
    "        print(\"here2\")\n",
    "        outputs, state = self.rnn(X, seq_lengths) # X is (batchSize, maxLen of exs in batch); outputs is (noTokensInEx,hiddDim), state is ((batch_size,1,hiddDim),(batch_size,1,hiddDim)) = (finalHiddState,finalCellState) \n",
    "        #print(outputs.data.shape)\n",
    "        #print(state[0].data.shape)\n",
    "        #print(state[1].data.shape)\n",
    "        outputs, seq_length = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "            outputs, batch_first=True) # outputs is (batchSize,MaxLen of examples in batch,hidden_dim); seq_length is noTokenInEx for each ex in batch\n",
    "        #print(outputs.data.shape)\n",
    "        #print(seq_length)\n",
    "        logits = self.classifier_layer(outputs) # this is an FCL from hidden_dim to output_dim (NoLabelClasses)\n",
    "        # logits are (108,117,12) or (1,11,5) = (batchSize,MaxLen of examples in batch,noLabelClasses) noLabelClasses include Start + End\n",
    "        # During training, we need to swap the dimensions of logits\n",
    "        # to accommodate `nn.CrossEntropyLoss`:\n",
    "        print(logits)\n",
    "        if self.training:\n",
    "            return logits.transpose(1, 2) # transpose dimensions 1 and 2 w/ each other (3d array) # outputs (108,12,117) or (1,5,11)\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "id": "fe4012cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T14:09:44.647289Z",
     "start_time": "2022-04-05T14:09:44.607881Z"
    }
   },
=======
   "execution_count": 7,
   "id": "fdd5c84b",
   "metadata": {},
>>>>>>> 0c5a7873868780eda6eb91e0ef7fcdf757aa2d1f
   "outputs": [],
   "source": [
    "X_train = [\"the wall street journal reported today that apple corporation made money\".split(),\"georgia tech is a university in georgia\".split()]\n",
    "y_train = [\"B I I I O O O B I O O\".split(),\"B I O O O O B\".split()]\n",
    "vocab = sorted({w for seq in X_train for w in seq}) + [\"$UNK\"]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
   "id": "3fbfe505",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T14:09:50.797119Z",
     "start_time": "2022-04-05T14:09:50.795189Z"
    }
   },
=======
   "execution_count": 8,
   "id": "fe4012cd",
   "metadata": {},
>>>>>>> 0c5a7873868780eda6eb91e0ef7fcdf757aa2d1f
   "outputs": [],
   "source": [
    "seq_mod = TorchRNNSequenceLabeler(\n",
    "    vocab,\n",
    "    early_stopping=True,\n",
    "    eta=0.001)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 24,
   "id": "66a47009",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T14:19:33.091561Z",
     "start_time": "2022-04-05T14:19:33.087437Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wall</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>street</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>journal</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reported</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>today</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>that</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>apple</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>corporation</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>made</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>money</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              X  y\n",
       "0           the  B\n",
       "1          wall  I\n",
       "2        street  I\n",
       "3       journal  I\n",
       "4      reported  O\n",
       "5         today  O\n",
       "6          that  O\n",
       "7         apple  B\n",
       "8   corporation  I\n",
       "9          made  O\n",
       "10        money  O"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(X_train[0], y_train[0])), columns=[\"X\", \"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
=======
   "execution_count": 9,
>>>>>>> 0c5a7873868780eda6eb91e0ef7fcdf757aa2d1f
   "id": "f8f210b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T14:20:45.492367Z",
     "start_time": "2022-04-05T14:20:45.342841Z"
    }
   },
   "outputs": [
    {
<<<<<<< HEAD
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 20. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 1.0853766202926636"
     ]
    },
    {
=======
>>>>>>> 0c5a7873868780eda6eb91e0ef7fcdf757aa2d1f
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here00\n",
      "here0\n",
      "here01\n",
      "here02\n",
      "here021\n",
      "batch1\n",
      "here2\n",
<<<<<<< HEAD
      "here21\n",
      "tensor([[[-0.0468,  0.1913, -0.0816, -0.0243, -0.0453],\n",
      "         [-0.0522,  0.1927, -0.1355, -0.0581, -0.0249],\n",
      "         [-0.0612,  0.1893, -0.1723, -0.0763, -0.0242],\n",
      "         [-0.0678,  0.1864, -0.1940, -0.0844, -0.0285],\n",
      "         [-0.0721,  0.1843, -0.2059, -0.0873, -0.0331],\n",
      "         [-0.0746,  0.1827, -0.2124, -0.0880, -0.0368],\n",
      "         [-0.0761,  0.1816, -0.2160, -0.0877, -0.0395],\n",
      "         [-0.0770,  0.1808, -0.2178, -0.0872, -0.0414],\n",
      "         [-0.0776,  0.1801, -0.2187, -0.0867, -0.0427],\n",
      "         [-0.0779,  0.1796, -0.2192, -0.0862, -0.0435],\n",
      "         [-0.0782,  0.1794, -0.2195, -0.0859, -0.0440]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0490,  0.2121, -0.0366, -0.0381, -0.0686],\n",
      "         [-0.0529,  0.2263, -0.0614, -0.0797, -0.0595],\n",
      "         [-0.0598,  0.2306, -0.0799, -0.1025, -0.0643],\n",
      "         [-0.0649,  0.2325, -0.0902, -0.1135, -0.0713],\n",
      "         [-0.0680,  0.2335, -0.0953, -0.1182, -0.0773],\n",
      "         [-0.0572,  0.2272, -0.0479, -0.0082, -0.1971],\n",
      "         [-0.0712,  0.2532, -0.0274, -0.0623, -0.1187]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0490,  0.2121, -0.0366, -0.0381, -0.0686],\n",
      "         [-0.0529,  0.2263, -0.0614, -0.0797, -0.0595],\n",
      "         [-0.0598,  0.2306, -0.0799, -0.1025, -0.0643],\n",
      "         [-0.0649,  0.2325, -0.0902, -0.1135, -0.0713],\n",
      "         [-0.0680,  0.2335, -0.0953, -0.1182, -0.0773],\n",
      "         [-0.0699,  0.2339, -0.0975, -0.1200, -0.0818],\n",
      "         [-0.0709,  0.2341, -0.0984, -0.1205, -0.0849],\n",
      "         [-0.0716,  0.2342, -0.0986, -0.1205, -0.0871],\n",
      "         [-0.0721,  0.2341, -0.0984, -0.1204, -0.0885],\n",
      "         [-0.0723,  0.2341, -0.0982, -0.1201, -0.0895],\n",
      "         [-0.0724,  0.2341, -0.0981, -0.1199, -0.0901]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0514,  0.2332,  0.0073, -0.0526, -0.0919],\n",
      "         [-0.0539,  0.2602,  0.0108, -0.1020, -0.0942],\n",
      "         [-0.0587,  0.2724,  0.0102, -0.1292, -0.1044],\n",
      "         [-0.0622,  0.2792,  0.0109, -0.1430, -0.1141],\n",
      "         [-0.0643,  0.2832,  0.0127, -0.1495, -0.1214],\n",
      "         [-0.0518,  0.2512,  0.0173, -0.0325, -0.2168],\n",
      "         [-0.0706,  0.2906,  0.0577, -0.0876, -0.1546]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0514,  0.2332,  0.0073, -0.0526, -0.0919],\n",
      "         [-0.0539,  0.2602,  0.0108, -0.1020, -0.0942],\n",
      "         [-0.0587,  0.2724,  0.0102, -0.1292, -0.1044],\n",
      "         [-0.0622,  0.2792,  0.0109, -0.1430, -0.1141],\n",
      "         [-0.0643,  0.2832,  0.0127, -0.1495, -0.1214],\n",
      "         [-0.0654,  0.2856,  0.0146, -0.1524, -0.1266],\n",
      "         [-0.0661,  0.2871,  0.0163, -0.1537, -0.1300],\n",
      "         [-0.0664,  0.2879,  0.0178, -0.1541, -0.1324],\n",
      "         [-0.0667,  0.2884,  0.0189, -0.1542, -0.1340],\n",
      "         [-0.0668,  0.2888,  0.0197, -0.1542, -0.1351],\n",
      "         [-0.0669,  0.2890,  0.0204, -0.1542, -0.1358]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0538,  0.2549,  0.0500, -0.0673, -0.1159],\n",
      "         [-0.0546,  0.2951,  0.0812, -0.1246, -0.1300],\n",
      "         [-0.0573,  0.3152,  0.0980, -0.1561, -0.1460],\n",
      "         [-0.0591,  0.3267,  0.1096, -0.1723, -0.1585],\n",
      "         [-0.0600,  0.3337,  0.1180, -0.1804, -0.1672],\n",
      "         [-0.0463,  0.2755,  0.0810, -0.0569, -0.2371],\n",
      "         [-0.0695,  0.3295,  0.1410, -0.1129, -0.1917]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0538,  0.2549,  0.0500, -0.0673, -0.1159],\n",
      "         [-0.0546,  0.2951,  0.0812, -0.1246, -0.1300],\n",
      "         [-0.0573,  0.3152,  0.0980, -0.1561, -0.1460],\n",
      "         [-0.0591,  0.3267,  0.1096, -0.1723, -0.1585],\n",
      "         [-0.0600,  0.3337,  0.1180, -0.1804, -0.1672],\n",
      "         [-0.0604,  0.3381,  0.1240, -0.1844, -0.1730],\n",
      "         [-0.0605,  0.3407,  0.1283, -0.1863, -0.1769],\n",
      "         [-0.0606,  0.3423,  0.1312, -0.1872, -0.1794],\n",
      "         [-0.0607,  0.3433,  0.1333, -0.1876, -0.1812],\n",
      "         [-0.0608,  0.3440,  0.1347, -0.1879, -0.1824],\n",
      "         [-0.0607,  0.3444,  0.1356, -0.1879, -0.1831]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0563,  0.2771,  0.0917, -0.0825, -0.1407],\n",
      "         [-0.0554,  0.3307,  0.1501, -0.1477, -0.1672],\n",
      "         [-0.0557,  0.3586,  0.1841, -0.1834, -0.1892],\n",
      "         [-0.0557,  0.3749,  0.2062, -0.2020, -0.2046],\n",
      "         [-0.0553,  0.3847,  0.2210, -0.2115, -0.2147],\n",
      "         [-0.0404,  0.3001,  0.1435, -0.0818, -0.2583],\n",
      "         [-0.0680,  0.3695,  0.2230, -0.1390, -0.2300]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0563,  0.2771,  0.0917, -0.0825, -0.1407],\n",
      "         [-0.0554,  0.3307,  0.1501, -0.1477, -0.1672],\n",
      "         [-0.0557,  0.3586,  0.1841, -0.1834, -0.1892],\n",
      "         [-0.0557,  0.3749,  0.2062, -0.2020, -0.2046],\n",
      "         [-0.0553,  0.3847,  0.2210, -0.2115, -0.2147],\n",
      "         [-0.0549,  0.3907,  0.2309, -0.2165, -0.2213],\n",
      "         [-0.0546,  0.3944,  0.2376, -0.2191, -0.2255],\n",
      "         [-0.0544,  0.3968,  0.2419, -0.2205, -0.2283],\n",
      "         [-0.0542,  0.3983,  0.2449, -0.2212, -0.2300],\n",
      "         [-0.0542,  0.3992,  0.2469, -0.2216, -0.2313],\n",
      "         [-0.0541,  0.3998,  0.2482, -0.2219, -0.2321]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0587,  0.2997,  0.1326, -0.0980, -0.1658],\n",
      "         [-0.0558,  0.3668,  0.2179, -0.1713, -0.2051],\n",
      "         [-0.0538,  0.4025,  0.2688, -0.2112, -0.2334],\n",
      "         [-0.0518,  0.4232,  0.3012, -0.2321, -0.2517],\n",
      "         [-0.0502,  0.4356,  0.3221, -0.2430, -0.2632],\n",
      "         [-0.0342,  0.3249,  0.2054, -0.1071, -0.2799],\n",
      "         [-0.0659,  0.4103,  0.3042, -0.1657, -0.2689]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0587,  0.2997,  0.1326, -0.0980, -0.1658],\n",
      "         [-0.0558,  0.3668,  0.2179, -0.1713, -0.2051],\n",
      "         [-0.0538,  0.4025,  0.2688, -0.2112, -0.2334],\n",
      "         [-0.0518,  0.4232,  0.3012, -0.2321, -0.2517],\n",
      "         [-0.0502,  0.4356,  0.3221, -0.2430, -0.2632],\n",
      "         [-0.0490,  0.4432,  0.3358, -0.2488, -0.2704],\n",
      "         [-0.0481,  0.4479,  0.3447, -0.2519, -0.2749],\n",
      "         [-0.0476,  0.4508,  0.3505, -0.2538, -0.2778],\n",
      "         [-0.0473,  0.4526,  0.3542, -0.2548, -0.2796],\n",
      "         [-0.0471,  0.4538,  0.3567, -0.2554, -0.2808],\n",
      "         [-0.0470,  0.4545,  0.3583, -0.2558, -0.2817]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0608,  0.3228,  0.1732, -0.1139, -0.1912],\n",
      "         [-0.0561,  0.4034,  0.2853, -0.1955, -0.2435],\n",
      "         [-0.0516,  0.4467,  0.3528, -0.2397, -0.2781],\n",
      "         [-0.0478,  0.4714,  0.3952, -0.2629, -0.2994],\n",
      "         [-0.0449,  0.4862,  0.4221, -0.2752, -0.3121],\n",
      "         [-0.0275,  0.3499,  0.2674, -0.1334, -0.3020],\n",
      "         [-0.0635,  0.4518,  0.3853, -0.1935, -0.3083]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0608,  0.3228,  0.1732, -0.1139, -0.1912],\n",
      "         [-0.0561,  0.4034,  0.2853, -0.1955, -0.2435],\n",
      "         [-0.0516,  0.4467,  0.3528, -0.2397, -0.2781],\n",
      "         [-0.0478,  0.4714,  0.3952, -0.2629, -0.2994],\n",
      "         [-0.0449,  0.4862,  0.4221, -0.2752, -0.3121],\n",
      "         [-0.0428,  0.4951,  0.4392, -0.2818, -0.3198],\n",
      "         [-0.0414,  0.5006,  0.4503, -0.2855, -0.3244],\n",
      "         [-0.0406,  0.5040,  0.4573, -0.2877, -0.3274],\n",
      "         [-0.0401,  0.5062,  0.4619, -0.2890, -0.3294],\n",
      "         [-0.0398,  0.5075,  0.4648, -0.2899, -0.3305],\n",
      "         [-0.0397,  0.5084,  0.4668, -0.2903, -0.3314]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0626,  0.3461,  0.2131, -0.1304, -0.2168],\n",
      "         [-0.0560,  0.4402,  0.3521, -0.2207, -0.2824],\n",
      "         [-0.0492,  0.4906,  0.4361, -0.2693, -0.3234],\n",
      "         [-0.0434,  0.5191,  0.4883, -0.2949, -0.3475],\n",
      "         [-0.0392,  0.5357,  0.5208, -0.3085, -0.3613],\n",
      "         [-0.0203,  0.3748,  0.3299, -0.1609, -0.3246],\n",
      "         [-0.0605,  0.4935,  0.4665, -0.2230, -0.3483]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0626,  0.3461,  0.2131, -0.1304, -0.2168],\n",
      "         [-0.0560,  0.4402,  0.3521, -0.2207, -0.2824],\n",
      "         [-0.0492,  0.4906,  0.4361, -0.2693, -0.3234],\n",
      "         [-0.0434,  0.5191,  0.4883, -0.2949, -0.3475],\n",
      "         [-0.0392,  0.5357,  0.5208, -0.3085, -0.3613],\n",
      "         [-0.0363,  0.5458,  0.5413, -0.3160, -0.3694],\n",
      "         [-0.0346,  0.5519,  0.5543, -0.3203, -0.3741],\n",
      "         [-0.0334,  0.5557,  0.5625, -0.3228, -0.3770],\n",
      "         [-0.0327,  0.5581,  0.5678, -0.3244, -0.3788],\n",
      "         [-0.0322,  0.5595,  0.5712, -0.3254, -0.3800],\n",
      "         [-0.0320,  0.5605,  0.5734, -0.3260, -0.3808]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0642,  0.3696,  0.2532, -0.1474, -0.2423],\n",
      "         [-0.0557,  0.4771,  0.4191, -0.2468, -0.3214],\n",
      "         [-0.0465,  0.5341,  0.5196, -0.3001, -0.3687],\n",
      "         [-0.0389,  0.5658,  0.5813, -0.3281, -0.3953],\n",
      "         [-0.0334,  0.5841,  0.6194, -0.3431, -0.4101],\n",
      "         [-0.0125,  0.3995,  0.3939, -0.1898, -0.3475],\n",
      "         [-0.0570,  0.5351,  0.5488, -0.2543, -0.3884]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0642,  0.3696,  0.2532, -0.1474, -0.2423],\n",
      "         [-0.0557,  0.4771,  0.4191, -0.2468, -0.3214],\n",
      "         [-0.0465,  0.5341,  0.5196, -0.3001, -0.3687],\n",
      "         [-0.0389,  0.5658,  0.5813, -0.3281, -0.3953],\n",
      "         [-0.0334,  0.5841,  0.6194, -0.3431, -0.4101],\n",
      "         [-0.0298,  0.5949,  0.6430, -0.3514, -0.4185],\n",
      "         [-0.0275,  0.6014,  0.6577, -0.3562, -0.4232],\n",
      "         [-0.0260,  0.6054,  0.6672, -0.3591, -0.4260],\n",
      "         [-0.0251,  0.6079,  0.6732, -0.3609, -0.4277],\n",
      "         [-0.0245,  0.6094,  0.6771, -0.3621, -0.4288],\n",
      "         [-0.0242,  0.6105,  0.6795, -0.3629, -0.4295]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0659,  0.3932,  0.2928, -0.1650, -0.2679],\n",
      "         [-0.0556,  0.5139,  0.4859, -0.2739, -0.3605],\n",
      "         [-0.0442,  0.5771,  0.6029, -0.3321, -0.4140],\n",
      "         [-0.0348,  0.6114,  0.6739, -0.3627, -0.4431],\n",
      "         [-0.0282,  0.6308,  0.7172, -0.3790, -0.4588],\n",
      "         [-0.0044,  0.4237,  0.4591, -0.2200, -0.3708],\n",
      "         [-0.0536,  0.5764,  0.6318, -0.2874, -0.4287]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0659,  0.3932,  0.2928, -0.1650, -0.2679],\n",
      "         [-0.0556,  0.5139,  0.4859, -0.2739, -0.3605],\n",
      "         [-0.0442,  0.5771,  0.6029, -0.3321, -0.4140],\n",
      "         [-0.0348,  0.6114,  0.6739, -0.3627, -0.4431],\n",
      "         [-0.0282,  0.6308,  0.7172, -0.3790, -0.4588],\n",
      "         [-0.0238,  0.6421,  0.7438, -0.3881, -0.4673],\n",
      "         [-0.0210,  0.6489,  0.7605, -0.3933, -0.4721],\n",
      "         [-0.0191,  0.6529,  0.7710, -0.3967, -0.4747],\n",
      "         [-0.0181,  0.6556,  0.7776, -0.3987, -0.4763],\n",
      "         [-0.0174,  0.6571,  0.7818, -0.4000, -0.4772],\n",
      "         [-0.0170,  0.6581,  0.7847, -0.4009, -0.4779]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0672,  0.4171,  0.3321, -0.1832, -0.2934],\n",
      "         [-0.0554,  0.5508,  0.5526, -0.3022, -0.3998],\n",
      "         [-0.0418,  0.6197,  0.6859, -0.3655, -0.4594],\n",
      "         [-0.0308,  0.6563,  0.7661, -0.3986, -0.4909],\n",
      "         [-0.0231,  0.6764,  0.8144, -0.4163, -0.5074],\n",
      "         [ 0.0041,  0.4479,  0.5262, -0.2517, -0.3947],\n",
      "         [-0.0498,  0.6176,  0.7161, -0.3224, -0.4694]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0672,  0.4171,  0.3321, -0.1832, -0.2934],\n",
      "         [-0.0554,  0.5508,  0.5526, -0.3022, -0.3998],\n",
      "         [-0.0418,  0.6197,  0.6859, -0.3655, -0.4594],\n",
      "         [-0.0308,  0.6563,  0.7661, -0.3986, -0.4909],\n",
      "         [-0.0231,  0.6764,  0.8144, -0.4163, -0.5074],\n",
      "         [-0.0182,  0.6878,  0.8439, -0.4261, -0.5162],\n",
      "         [-0.0148,  0.6946,  0.8623, -0.4320, -0.5208],\n",
      "         [-0.0128,  0.6987,  0.8738, -0.4354, -0.5234],\n",
      "         [-0.0115,  0.7011,  0.8811, -0.4376, -0.5247],\n",
      "         [-0.0106,  0.7027,  0.8858, -0.4390, -0.5256],\n",
      "         [-0.0101,  0.7037,  0.8889, -0.4401, -0.5262]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0689,  0.4416,  0.3707, -0.2020, -0.3191],\n",
      "         [-0.0558,  0.5882,  0.6187, -0.3313, -0.4394],\n",
      "         [-0.0403,  0.6623,  0.7684, -0.4001, -0.5054],\n",
      "         [-0.0278,  0.7007,  0.8575, -0.4358, -0.5393],\n",
      "         [-0.0192,  0.7210,  0.9107, -0.4547, -0.5565],\n",
      "         [ 0.0123,  0.4724,  0.5950, -0.2848, -0.4196],\n",
      "         [-0.0466,  0.6587,  0.8011, -0.3592, -0.5111]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0689,  0.4416,  0.3707, -0.2020, -0.3191],\n",
      "         [-0.0558,  0.5882,  0.6187, -0.3313, -0.4394],\n",
      "         [-0.0403,  0.6623,  0.7684, -0.4001, -0.5054],\n",
      "         [-0.0278,  0.7007,  0.8575, -0.4358, -0.5393],\n",
      "         [-0.0192,  0.7210,  0.9107, -0.4547, -0.5565],\n",
      "         [-0.0134,  0.7325,  0.9431, -0.4653, -0.5653],\n",
      "         [-0.0097,  0.7391,  0.9632, -0.4713, -0.5700],\n",
      "         [-0.0073,  0.7430,  0.9757, -0.4750, -0.5724],\n",
      "         [-0.0059,  0.7453,  0.9837, -0.4775, -0.5737],\n",
      "         [-0.0050,  0.7467,  0.9888, -0.4790, -0.5743],\n",
      "         [-0.0043,  0.7476,  0.9922, -0.4799, -0.5747]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0707,  0.4667,  0.4085, -0.2213, -0.3447],\n",
      "         [-0.0565,  0.6266,  0.6839, -0.3615, -0.4793],\n",
      "         [-0.0392,  0.7056,  0.8498, -0.4358, -0.5515],\n",
      "         [-0.0254,  0.7449,  0.9478, -0.4743, -0.5877],\n",
      "         [-0.0157,  0.7656,  1.0059, -0.4944, -0.6058],\n",
      "         [ 0.0204,  0.4974,  0.6654, -0.3191, -0.4454],\n",
      "         [-0.0433,  0.7004,  0.8869, -0.3979, -0.5532]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-7.0687e-02,  4.6669e-01,  4.0847e-01, -2.2128e-01, -3.4471e-01],\n",
      "         [-5.6457e-02,  6.2655e-01,  6.8388e-01, -3.6155e-01, -4.7926e-01],\n",
      "         [-3.9155e-02,  7.0561e-01,  8.4985e-01, -4.3584e-01, -5.5154e-01],\n",
      "         [-2.5418e-02,  7.4492e-01,  9.4776e-01, -4.7429e-01, -5.8768e-01],\n",
      "         [-1.5720e-02,  7.6558e-01,  1.0059e+00, -4.9442e-01, -6.0580e-01],\n",
      "         [-9.3360e-03,  7.7663e-01,  1.0411e+00, -5.0557e-01, -6.1481e-01],\n",
      "         [-5.3677e-03,  7.8272e-01,  1.0627e+00, -5.1199e-01, -6.1935e-01],\n",
      "         [-2.7636e-03,  7.8617e-01,  1.0763e+00, -5.1577e-01, -6.2163e-01],\n",
      "         [-1.1616e-03,  7.8817e-01,  1.0849e+00, -5.1826e-01, -6.2276e-01],\n",
      "         [-4.9591e-05,  7.8947e-01,  1.0907e+00, -5.1998e-01, -6.2325e-01],\n",
      "         [ 7.5206e-04,  7.9034e-01,  1.0944e+00, -5.2101e-01, -6.2352e-01]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0723,  0.4929,  0.4450, -0.2408, -0.3706],\n",
      "         [-0.0571,  0.6662,  0.7478, -0.3923, -0.5200],\n",
      "         [-0.0380,  0.7498,  0.9299, -0.4723, -0.5986],\n",
      "         [-0.0227,  0.7899,  1.0366, -0.5133, -0.6372],\n",
      "         [-0.0120,  0.8100,  1.0996, -0.5347, -0.6560],\n",
      "         [ 0.0286,  0.5233,  0.7372, -0.3543, -0.4728],\n",
      "         [-0.0397,  0.7424,  0.9730, -0.4378, -0.5967]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-7.2265e-02,  4.9290e-01,  4.4503e-01, -2.4076e-01, -3.7055e-01],\n",
      "         [-5.7062e-02,  6.6621e-01,  7.4781e-01, -3.9230e-01, -5.1997e-01],\n",
      "         [-3.7977e-02,  7.4976e-01,  9.2992e-01, -4.7226e-01, -5.9861e-01],\n",
      "         [-2.2677e-02,  7.8994e-01,  1.0366e+00, -5.1331e-01, -6.3717e-01],\n",
      "         [-1.1975e-02,  8.0996e-01,  1.0996e+00, -5.3468e-01, -6.5598e-01],\n",
      "         [-5.1482e-03,  8.2036e-01,  1.1374e+00, -5.4635e-01, -6.6510e-01],\n",
      "         [-6.6698e-04,  8.2605e-01,  1.1608e+00, -5.5297e-01, -6.6966e-01],\n",
      "         [ 2.3931e-03,  8.2876e-01,  1.1754e+00, -5.5693e-01, -6.7164e-01],\n",
      "         [ 4.1708e-03,  8.3040e-01,  1.1848e+00, -5.5950e-01, -6.7267e-01],\n",
      "         [ 5.5155e-03,  8.3137e-01,  1.1910e+00, -5.6106e-01, -6.7300e-01],\n",
      "         [ 6.2017e-03,  8.3197e-01,  1.1951e+00, -5.6233e-01, -6.7324e-01]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0731,  0.5201,  0.4801, -0.2605, -0.3964],\n",
      "         [-0.0568,  0.7073,  0.8098, -0.4237, -0.5608],\n",
      "         [-0.0358,  0.7948,  1.0081, -0.5095, -0.6459],\n",
      "         [-0.0189,  0.8353,  1.1236, -0.5533, -0.6868],\n",
      "         [-0.0073,  0.8544,  1.1914, -0.5758, -0.7063],\n",
      "         [ 0.0376,  0.5498,  0.8102, -0.3901, -0.5015],\n",
      "         [-0.0344,  0.7849,  1.0594, -0.4789, -0.6409]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-7.3147e-02,  5.2012e-01,  4.8008e-01, -2.6048e-01, -3.9639e-01],\n",
      "         [-5.6846e-02,  7.0727e-01,  8.0982e-01, -4.2366e-01, -5.6078e-01],\n",
      "         [-3.5771e-02,  7.9480e-01,  1.0081e+00, -5.0949e-01, -6.4587e-01],\n",
      "         [-1.8875e-02,  8.3530e-01,  1.1236e+00, -5.5325e-01, -6.8676e-01],\n",
      "         [-7.2634e-03,  8.5444e-01,  1.1914e+00, -5.7581e-01, -7.0632e-01],\n",
      "         [ 5.9749e-04,  8.6386e-01,  1.2321e+00, -5.8803e-01, -7.1563e-01],\n",
      "         [ 5.6511e-03,  8.6827e-01,  1.2570e+00, -5.9469e-01, -7.1992e-01],\n",
      "         [ 8.9775e-03,  8.7063e-01,  1.2729e+00, -5.9886e-01, -7.2183e-01],\n",
      "         [ 1.1061e-02,  8.7178e-01,  1.2831e+00, -6.0139e-01, -7.2280e-01],\n",
      "         [ 1.2562e-02,  8.7230e-01,  1.2898e+00, -6.0308e-01, -7.2310e-01],\n",
      "         [ 1.3428e-02,  8.7251e-01,  1.2942e+00, -6.0411e-01, -7.2297e-01]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-7.2929e-02,  5.4848e-01,  5.1346e-01, -2.8055e-01, -4.2223e-01],\n",
      "         [-5.5133e-02,  7.4964e-01,  8.6968e-01, -4.5564e-01, -6.0194e-01],\n",
      "         [-3.1545e-02,  8.4103e-01,  1.0842e+00, -5.4757e-01, -6.9362e-01],\n",
      "         [-1.2701e-02,  8.8114e-01,  1.2087e+00, -5.9407e-01, -7.3693e-01],\n",
      "         [ 3.0898e-04,  8.9891e-01,  1.2811e+00, -6.1768e-01, -7.5707e-01],\n",
      "         [ 4.8019e-02,  5.7693e-01,  8.8401e-01, -4.2665e-01, -5.3156e-01],\n",
      "         [-2.6783e-02,  8.2760e-01,  1.1456e+00, -5.2131e-01, -6.8612e-01]]],\n",
      "       device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-7.2929e-02,  5.4848e-01,  5.1346e-01, -2.8055e-01, -4.2223e-01],\n",
      "         [-5.5133e-02,  7.4964e-01,  8.6968e-01, -4.5564e-01, -6.0194e-01],\n",
      "         [-3.1545e-02,  8.4103e-01,  1.0842e+00, -5.4757e-01, -6.9362e-01],\n",
      "         [-1.2701e-02,  8.8114e-01,  1.2087e+00, -5.9407e-01, -7.3693e-01],\n",
      "         [ 3.0898e-04,  8.9891e-01,  1.2811e+00, -6.1768e-01, -7.5707e-01],\n",
      "         [ 9.0814e-03,  9.0697e-01,  1.3248e+00, -6.3025e-01, -7.6657e-01],\n",
      "         [ 1.4683e-02,  9.1036e-01,  1.3514e+00, -6.3716e-01, -7.7074e-01],\n",
      "         [ 1.8518e-02,  9.1173e-01,  1.3685e+00, -6.4114e-01, -7.7263e-01],\n",
      "         [ 2.0993e-02,  9.1218e-01,  1.3795e+00, -6.4373e-01, -7.7317e-01],\n",
      "         [ 2.2569e-02,  9.1219e-01,  1.3867e+00, -6.4544e-01, -7.7340e-01],\n",
      "         [ 2.3698e-02,  9.1220e-01,  1.3917e+00, -6.4666e-01, -7.7339e-01]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0714,  0.5780,  0.5449, -0.3008, -0.4478],\n",
      "         [-0.0513,  0.7937,  0.9272, -0.4880, -0.6433],\n",
      "         [-0.0249,  0.8884,  1.1578, -0.5863, -0.7416],\n",
      "         [-0.0035,  0.9276,  1.2910, -0.6354, -0.7870],\n",
      "         [ 0.0111,  0.9438,  1.3686, -0.6598, -0.8080],\n",
      "         [ 0.0605,  0.6049,  0.9584, -0.4636, -0.5629],\n",
      "         [-0.0161,  0.8705,  1.2309, -0.5645, -0.7321]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0714,  0.5780,  0.5449, -0.3008, -0.4478],\n",
      "         [-0.0513,  0.7937,  0.9272, -0.4880, -0.6433],\n",
      "         [-0.0249,  0.8884,  1.1578, -0.5863, -0.7416],\n",
      "         [-0.0035,  0.9276,  1.2910, -0.6354, -0.7870],\n",
      "         [ 0.0111,  0.9438,  1.3686, -0.6598, -0.8080],\n",
      "         [ 0.0211,  0.9503,  1.4151, -0.6728, -0.8175],\n",
      "         [ 0.0274,  0.9523,  1.4435, -0.6797, -0.8216],\n",
      "         [ 0.0317,  0.9528,  1.4619, -0.6839, -0.8234],\n",
      "         [ 0.0346,  0.9524,  1.4737, -0.6863, -0.8238],\n",
      "         [ 0.0364,  0.9520,  1.4815, -0.6880, -0.8238],\n",
      "         [ 0.0378,  0.9513,  1.4869, -0.6890, -0.8237]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0684,  0.6086,  0.5741, -0.3211, -0.4731],\n",
      "         [-0.0455,  0.8393,  0.9814, -0.5206, -0.6844],\n",
      "         [-0.0158,  0.9371,  1.2276, -0.6252, -0.7893],\n",
      "         [ 0.0085,  0.9753,  1.3699, -0.6771, -0.8371],\n",
      "         [ 0.0253,  0.9894,  1.4525, -0.7026, -0.8587],\n",
      "         [ 0.0748,  0.6338,  1.0323, -0.5011, -0.5959],\n",
      "         [-0.0020,  0.9141,  1.3151, -0.6083, -0.7789]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0684,  0.6086,  0.5741, -0.3211, -0.4731],\n",
      "         [-0.0455,  0.8393,  0.9814, -0.5206, -0.6844],\n",
      "         [-0.0158,  0.9371,  1.2276, -0.6252, -0.7893],\n",
      "         [ 0.0085,  0.9753,  1.3699, -0.6771, -0.8371],\n",
      "         [ 0.0253,  0.9894,  1.4525, -0.7026, -0.8587],\n",
      "         [ 0.0363,  0.9937,  1.5017, -0.7157, -0.8683],\n",
      "         [ 0.0436,  0.9946,  1.5325, -0.7228, -0.8726],\n",
      "         [ 0.0485,  0.9938,  1.5518, -0.7266, -0.8741],\n",
      "         [ 0.0518,  0.9927,  1.5647, -0.7291, -0.8745],\n",
      "         [ 0.0539,  0.9913,  1.5730, -0.7305, -0.8745],\n",
      "         [ 0.0556,  0.9902,  1.5789, -0.7317, -0.8741]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0639,  0.6404,  0.6009, -0.3413, -0.4980],\n",
      "         [-0.0374,  0.8867,  1.0320, -0.5534, -0.7253],\n",
      "         [-0.0037,  0.9878,  1.2938, -0.6645, -0.8372],\n",
      "         [ 0.0239,  1.0243,  1.4449, -0.7191, -0.8873],\n",
      "         [ 0.0430,  1.0360,  1.5327, -0.7456, -0.9095],\n",
      "         [ 0.0913,  0.6637,  1.1051, -0.5386, -0.6307],\n",
      "         [ 0.0155,  0.9580,  1.3970, -0.6525, -0.8265]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0639,  0.6404,  0.6009, -0.3413, -0.4980],\n",
      "         [-0.0374,  0.8867,  1.0320, -0.5534, -0.7253],\n",
      "         [-0.0037,  0.9878,  1.2938, -0.6645, -0.8372],\n",
      "         [ 0.0239,  1.0243,  1.4449, -0.7191, -0.8873],\n",
      "         [ 0.0430,  1.0360,  1.5327, -0.7456, -0.9095],\n",
      "         [ 0.0555,  1.0382,  1.5850, -0.7587, -0.9193],\n",
      "         [ 0.0639,  1.0371,  1.6175, -0.7656, -0.9234],\n",
      "         [ 0.0695,  1.0352,  1.6382, -0.7692, -0.9249],\n",
      "         [ 0.0732,  1.0331,  1.6520, -0.7717, -0.9253],\n",
      "         [ 0.0756,  1.0311,  1.6610, -0.7730, -0.9250],\n",
      "         [ 0.0774,  1.0294,  1.6673, -0.7740, -0.9246]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0581,  0.6731,  0.6251, -0.3613, -0.5222],\n",
      "         [-0.0277,  0.9359,  1.0787, -0.5856, -0.7656],\n",
      "         [ 0.0101,  1.0403,  1.3552, -0.7033, -0.8843],\n",
      "         [ 0.0416,  1.0747,  1.5153, -0.7607, -0.9367],\n",
      "         [ 0.0633,  1.0838,  1.6081, -0.7881, -0.9598],\n",
      "         [ 0.1096,  0.6949,  1.1757, -0.5756, -0.6668],\n",
      "         [ 0.0362,  1.0027,  1.4760, -0.6964, -0.8743]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0581,  0.6731,  0.6251, -0.3613, -0.5222],\n",
      "         [-0.0277,  0.9359,  1.0787, -0.5856, -0.7656],\n",
      "         [ 0.0101,  1.0403,  1.3552, -0.7033, -0.8843],\n",
      "         [ 0.0416,  1.0747,  1.5153, -0.7607, -0.9367],\n",
      "         [ 0.0633,  1.0838,  1.6081, -0.7881, -0.9598],\n",
      "         [ 0.0778,  1.0837,  1.6637, -0.8014, -0.9698],\n",
      "         [ 0.0873,  1.0807,  1.6981, -0.8080, -0.9741],\n",
      "         [ 0.0935,  1.0775,  1.7202, -0.8115, -0.9754],\n",
      "         [ 0.0978,  1.0742,  1.7348, -0.8136, -0.9755],\n",
      "         [ 0.1006,  1.0714,  1.7446, -0.8148, -0.9753],\n",
      "         [ 0.1027,  1.0693,  1.7515, -0.8155, -0.9749]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0512,  0.7068,  0.6463, -0.3810, -0.5460],\n",
      "         [-0.0164,  0.9873,  1.1204, -0.6175, -0.8058],\n",
      "         [ 0.0259,  1.0951,  1.4109, -0.7416, -0.9316],\n",
      "         [ 0.0614,  1.1275,  1.5798, -0.8022, -0.9864],\n",
      "         [ 0.0861,  1.1334,  1.6779, -0.8307, -1.0102],\n",
      "         [ 0.1297,  0.7282,  1.2436, -0.6126, -0.7049],\n",
      "         [ 0.0596,  1.0486,  1.5511, -0.7403, -0.9232]]], device='cuda:0')\n",
      "CPU times: user 126 ms, sys: 23.2 ms, total: 149 ms\n",
      "Wall time: 148 ms\n"
=======
      "here21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished epoch 10 of 1000; error is 1.3484532833099365"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3627, -0.0571,  0.1751, -0.1338,  0.0219],\n",
      "         [-0.0976,  0.0181,  0.0332, -0.0325,  0.1119],\n",
      "         [-0.2014,  0.0605,  0.1298, -0.0567,  0.0970],\n",
      "         [-0.2015,  0.1037,  0.0392, -0.0535,  0.0768],\n",
      "         [-0.0959,  0.0611,  0.0748, -0.1305,  0.1798],\n",
      "         [-0.1551,  0.0170,  0.0991, -0.1830,  0.0736],\n",
      "         [-0.0786,  0.0709,  0.0116, -0.0523, -0.1000],\n",
      "         [-0.1403,  0.1220, -0.0602, -0.0288,  0.1099],\n",
      "         [-0.2416,  0.1540,  0.1170,  0.0194,  0.1142],\n",
      "         [-0.2535, -0.0141,  0.0446,  0.1006,  0.1224],\n",
      "         [-0.1576, -0.1045,  0.1067,  0.0832,  0.1514]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1249, -0.0782,  0.0023, -0.0520,  0.1311],\n",
      "         [-0.0366,  0.0341,  0.0813, -0.1528,  0.0561],\n",
      "         [-0.0623,  0.1088,  0.0040, -0.1438,  0.1385],\n",
      "         [-0.1064,  0.0313,  0.1009, -0.0774,  0.0317],\n",
      "         [-0.2064,  0.0638,  0.1199,  0.0804,  0.0294],\n",
      "         [-0.1743,  0.0478,  0.0579,  0.1129, -0.0346],\n",
      "         [-0.1604, -0.0311, -0.0346,  0.0556,  0.0728]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-3.4811e-01, -4.9334e-02,  1.7122e-01, -1.3973e-01,  1.7148e-02],\n",
      "         [-9.9666e-02,  4.2356e-02,  4.2966e-02, -4.4054e-02,  9.6089e-02],\n",
      "         [-2.0156e-01,  8.6886e-02,  1.3601e-01, -6.3019e-02,  8.3773e-02],\n",
      "         [-2.0545e-01,  1.2941e-01,  4.9187e-02, -6.6033e-02,  5.8716e-02],\n",
      "         [-1.0480e-01,  6.6132e-02,  1.0596e-01, -1.4588e-01,  1.6261e-01],\n",
      "         [-1.6771e-01,  1.4023e-02,  1.3858e-01, -1.9643e-01,  5.9927e-02],\n",
      "         [-8.0451e-02,  6.1311e-02,  4.5406e-02, -6.5957e-02, -1.1155e-01],\n",
      "         [-1.1958e-01,  1.2353e-01, -4.1184e-02, -4.2967e-02,  9.9297e-02],\n",
      "         [-2.4195e-01,  1.6821e-01,  1.4462e-01, -2.0862e-07,  9.5562e-02],\n",
      "         [-2.6309e-01, -1.0023e-02,  8.7816e-02,  7.8723e-02,  1.0641e-01],\n",
      "         [-1.6708e-01, -1.0616e-01,  1.5685e-01,  6.3674e-02,  1.3334e-01]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1214, -0.0777,  0.0040, -0.0544,  0.1285],\n",
      "         [-0.0394,  0.0326,  0.0932, -0.1598,  0.0499],\n",
      "         [-0.0601,  0.1132,  0.0083, -0.1460,  0.1339],\n",
      "         [-0.1090,  0.0367,  0.1113, -0.0818,  0.0256],\n",
      "         [-0.2059,  0.0713,  0.1329,  0.0694,  0.0192],\n",
      "         [-0.1757,  0.0546,  0.0655,  0.1071, -0.0404],\n",
      "         [-0.1580, -0.0291, -0.0287,  0.0506,  0.0683]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.3336, -0.0417,  0.1674, -0.1465,  0.0118],\n",
      "         [-0.1017,  0.0669,  0.0526, -0.0555,  0.0804],\n",
      "         [-0.2019,  0.1133,  0.1424, -0.0693,  0.0704],\n",
      "         [-0.2096,  0.1556,  0.0589, -0.0791,  0.0403],\n",
      "         [-0.1139,  0.0713,  0.1370, -0.1616,  0.1453],\n",
      "         [-0.1803,  0.0112,  0.1778, -0.2095,  0.0463],\n",
      "         [-0.0823,  0.0518,  0.0789, -0.0796, -0.1233],\n",
      "         [-0.0990,  0.1257, -0.0222, -0.0567,  0.0890],\n",
      "         [-0.2426,  0.1833,  0.1713, -0.0191,  0.0767],\n",
      "         [-0.2729, -0.0052,  0.1305,  0.0580,  0.0910],\n",
      "         [-0.1768, -0.1077,  0.2062,  0.0460,  0.1162]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1180, -0.0772,  0.0057, -0.0568,  0.1259],\n",
      "         [-0.0424,  0.0310,  0.1050, -0.1667,  0.0436],\n",
      "         [-0.0581,  0.1174,  0.0125, -0.1482,  0.1295],\n",
      "         [-0.1116,  0.0418,  0.1217, -0.0862,  0.0194],\n",
      "         [-0.2058,  0.0787,  0.1458,  0.0584,  0.0088],\n",
      "         [-0.1772,  0.0613,  0.0728,  0.1015, -0.0463],\n",
      "         [-0.1555, -0.0271, -0.0230,  0.0459,  0.0638]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-3.1909e-01, -3.3850e-02,  1.6368e-01, -1.5353e-01,  6.2391e-03],\n",
      "         [-1.0363e-01,  9.1719e-02,  6.2039e-02, -6.6828e-02,  6.4597e-02],\n",
      "         [-2.0247e-01,  1.3982e-01,  1.4880e-01, -7.5503e-02,  5.6975e-02],\n",
      "         [-2.1408e-01,  1.8240e-01,  6.8538e-02, -9.2229e-02,  2.1676e-02],\n",
      "         [-1.2304e-01,  7.6723e-02,  1.6807e-01, -1.7727e-01,  1.2800e-01],\n",
      "         [-1.9282e-01,  8.4953e-03,  2.1659e-01, -2.2231e-01,  3.2772e-02],\n",
      "         [-8.4275e-02,  4.2127e-02,  1.1233e-01, -9.3372e-02, -1.3519e-01],\n",
      "         [-7.8755e-02,  1.2830e-01, -3.7891e-03, -7.0046e-02,  7.8906e-02],\n",
      "         [-2.4376e-01,  1.9895e-01,  1.9742e-01, -3.8035e-02,  5.7753e-02],\n",
      "         [-2.8327e-01, -2.2906e-04,  1.7290e-01,  3.7832e-02,  7.5776e-02],\n",
      "         [-1.8686e-01, -1.0928e-01,  2.5507e-01,  2.9269e-02,  9.9390e-02]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1145, -0.0767,  0.0073, -0.0591,  0.1232],\n",
      "         [-0.0455,  0.0294,  0.1168, -0.1734,  0.0371],\n",
      "         [-0.0561,  0.1215,  0.0167, -0.1503,  0.1251],\n",
      "         [-0.1143,  0.0466,  0.1320, -0.0905,  0.0130],\n",
      "         [-0.2058,  0.0860,  0.1586,  0.0474, -0.0019],\n",
      "         [-0.1786,  0.0682,  0.0799,  0.0960, -0.0524],\n",
      "         [-0.1531, -0.0251, -0.0174,  0.0412,  0.0591]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.3047, -0.0258,  0.1599, -0.1607,  0.0005],\n",
      "         [-0.1055,  0.1169,  0.0711, -0.0782,  0.0487],\n",
      "         [-0.2034,  0.1667,  0.1551, -0.0818,  0.0433],\n",
      "         [-0.2190,  0.2097,  0.0781, -0.1054,  0.0027],\n",
      "         [-0.1324,  0.0824,  0.1992, -0.1930,  0.1105],\n",
      "         [-0.2053,  0.0059,  0.2552, -0.2350,  0.0192],\n",
      "         [-0.0862,  0.0326,  0.1457, -0.1072, -0.1472],\n",
      "         [-0.0588,  0.1312,  0.0142, -0.0829,  0.0690],\n",
      "         [-0.2452,  0.2154,  0.2231, -0.0567,  0.0388],\n",
      "         [-0.2942,  0.0051,  0.2152,  0.0181,  0.0607],\n",
      "         [-0.1972, -0.1108,  0.3036,  0.0130,  0.0827]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1110, -0.0763,  0.0088, -0.0613,  0.1207],\n",
      "         [-0.0487,  0.0278,  0.1285, -0.1800,  0.0304],\n",
      "         [-0.0542,  0.1256,  0.0208, -0.1524,  0.1209],\n",
      "         [-0.1170,  0.0513,  0.1424, -0.0949,  0.0066],\n",
      "         [-0.2060,  0.0933,  0.1715,  0.0362, -0.0130],\n",
      "         [-0.1802,  0.0751,  0.0867,  0.0906, -0.0589],\n",
      "         [-0.1507, -0.0230, -0.0120,  0.0366,  0.0543]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.2903, -0.0176,  0.1562, -0.1680, -0.0055],\n",
      "         [-0.1072,  0.1425,  0.0797, -0.0895,  0.0327],\n",
      "         [-0.2046,  0.1939,  0.1614, -0.0880,  0.0294],\n",
      "         [-0.2244,  0.2377,  0.0875, -0.1187, -0.0166],\n",
      "         [-0.1421,  0.0882,  0.2304, -0.2087,  0.0929],\n",
      "         [-0.2179,  0.0034,  0.2937, -0.2478,  0.0054],\n",
      "         [-0.0883,  0.0232,  0.1792, -0.1211, -0.1593],\n",
      "         [-0.0390,  0.1344,  0.0318, -0.0955,  0.0593],\n",
      "         [-0.2470,  0.2327,  0.2482, -0.0751,  0.0196],\n",
      "         [-0.3056,  0.0109,  0.2574, -0.0012,  0.0455],\n",
      "         [-0.2077, -0.1124,  0.3521, -0.0028,  0.0660]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-1.0740e-01, -7.5998e-02,  1.0238e-02, -6.3312e-02,  1.1822e-01],\n",
      "         [-5.1961e-02,  2.6226e-02,  1.4023e-01, -1.8657e-01,  2.3460e-02],\n",
      "         [-5.2332e-02,  1.2967e-01,  2.4860e-02, -1.5436e-01,  1.1663e-01],\n",
      "         [-1.1980e-01,  5.5834e-02,  1.5283e-01, -9.9243e-02, -8.5793e-06],\n",
      "         [-2.0610e-01,  1.0049e-01,  1.8430e-01,  2.4865e-02, -2.4282e-02],\n",
      "         [-1.8164e-01,  8.2339e-02,  9.3394e-02,  8.5102e-02, -6.5430e-02],\n",
      "         [-1.4815e-01, -2.0915e-02, -6.7356e-03,  3.2134e-02,  4.9501e-02]]],\n",
      "       device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-2.7608e-01, -9.3125e-03,  1.5258e-01, -1.7527e-01, -1.1473e-02],\n",
      "         [-1.0872e-01,  1.6845e-01,  8.8016e-02, -1.0098e-01,  1.6510e-02],\n",
      "         [-2.0604e-01,  2.2146e-01,  1.6762e-01, -9.4358e-02,  1.5243e-02],\n",
      "         [-2.3027e-01,  2.6626e-01,  9.7012e-02, -1.3203e-01, -3.6169e-02],\n",
      "         [-1.5236e-01,  9.4300e-02,  2.6185e-01, -2.2458e-01,  7.5039e-02],\n",
      "         [-2.3063e-01,  1.1417e-03,  3.3234e-01, -2.6076e-01, -8.6631e-03],\n",
      "         [-9.0614e-02,  1.4114e-02,  2.1292e-01, -1.3523e-01, -1.7166e-01],\n",
      "         [-1.9360e-02,  1.3802e-01,  4.9146e-02, -1.0795e-01,  4.9693e-02],\n",
      "         [-2.4886e-01,  2.5087e-01,  2.7308e-01, -9.3592e-02,  2.6453e-04],\n",
      "         [-3.1754e-01,  1.7162e-02,  2.9969e-01, -2.0476e-02,  3.0145e-02],\n",
      "         [-2.1855e-01, -1.1397e-01,  4.0062e-01, -1.8414e-02,  4.9129e-02]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1037, -0.0758,  0.0116, -0.0652,  0.1159],\n",
      "         [-0.0553,  0.0247,  0.1520, -0.1931,  0.0164],\n",
      "         [-0.0505,  0.1337,  0.0289, -0.1563,  0.1124],\n",
      "         [-0.1226,  0.0603,  0.1633, -0.1036, -0.0067],\n",
      "         [-0.2062,  0.1078,  0.1971,  0.0135, -0.0358],\n",
      "         [-0.1831,  0.0898,  0.0999,  0.0796, -0.0721],\n",
      "         [-0.1455, -0.0188, -0.0016,  0.0277,  0.0447]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-2.6189e-01, -9.4128e-04,  1.4906e-01, -1.8256e-01, -1.7512e-02],\n",
      "         [-1.1013e-01,  1.9479e-01,  9.6077e-02, -1.1258e-01,  9.8243e-05],\n",
      "         [-2.0778e-01,  2.4954e-01,  1.7391e-01, -1.0081e-01,  7.1754e-04],\n",
      "         [-2.3655e-01,  2.9561e-01,  1.0660e-01, -1.4558e-01, -5.6148e-02],\n",
      "         [-1.6310e-01,  1.0063e-01,  2.9373e-01, -2.4061e-01,  5.6900e-02],\n",
      "         [-2.4364e-01, -9.7675e-04,  3.7131e-01, -2.7410e-01, -2.3087e-02],\n",
      "         [-9.3218e-02,  5.2660e-03,  2.4709e-01, -1.4972e-01, -1.8435e-01],\n",
      "         [ 2.6169e-04,  1.4193e-01,  6.6427e-02, -1.2029e-01,  4.0122e-02],\n",
      "         [-2.5090e-01,  2.6988e-01,  2.9773e-01, -1.1214e-01, -1.9451e-02],\n",
      "         [-3.2993e-01,  2.3984e-02,  3.4236e-01, -3.9766e-02,  1.4400e-02],\n",
      "         [-2.2961e-01, -1.1542e-01,  4.4937e-01, -3.3948e-02,  3.2030e-02]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0999, -0.0756,  0.0129, -0.0670,  0.1137],\n",
      "         [-0.0586,  0.0233,  0.1638, -0.1996,  0.0091],\n",
      "         [-0.0488,  0.1376,  0.0329, -0.1582,  0.1082],\n",
      "         [-0.1254,  0.0648,  0.1738, -0.1080, -0.0134],\n",
      "         [-0.2063,  0.1151,  0.2100,  0.0020, -0.0474],\n",
      "         [-0.1845,  0.0975,  0.1062,  0.0740, -0.0790],\n",
      "         [-0.1428, -0.0168,  0.0035,  0.0233,  0.0399]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.2477,  0.0075,  0.1456, -0.1898, -0.0236],\n",
      "         [-0.1114,  0.2216,  0.1040, -0.1243, -0.0166],\n",
      "         [-0.2098,  0.2782,  0.1803, -0.1074, -0.0142],\n",
      "         [-0.2433,  0.3258,  0.1164, -0.1594, -0.0766],\n",
      "         [-0.1744,  0.1073,  0.3262, -0.2569,  0.0384],\n",
      "         [-0.2570, -0.0029,  0.4107, -0.2879, -0.0379],\n",
      "         [-0.0962, -0.0033,  0.2818, -0.1647, -0.1975],\n",
      "         [ 0.0199,  0.1462,  0.0837, -0.1327,  0.0305],\n",
      "         [-0.2531,  0.2898,  0.3223, -0.1309, -0.0396],\n",
      "         [-0.3428,  0.0314,  0.3856, -0.0593, -0.0018],\n",
      "         [-0.2410, -0.1167,  0.4986, -0.0495,  0.0146]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0959, -0.0756,  0.0141, -0.0687,  0.1117],\n",
      "         [-0.0620,  0.0219,  0.1757, -0.2063,  0.0018],\n",
      "         [-0.0471,  0.1416,  0.0369, -0.1601,  0.1039],\n",
      "         [-0.1282,  0.0694,  0.1843, -0.1125, -0.0202],\n",
      "         [-0.2064,  0.1227,  0.2230, -0.0095, -0.0592],\n",
      "         [-0.1859,  0.1056,  0.1125,  0.0683, -0.0859],\n",
      "         [-0.1400, -0.0146,  0.0086,  0.0189,  0.0351]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.2336,  0.0159,  0.1423, -0.1971, -0.0296],\n",
      "         [-0.1126,  0.2488,  0.1117, -0.1363, -0.0335],\n",
      "         [-0.2120,  0.3075,  0.1869, -0.1143, -0.0295],\n",
      "         [-0.2504,  0.3569,  0.1265, -0.1736, -0.0975],\n",
      "         [-0.1862,  0.1143,  0.3594, -0.2736,  0.0195],\n",
      "         [-0.2707, -0.0045,  0.4508, -0.3022, -0.0532],\n",
      "         [-0.0995, -0.0117,  0.3170, -0.1801, -0.2111],\n",
      "         [ 0.0397,  0.1508,  0.1012, -0.1452,  0.0208],\n",
      "         [-0.2554,  0.3105,  0.3469, -0.1499, -0.0603],\n",
      "         [-0.3561,  0.0395,  0.4296, -0.0793, -0.0187],\n",
      "         [-0.2527, -0.1179,  0.5484, -0.0653, -0.0033]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0918, -0.0756,  0.0152, -0.0703,  0.1098],\n",
      "         [-0.0653,  0.0206,  0.1875, -0.2129, -0.0058],\n",
      "         [-0.0454,  0.1455,  0.0408, -0.1621,  0.0997],\n",
      "         [-0.1310,  0.0740,  0.1949, -0.1169, -0.0271],\n",
      "         [-0.2066,  0.1305,  0.2359, -0.0210, -0.0710],\n",
      "         [-0.1873,  0.1140,  0.1186,  0.0627, -0.0930],\n",
      "         [-0.1372, -0.0125,  0.0137,  0.0144,  0.0304]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-2.1955e-01,  2.4439e-02,  1.3903e-01, -2.0440e-01, -3.5735e-02],\n",
      "         [-1.1360e-01,  2.7662e-01,  1.1936e-01, -1.4848e-01, -5.0803e-02],\n",
      "         [-2.1457e-01,  3.3745e-01,  1.9360e-01, -1.2135e-01, -4.5274e-02],\n",
      "         [-2.5795e-01,  3.8902e-01,  1.3685e-01, -1.8814e-01, -1.1910e-01],\n",
      "         [-1.9849e-01,  1.2182e-01,  3.9350e-01, -2.9065e-01,  7.8984e-05],\n",
      "         [-2.8495e-01, -5.7783e-03,  4.9163e-01, -3.1701e-01, -6.9060e-02],\n",
      "         [-1.0314e-01, -1.9703e-02,  3.5300e-01, -1.9617e-01, -2.2524e-01],\n",
      "         [ 5.9611e-02,  1.5578e-01,  1.1884e-01, -1.5803e-01,  1.0880e-02],\n",
      "         [-2.5791e-01,  3.3224e-01,  3.7159e-01, -1.6938e-01, -8.1543e-02],\n",
      "         [-3.6995e-01,  4.8295e-02,  4.7450e-01, -9.9783e-02, -3.6249e-02],\n",
      "         [-2.6477e-01, -1.1877e-01,  5.9899e-01, -8.1428e-02, -2.1704e-02]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0876, -0.0757,  0.0163, -0.0719,  0.1080],\n",
      "         [-0.0686,  0.0194,  0.1994, -0.2197, -0.0134],\n",
      "         [-0.0439,  0.1495,  0.0447, -0.1640,  0.0955],\n",
      "         [-0.1339,  0.0788,  0.2054, -0.1214, -0.0340],\n",
      "         [-0.2068,  0.1385,  0.2489, -0.0326, -0.0830],\n",
      "         [-0.1888,  0.1228,  0.1246,  0.0570, -0.1003],\n",
      "         [-0.1343, -0.0102,  0.0187,  0.0100,  0.0256]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 17. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 1.1498440504074097"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.2055,  0.0330,  0.1358, -0.2117, -0.0419],\n",
      "         [-0.1146,  0.3050,  0.1270, -0.1609, -0.0685],\n",
      "         [-0.2174,  0.3682,  0.2005, -0.1287, -0.0615],\n",
      "         [-0.2659,  0.4222,  0.1476, -0.2032, -0.1413],\n",
      "         [-0.2114,  0.1298,  0.4285, -0.3082, -0.0199],\n",
      "         [-0.2997, -0.0067,  0.5334, -0.3325, -0.0855],\n",
      "         [-0.1073, -0.0274,  0.3898, -0.2129, -0.2400],\n",
      "         [ 0.0797,  0.1612,  0.1368, -0.1711,  0.0008],\n",
      "         [-0.2606,  0.3549,  0.3965, -0.1893, -0.1035],\n",
      "         [-0.3843,  0.0578,  0.5206, -0.1210, -0.0546],\n",
      "         [-0.2773, -0.1194,  0.6506, -0.0980, -0.0408]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0833, -0.0758,  0.0173, -0.0734,  0.1063],\n",
      "         [-0.0720,  0.0183,  0.2113, -0.2265, -0.0212],\n",
      "         [-0.0423,  0.1534,  0.0486, -0.1658,  0.0914],\n",
      "         [-0.1369,  0.0838,  0.2160, -0.1259, -0.0410],\n",
      "         [-0.2070,  0.1469,  0.2619, -0.0441, -0.0952],\n",
      "         [-0.1904,  0.1321,  0.1306,  0.0513, -0.1077],\n",
      "         [-0.1313, -0.0078,  0.0238,  0.0056,  0.0208]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1914,  0.0416,  0.1325, -0.2190, -0.0480],\n",
      "         [-0.1154,  0.3341,  0.1345, -0.1736, -0.0865],\n",
      "         [-0.2205,  0.3999,  0.2077, -0.1364, -0.0783],\n",
      "         [-0.2744,  0.4566,  0.1587, -0.2188, -0.1643],\n",
      "         [-0.2249,  0.1383,  0.4647, -0.3264, -0.0406],\n",
      "         [-0.3151, -0.0073,  0.5763, -0.3486, -0.1025],\n",
      "         [-0.1118, -0.0349,  0.4275, -0.2303, -0.2555],\n",
      "         [ 0.1000,  0.1670,  0.1551, -0.1846, -0.0097],\n",
      "         [-0.2635,  0.3787,  0.4216, -0.2097, -0.1261],\n",
      "         [-0.3993,  0.0681,  0.5679, -0.1430, -0.0738],\n",
      "         [-0.2904, -0.1198,  0.7034, -0.1151, -0.0606]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0789, -0.0760,  0.0182, -0.0747,  0.1048],\n",
      "         [-0.0753,  0.0173,  0.2232, -0.2334, -0.0292],\n",
      "         [-0.0409,  0.1574,  0.0524, -0.1677,  0.0872],\n",
      "         [-0.1399,  0.0890,  0.2267, -0.1305, -0.0482],\n",
      "         [-0.2074,  0.1557,  0.2749, -0.0556, -0.1075],\n",
      "         [-0.1920,  0.1418,  0.1366,  0.0455, -0.1154],\n",
      "         [-0.1284, -0.0053,  0.0288,  0.0011,  0.0160]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1774,  0.0502,  0.1293, -0.2264, -0.0542],\n",
      "         [-0.1163,  0.3639,  0.1420, -0.1866, -0.1050],\n",
      "         [-0.2240,  0.4325,  0.2151, -0.1444, -0.0957],\n",
      "         [-0.2834,  0.4923,  0.1703, -0.2350, -0.1882],\n",
      "         [-0.2391,  0.1474,  0.5020, -0.3452, -0.0620],\n",
      "         [-0.3312, -0.0074,  0.6205, -0.3655, -0.1203],\n",
      "         [-0.1169, -0.0420,  0.4664, -0.2484, -0.2717],\n",
      "         [ 0.1205,  0.1732,  0.1739, -0.1986, -0.0204],\n",
      "         [-0.2666,  0.4035,  0.4470, -0.2307, -0.1496],\n",
      "         [-0.4149,  0.0792,  0.6168, -0.1660, -0.0940],\n",
      "         [-0.3040, -0.1199,  0.7576, -0.1328, -0.0814]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0744, -0.0762,  0.0190, -0.0761,  0.1033],\n",
      "         [-0.0786,  0.0164,  0.2351, -0.2403, -0.0372],\n",
      "         [-0.0395,  0.1614,  0.0562, -0.1696,  0.0830],\n",
      "         [-0.1431,  0.0944,  0.2373, -0.1351, -0.0554],\n",
      "         [-0.2078,  0.1648,  0.2879, -0.0672, -0.1200],\n",
      "         [-0.1937,  0.1521,  0.1426,  0.0396, -0.1232],\n",
      "         [-0.1255, -0.0026,  0.0340, -0.0035,  0.0111]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1633,  0.0589,  0.1259, -0.2337, -0.0604],\n",
      "         [-0.1171,  0.3945,  0.1494, -0.2000, -0.1239],\n",
      "         [-0.2279,  0.4661,  0.2228, -0.1528, -0.1137],\n",
      "         [-0.2928,  0.5293,  0.1824, -0.2518, -0.2129],\n",
      "         [-0.2541,  0.1571,  0.5407, -0.3648, -0.0843],\n",
      "         [-0.3480, -0.0071,  0.6662, -0.3832, -0.1388],\n",
      "         [-0.1226, -0.0488,  0.5064, -0.2675, -0.2888],\n",
      "         [ 0.1411,  0.1799,  0.1932, -0.2131, -0.0316],\n",
      "         [-0.2699,  0.4294,  0.4728, -0.2523, -0.1739],\n",
      "         [-0.4311,  0.0911,  0.6673, -0.1901, -0.1152],\n",
      "         [-0.3182, -0.1196,  0.8134, -0.1514, -0.1031]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-6.9874e-02, -7.6489e-02,  1.9738e-02, -7.7314e-02,  1.0191e-01],\n",
      "         [-8.1982e-02,  1.5499e-02,  2.4691e-01, -2.4735e-01, -4.5454e-02],\n",
      "         [-3.8124e-02,  1.6543e-01,  5.9818e-02, -1.7153e-01,  7.8759e-02],\n",
      "         [-1.4631e-01,  1.0002e-01,  2.4804e-01, -1.3986e-01, -6.2757e-02],\n",
      "         [-2.0841e-01,  1.7444e-01,  3.0088e-01, -7.8829e-02, -1.3279e-01],\n",
      "         [-1.9550e-01,  1.6284e-01,  1.4858e-01,  3.3573e-02, -1.3137e-01],\n",
      "         [-1.2264e-01,  2.0712e-04,  3.9214e-02, -8.0946e-03,  6.1644e-03]]],\n",
      "       device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1493,  0.0677,  0.1225, -0.2411, -0.0667],\n",
      "         [-0.1179,  0.4259,  0.1567, -0.2137, -0.1433],\n",
      "         [-0.2321,  0.5009,  0.2308, -0.1616, -0.1323],\n",
      "         [-0.3029,  0.5678,  0.1950, -0.2693, -0.2386],\n",
      "         [-0.2699,  0.1675,  0.5808, -0.3852, -0.1075],\n",
      "         [-0.3657, -0.0062,  0.7135, -0.4019, -0.1583],\n",
      "         [-0.1289, -0.0553,  0.5478, -0.2875, -0.3068],\n",
      "         [ 0.1619,  0.1871,  0.2132, -0.2282, -0.0434],\n",
      "         [-0.2734,  0.4566,  0.4990, -0.2748, -0.1992],\n",
      "         [-0.4481,  0.1040,  0.7196, -0.2154, -0.1375],\n",
      "         [-0.3331, -0.1191,  0.8709, -0.1709, -0.1259]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0652, -0.0768,  0.0204, -0.0785,  0.1006],\n",
      "         [-0.0853,  0.0147,  0.2587, -0.2544, -0.0538],\n",
      "         [-0.0368,  0.1695,  0.0634, -0.1735,  0.0745],\n",
      "         [-0.1497,  0.1059,  0.2588, -0.1447, -0.0703],\n",
      "         [-0.2091,  0.1845,  0.3138, -0.0905, -0.1458],\n",
      "         [-0.1975,  0.1742,  0.1546,  0.0274, -0.1398],\n",
      "         [-0.1198,  0.0032,  0.0445, -0.0129,  0.0011]]], device='cuda:0')\n",
      "batch1\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.1353,  0.0765,  0.1190, -0.2486, -0.0731],\n",
      "         [-0.1186,  0.4583,  0.1639, -0.2277, -0.1632],\n",
      "         [-0.2368,  0.5369,  0.2390, -0.1710, -0.1517],\n",
      "         [-0.3135,  0.6078,  0.2081, -0.2876, -0.2654],\n",
      "         [-0.2866,  0.1787,  0.6225, -0.4065, -0.1317],\n",
      "         [-0.3843, -0.0049,  0.7625, -0.4215, -0.1787],\n",
      "         [-0.1359, -0.0616,  0.5906, -0.3085, -0.3258],\n",
      "         [ 0.1829,  0.1948,  0.2338, -0.2441, -0.0557],\n",
      "         [-0.2772,  0.4850,  0.5256, -0.2981, -0.2255],\n",
      "         [-0.4657,  0.1177,  0.7737, -0.2421, -0.1611],\n",
      "         [-0.3488, -0.1181,  0.9303, -0.1914, -0.1499]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "here2\n",
      "here21\n",
      "tensor([[[-0.0605, -0.0772,  0.0209, -0.0796,  0.0994],\n",
      "         [-0.0887,  0.0140,  0.2704, -0.2615, -0.0623],\n",
      "         [-0.0356,  0.1737,  0.0668, -0.1754,  0.0702],\n",
      "         [-0.1531,  0.1121,  0.2696, -0.1496, -0.0780],\n",
      "         [-0.2099,  0.1951,  0.3266, -0.1023, -0.1591],\n",
      "         [-0.1996,  0.1861,  0.1608,  0.0211, -0.1486],\n",
      "         [-0.1171,  0.0064,  0.0500, -0.0178, -0.0042]]], device='cuda:0')\n",
      "Wall time: 6.97 s\n"
>>>>>>> 0c5a7873868780eda6eb91e0ef7fcdf757aa2d1f
     ]
    }
   ],
   "source": [
    "%time _ = seq_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
   "id": "c4d6a156",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T14:11:54.771750Z",
     "start_time": "2022-04-05T14:11:54.740082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here2\n",
      "here21\n",
      "tensor([[[ 0.0533, -0.0668,  0.0509, -0.1268, -0.0599],\n",
      "         [ 0.0757, -0.0614,  0.1302, -0.1578, -0.0358],\n",
      "         [ 0.0825, -0.0630,  0.1838, -0.1707, -0.0218],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920]],\n",
      "\n",
      "        [[ 0.0533, -0.0668,  0.0509, -0.1268, -0.0599],\n",
      "         [ 0.0757, -0.0614,  0.1302, -0.1578, -0.0358],\n",
      "         [ 0.0825, -0.0630,  0.1838, -0.1707, -0.0218],\n",
      "         [ 0.0855, -0.0644,  0.2189, -0.1760, -0.0134],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920]],\n",
      "\n",
      "        [[ 0.0533, -0.0668,  0.0509, -0.1268, -0.0599],\n",
      "         [ 0.0757, -0.0614,  0.1302, -0.1578, -0.0358],\n",
      "         [ 0.0825, -0.0630,  0.1838, -0.1707, -0.0218],\n",
      "         [ 0.0855, -0.0644,  0.2189, -0.1760, -0.0134],\n",
      "         [ 0.0873, -0.0644,  0.2421, -0.1783, -0.0081],\n",
      "         [ 0.0887, -0.0634,  0.2579, -0.1794, -0.0046],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920]],\n",
      "\n",
      "        [[ 0.0533, -0.0668,  0.0509, -0.1268, -0.0599],\n",
      "         [ 0.0757, -0.0614,  0.1302, -0.1578, -0.0358],\n",
      "         [ 0.0825, -0.0630,  0.1838, -0.1707, -0.0218],\n",
      "         [ 0.0855, -0.0644,  0.2189, -0.1760, -0.0134],\n",
      "         [ 0.0873, -0.0644,  0.2421, -0.1783, -0.0081],\n",
      "         [ 0.0887, -0.0634,  0.2579, -0.1794, -0.0046],\n",
      "         [ 0.0899, -0.0620,  0.2686, -0.1798, -0.0022],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920]],\n",
      "\n",
      "        [[ 0.0533, -0.0668,  0.0509, -0.1268, -0.0599],\n",
      "         [ 0.0757, -0.0614,  0.1302, -0.1578, -0.0358],\n",
      "         [ 0.0825, -0.0630,  0.1838, -0.1707, -0.0218],\n",
      "         [ 0.0855, -0.0644,  0.2189, -0.1760, -0.0134],\n",
      "         [ 0.0873, -0.0644,  0.2421, -0.1783, -0.0081],\n",
      "         [ 0.0887, -0.0634,  0.2579, -0.1794, -0.0046],\n",
      "         [ 0.0899, -0.0620,  0.2686, -0.1798, -0.0022],\n",
      "         [ 0.0911, -0.0604,  0.2761, -0.1798, -0.0005],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920]],\n",
      "\n",
      "        [[ 0.0533, -0.0668,  0.0509, -0.1268, -0.0599],\n",
      "         [ 0.0757, -0.0614,  0.1302, -0.1578, -0.0358],\n",
      "         [ 0.0825, -0.0630,  0.1838, -0.1707, -0.0218],\n",
      "         [ 0.0855, -0.0644,  0.2189, -0.1760, -0.0134],\n",
      "         [ 0.0873, -0.0644,  0.2421, -0.1783, -0.0081],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920]],\n",
      "\n",
      "        [[ 0.0533, -0.0668,  0.0509, -0.1268, -0.0599],\n",
      "         [ 0.0757, -0.0614,  0.1302, -0.1578, -0.0358],\n",
      "         [ 0.0825, -0.0630,  0.1838, -0.1707, -0.0218],\n",
      "         [ 0.0855, -0.0644,  0.2189, -0.1760, -0.0134],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920]],\n",
      "\n",
      "        [[ 0.0533, -0.0668,  0.0509, -0.1268, -0.0599],\n",
      "         [ 0.0757, -0.0614,  0.1302, -0.1578, -0.0358],\n",
      "         [ 0.0825, -0.0630,  0.1838, -0.1707, -0.0218],\n",
      "         [ 0.0855, -0.0644,  0.2189, -0.1760, -0.0134],\n",
      "         [ 0.0873, -0.0644,  0.2421, -0.1783, -0.0081],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920]],\n",
      "\n",
      "        [[ 0.0533, -0.0668,  0.0509, -0.1268, -0.0599],\n",
      "         [ 0.0757, -0.0614,  0.1302, -0.1578, -0.0358],\n",
      "         [ 0.0825, -0.0630,  0.1838, -0.1707, -0.0218],\n",
      "         [ 0.0855, -0.0644,  0.2189, -0.1760, -0.0134],\n",
      "         [ 0.0873, -0.0644,  0.2421, -0.1783, -0.0081],\n",
      "         [ 0.0887, -0.0634,  0.2579, -0.1794, -0.0046],\n",
      "         [ 0.0899, -0.0620,  0.2686, -0.1798, -0.0022],\n",
      "         [ 0.0911, -0.0604,  0.2761, -0.1798, -0.0005],\n",
      "         [ 0.0630, -0.1006,  0.2509, -0.1372, -0.1017],\n",
      "         [ 0.0803, -0.0680,  0.2470, -0.1644, -0.0288],\n",
      "         [ 0.0892, -0.0512,  0.2553, -0.1770, -0.0134]],\n",
      "\n",
      "        [[ 0.0533, -0.0668,  0.0509, -0.1268, -0.0599],\n",
      "         [ 0.0757, -0.0614,  0.1302, -0.1578, -0.0358],\n",
      "         [ 0.0825, -0.0630,  0.1838, -0.1707, -0.0218],\n",
      "         [ 0.0855, -0.0644,  0.2189, -0.1760, -0.0134],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920]],\n",
      "\n",
      "        [[ 0.0533, -0.0668,  0.0509, -0.1268, -0.0599],\n",
      "         [ 0.0757, -0.0614,  0.1302, -0.1578, -0.0358],\n",
      "         [ 0.0825, -0.0630,  0.1838, -0.1707, -0.0218],\n",
      "         [ 0.0855, -0.0644,  0.2189, -0.1760, -0.0134],\n",
      "         [ 0.0873, -0.0644,  0.2421, -0.1783, -0.0081],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920],\n",
      "         [-0.0329, -0.1122, -0.0464, -0.0639, -0.0920]]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['B', 'O', 'O'],\n",
       " ['B', 'O', 'O', 'O'],\n",
       " ['B', 'O', 'O', 'O', 'O', 'O'],\n",
       " ['B', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       " ['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       " ['B', 'O', 'O', 'O', 'O'],\n",
       " ['B', 'O', 'O', 'O'],\n",
       " ['B', 'O', 'O', 'O', 'O'],\n",
       " ['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       " ['B', 'O', 'O', 'O'],\n",
       " ['B', 'O', 'O', 'O', 'O']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_mod.predict(\"the wall street journal reported today that apple corporation made money\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
=======
   "execution_count": 99,
>>>>>>> 0c5a7873868780eda6eb91e0ef7fcdf757aa2d1f
   "id": "ceee1a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchcrf import CRF\n",
    "\n",
    "class TorchCRFSequenceLabeler(TorchRNNClassifier):\n",
    "\n",
    "    def build_graph(self): # uses this build_graph instead of TorchRNNClassifier.build_graph\n",
    "        print(\"here0\")\n",
    "        rnn = TorchRNNModel(\n",
    "            vocab_size=len(self.vocab),\n",
    "            embedding=self.embedding,\n",
    "            use_embedding=self.use_embedding,\n",
    "            embed_dim=self.embed_dim,\n",
    "            rnn_cell_class=self.rnn_cell_class,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            bidirectional=self.bidirectional,\n",
    "            freeze_embedding=self.freeze_embedding)\n",
    "        print(\"here02\")\n",
    "        model = CRF(num_tags)\n",
    "       # model = TorchSequenceLabeler( # this defines self.model\n",
    "       #     rnn=rnn,\n",
    "       #     output_dim=self.n_classes_)\n",
    "       # self.embed_dim = rnn.embed_dim\n",
    "        return model\n",
    "\n",
    "    def build_dataset(self, X, y=None):\n",
    "        START_TAG = \"<START>\"\n",
    "        STOP_TAG = \"<STOP>\"\n",
    "        X, seq_lengths = self._prepare_sequences(X) # converts tokens into tokenIds\n",
    "        if y is None:\n",
    "            return TorchRNNDataset(X, seq_lengths)\n",
    "        else:\n",
    "            # These are the changes from a regular classifier. All\n",
    "            # concern the fact that our labels are sequences of labels.\n",
    "            self.classes_ = sorted({x for seq in y for x in seq})\n",
    "            self.n_classes_ = len(self.classes_)\n",
    "            class2index = dict(zip(self.classes_, range(2,self.n_classes_+2))) # start at id=2\n",
    "            class2index[STOP_TAG]=0    # add start and stop tags (note: stop needs to be 0 as that is default for padding in collate_fn)\n",
    "            class2index[START_TAG]=1 \n",
    "            print(class2index)\n",
    "            # `y` is a list of tensors of different length. Our Dataset\n",
    "            # class will turn it into a padding tensor for processing.\n",
    "            y = [torch.tensor([class2index[label] for label in seq])\n",
    "                 for seq in y] # converts labels to indices\n",
    "            return TorchRNNDataset(X, seq_lengths, y)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        seq_lengths = [len(ex) for ex in X]\n",
    "        # The base class does the heavy lifting:\n",
    "        preds = self._predict(X)\n",
    "        # Trim to the actual sequence lengths:\n",
    "        preds = [p[: l] for p, l in zip(preds, seq_lengths)]\n",
    "        # Use `softmax`; the model doesn't do this because the loss\n",
    "        # function does it internally.\n",
    "        probs = [torch.softmax(seq, dim=1) for seq in preds]\n",
    "        return probs\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        return [[self.classes_[i] for i in seq.argmax(axis=1)] for seq in probs] # seq.argmax(axis=1) gives index of col that maximizes softmax prob\n",
    "        # see difference vs TorchRNNClassifier.predict\n",
    "\n",
    "    def score(self, X, y):\n",
    "        preds = self.predict(X)\n",
    "        flat_preds = [x for seq in preds for x in seq]\n",
    "        flat_y = [x for seq in y for x in seq]\n",
    "        return utils.safe_macro_f1(flat_y, flat_preds)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f6014b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following converts words to indices and pads sequences\n",
    "seq_mod = TorchCRFSequenceLabeler(\n",
    "    vocab,\n",
    "    early_stopping=True,\n",
    "    eta=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70ec885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [\"the wall street journal reported today that apple corporation made money\".split(),\"georgia tech is a university in georgia\".split()]\n",
    "y_train = [\"B I I I O O O B I O O\".split(),\"B I O O O O B\".split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f43c9772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B': 2, 'I': 3, 'O': 4, '<STOP>': 0, '<START>': 1}\n",
      "tensor([[13, 16, 10,  6,  9, 14, 12,  1,  2,  7,  8],\n",
      "        [ 3, 11,  5,  0, 15,  4,  3,  0,  0,  0,  0]])\n",
      "tensor([11,  7])\n",
      "tensor([[2, 3, 3, 3, 4, 4, 4, 2, 3, 4, 4],\n",
      "        [2, 3, 4, 4, 4, 4, 2, 0, 0, 0, 0]])\n",
      "tensor([11,  7])\n",
      "tensor([[ 0.0457,  0.1530, -0.4757, -1.8821, -0.7765],\n",
      "        [ 2.0242, -0.0865,  0.0981, -1.0373,  1.5748],\n",
      "        [-0.6298,  2.4070,  0.2786,  0.2468,  1.1843],\n",
      "        [-0.7282,  0.4415,  1.1651,  2.0154,  0.2152],\n",
      "        [-0.5242, -1.8034, -1.3083,  0.4533, -0.8696],\n",
      "        [-3.3312, -0.7479,  1.1173,  0.2981,  0.1099],\n",
      "        [-0.6463,  0.4285, -0.0075,  1.6734,  0.0103],\n",
      "        [ 0.9837,  0.8793, -1.4504, -1.1802,  1.3075],\n",
      "        [-1.1628,  0.1196, -0.1631,  0.6614,  1.1899],\n",
      "        [ 0.8165, -0.9135, -0.3538,  0.7639, -0.5890],\n",
      "        [-0.7636,  1.3352,  0.6043, -0.1034, -0.1512]])\n",
      "torch.Size([1, 11])\n",
      "tensor(-23.6227, grad_fn=<SumBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0277,  0.0049,  0.0365, -0.0390, -0.0073],\n",
      "        [-0.0090,  0.0145, -0.0004,  0.0874,  0.0311],\n",
      "        [-0.0372, -0.0604, -0.0168, -0.0431, -0.0320],\n",
      "        [ 0.0048,  0.0596,  0.0544, -0.0978,  0.0620],\n",
      "        [ 0.0279,  0.0949,  0.0660, -0.0911, -0.0951]], requires_grad=True)\n",
      "[[0], [0], [1], [3], [3], [2], [3], [4], [4], [0], [1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasco\\AppData\\Local\\Temp/ipykernel_17200/1289059235.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y=torch.tensor(y[1]).view(1,-1)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "dataset = seq_mod.build_dataset(X_train, y_train) \n",
    "dataloader = seq_mod._build_dataloader(dataset, shuffle=False) \n",
    "num_tags = 5\n",
    "model = CRF(num_tags)\n",
    "for batch_num, batch in enumerate(dataloader, start=1):\n",
    "    x=batch[0]   \n",
    "    print(x)\n",
    "    seq_length=batch[1]\n",
    "    print(seq_length)\n",
    "    y=batch[2] \n",
    "    print(y)\n",
    "    print(seq_length)\n",
    "batch_size=1\n",
    "emissions = torch.randn(batch_size, max(seq_length), num_tags)\n",
    "print(emissions[0])\n",
    "y=torch.tensor(y[1]).view(1,-1)\n",
    "print(y.shape)\n",
    "print(model(emissions,y)) # computes log likelihood\n",
    "#model.decode(emissions)\n",
    "a=model.transitions\n",
    "print(a)\n",
    "print(model.decode(emissions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ed9f4b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.5731, grad_fn=<SumBackward0>)\n",
      "tensor([[[-0.4519, -0.1661]]])\n",
      "tensor([[1]])\n",
      "Parameter containing:\n",
      "tensor([[-0.0941,  0.0600],\n",
      "        [-0.0206,  0.0509]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0515, -0.0441], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0194,  0.0469], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# this is where I matched my first model score (i.e. log likelihood of crf)\n",
    "torch.manual_seed(1)\n",
    "seq_length = 1  # maximum sequence length in a batch\n",
    "batch_size = 1  # number of samples in the batch\n",
    "num_tags=2\n",
    "model = CRF(num_tags,batch_first=True)\n",
    "#emissions = torch.randn(batch_size, seq_length, num_tags)\n",
    "#tags = torch.tensor([[0, 2, 3], [1, 4, 1]], dtype=torch.long)  # (batch_size, seq_length)\n",
    "emissions = torch.randn(1, seq_length, num_tags)\n",
    "\n",
    "tags = torch.tensor([[1]], dtype=torch.long)  \n",
    "print(model(emissions, tags))\n",
    "print(emissions)\n",
    "print(tags)\n",
    "print(model.transitions)\n",
    "print(model.start_transitions)\n",
    "print(model.end_transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "59964b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-8.3568, grad_fn=<SumBackward0>)\n",
      "[[3, 4, 3], [4, 1]]\n",
      "tensor(-2.7487, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# add mask vector so as to not to consider padding part of sequences\n",
    "# e.g. want to mask last zero of 2nd obs\n",
    "torch.manual_seed(1)\n",
    "seq_length = 3  # maximum sequence length in a batch\n",
    "batch_size = 2  # number of samples in the batch\n",
    "num_tags=5\n",
    "model = CRF(num_tags,batch_first=True)\n",
    "emissions = torch.randn(batch_size, seq_length, num_tags)\n",
    "tags = torch.tensor([[1, 2, 3], [1, 4, 0]], dtype=torch.long)  # (batch_size, seq_length)\n",
    "mask = torch.tensor([[1, 1, 1], [1, 1, 0]], dtype=torch.uint8) # i.e. mask 3rd token of 2nd example in batch\n",
    "# 1.\n",
    "print(model(emissions, tags, mask=mask)) # model log likelihood\n",
    "# 2.\n",
    "print(model.decode(emissions,mask=mask)) # most likely tag sequences\n",
    "# 3. inference:\n",
    "tags_test = torch.tensor([[1, 2, 3]], dtype=torch.long)  # (batch_size, seq_length)\n",
    "print(model.forward(emissions[0].unsqueeze(dim=0),tags_test)) # returns log likelihood of test tag sequence (larger no. means more likely)\n",
    "# note: need to use torch array w/ same no. of examples as tags_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "d5c17e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "# note: this isn't exactly correct as training examples are shuffled (esp. max len of the smaller 12 ex batch is != 92)\n",
    "auxMax=0\n",
    "x_max_idx=108\n",
    "for i in range(0,min(len(X_train),x_max_idx)):\n",
    "    if len(X_train[i])>auxMax:\n",
    "        auxMax=len(X_train[i])\n",
    "print(auxMax)\n",
    "auxMax2=0\n",
    "x_min_idx=109\n",
    "for i in range(max(0,x_min_idx),len(X_train)):\n",
    "    if len(X_train[i])>auxMax2:\n",
    "        auxMax2=len(X_train[i])\n",
    "print(auxMax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cfe2a431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ORT', 'O', 'O', 'STRASSE', 'STRASSE', 'O', 'ORT', 'O', 'O', 'FLAECHE', 'O', 'O', 'IMMO_TYP', 'O', 'O', 'O', 'O', 'QMPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'VERKAEUFER', 'O', 'O', 'O', 'O', 'O', 'GESAMTPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERTRAG', 'DATUM_VERTRAG', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERBUECHERUNG', 'DATUM_VERBUECHERUNG', 'O']\n",
      "['KAEUFER', 'KAEUFER', 'O', 'O', 'KAEUFER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'IMMO_TYP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "y_pred = seq_mod.predict(X_test)\n",
    "print(y_test[0])\n",
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2960fed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=seq_mod.classes_\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d615f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfold all our data - NOTE: this means we don't care about per sentence results. \n",
    "# i.e. each classification is worth same regardless of sentence in which it occurs\n",
    "y_test_unfold = [y for element in y_test for y in element]\n",
    "y_pred_unfold = [y for element in y_pred for y in element]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "99efc2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ORT', 'O', 'O', 'STRASSE', 'STRASSE', 'O', 'ORT', 'O', 'O', 'FLAECHE']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(y_test_unfold[:10])\n",
    "print(y_pred_unfold[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5de61d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert y_test and y_pred into binary formats\n",
    "#from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7f4747c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                  O      0.808     0.888     0.846       643\n",
      "            KAEUFER      0.070     0.278     0.112        18\n",
      "DATUM_VERBUECHERUNG      0.000     0.000     0.000        25\n",
      "      DATUM_VERTRAG      1.000     0.037     0.071        27\n",
      "         VERKAEUFER      0.333     0.042     0.074        24\n",
      "   TERRASSENGROESSE      0.000     0.000     0.000         5\n",
      "        GESAMTPREIS      0.000     0.000     0.000        11\n",
      "            FLAECHE      0.000     0.000     0.000        15\n",
      "           IMMO_TYP      0.000     0.000     0.000        19\n",
      "            QMPREIS      0.000     0.000     0.000        10\n",
      "                ORT      0.000     0.000     0.000        26\n",
      "            STRASSE      0.118     0.125     0.121        16\n",
      "\n",
      "           accuracy                          0.691       839\n",
      "          macro avg      0.194     0.114     0.102       839\n",
      "       weighted avg      0.664     0.691     0.657       839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(\n",
    "    y_test_unfold, y_pred_unfold, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d9457a",
   "metadata": {},
   "source": [
    "Now try with leading \"B-\" and \"I-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a6f7276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## ONLY RUN IF WE WANT TO ADD LEADING \"B-\" / \"I-\" TO CLASS LABEL\n",
    "# now use above code and loop through all items of annot list:\n",
    "# addLeading=1 for \"Yes\" (i.e. add leading \"B-\",\"I-\" to annot); 0 for \"No\" (i.e. add labels to annot simply as they are)\n",
    "addLeading = 1\n",
    "\n",
    "if addLeading == 1:\n",
    "    for j in range(0,len(annot)):\n",
    "        a = annot[j]\n",
    "        # select list of dict of tokens w/ annnotations and add column w/ no. of words to each dict:\n",
    "        b = a['spans']\n",
    "        # add noWords to b dict. note: b is list of dicts w/ annotations; tokens not on this list don't have annotations\n",
    "        if b!=[]: #i.e. only try to add annotations to tokens if there are annotations to begin with\n",
    "            #print(b)\n",
    "            for i in range(0,len(annot[j]['tokens'])):\n",
    "                    # now break-up label into 1st occurrence (leading \"B-\") and subsequent occurrences (leading \"I-\") (only for non \"O\"'s)\n",
    "                    if annot[j]['tokens'][i]['label'] != \"O\":\n",
    "                        if i==0:\n",
    "                            annot[j]['tokens'][i]['label'] = \"B-\" + annot[j]['tokens'][i]['label']\n",
    "                        else: \n",
    "                            if annot[j]['tokens'][i]['label'] == annot[j]['tokens'][i-1]['label'][2:]: # need to remove the leading \"B-\" that we had already been added to c[i-1]\n",
    "                                annot[j]['tokens'][i]['label'] = \"I-\" + annot[j]['tokens'][i]['label']\n",
    "                            else:\n",
    "                                annot[j]['tokens'][i]['label'] = \"B-\" + annot[j]['tokens'][i]['label'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e6bd88ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get data into format that TorchRNN expects:\n",
    "X=[] \n",
    "y=[]\n",
    "for j in range(0,len(annot)):\n",
    "    a = annot[j]['tokens']\n",
    "    auxX = []\n",
    "    auxy = []\n",
    "    if annot[j]['spans']!=[]: # are there annot for this example?\n",
    "        for i in range(0,len(a)):\n",
    "            #token_element = (a[i]['text'],a[i]['label'])\n",
    "            auxX.append(a[i]['text'])\n",
    "            auxy.append(a[i]['label'])\n",
    "        X.append(auxX)\n",
    "        y.append(auxy)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_train, X_test, y_train, y_test = X[:120], X[120:], y[:120], y[120:]\n",
    "vocab = sorted({w for seq in X_train for w in seq}) + [\"$UNK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "353255ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DORNBIRN', 'In', 'der', 'Schulgasse', 'in', 'Dornbirn', 'hat', 'eine', '71,93', 'Quadratmeter', 'große', 'Wohnung', 'für', 'einen', 'Quadratmeterpreis', 'von', '5533,71', 'Euro', 'den', 'Besitzer', 'gewechselt', '.', 'Dieser', 'beinhaltet', 'auch', 'einen', 'Pkw-Abstellplatz', '.', 'Käufer', 'der', 'Wohnung', 'mit', '9,86', 'Quadratmetern', 'Terrasse', 'ist', 'die', 'ValLiLean', 'Beteiligungs-', 'und', 'Immobilienverwaltungs', 'GmbH', 'Beim', 'Verkäufer', 'handelt', 'es', 'sich', 'um', 'die', 'Karrenblick', 'Projekt', 'GmbH', ' ', 'Der', 'Kaufpreis', 'liegt', 'bei', '398.040', 'Euro', '.', 'Unterzeichnet', 'wurde', 'der', 'Kaufvertrag', 'am', '18.', 'September', '.', 'Die', 'Verbücherung', 'datiert', 'mit', 'Oktober', '2020', '.', '.', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "071c6a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 35. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 2.249159574508667"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.78 s\n",
      "['B-ORT', 'O', 'O', 'B-STRASSE', 'I-STRASSE', 'O', 'B-ORT', 'O', 'O', 'B-FLAECHE', 'O', 'O', 'B-IMMO_TYP', 'O', 'O', 'O', 'O', 'B-QMPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-VERKAEUFER', 'O', 'O', 'O', 'O', 'O', 'B-GESAMTPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATUM_VERTRAG', 'I-DATUM_VERTRAG', 'O', 'O', 'O', 'O', 'O', 'B-DATUM_VERBUECHERUNG', 'I-DATUM_VERBUECHERUNG', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "%time _ = seq_mod.fit(X_train, y_train)\n",
    "y_pred = seq_mod.predict(X_test)\n",
    "print(y_test[0])\n",
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "92a8a32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=seq_mod.classes_\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b338e92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfold all our data - NOTE: this means we don't care about per sentence results. \n",
    "# i.e. each classification is worth same regardless of sentence in which it occurs\n",
    "y_test_unfold = [y for element in y_test for y in element]\n",
    "y_pred_unfold = [y for element in y_pred for y in element]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "78515133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                    O      0.773     0.988     0.867       643\n",
      "B-DATUM_VERBUECHERUNG      0.000     0.000     0.000        13\n",
      "I-DATUM_VERBUECHERUNG      0.000     0.000     0.000        12\n",
      "      B-DATUM_VERTRAG      0.000     0.000     0.000        13\n",
      "      I-DATUM_VERTRAG      0.000     0.000     0.000        14\n",
      "            B-FLAECHE      0.000     0.000     0.000        15\n",
      "            I-FLAECHE      0.000     0.000     0.000         0\n",
      "        B-GESAMTPREIS      0.000     0.000     0.000        11\n",
      "        I-GESAMTPREIS      0.000     0.000     0.000         0\n",
      "           B-IMMO_TYP      0.000     0.000     0.000        19\n",
      "           I-IMMO_TYP      0.000     0.000     0.000         0\n",
      "            B-KAEUFER      0.000     0.000     0.000        10\n",
      "            I-KAEUFER      0.000     0.000     0.000         8\n",
      "                B-ORT      0.300     0.115     0.167        26\n",
      "            B-QMPREIS      0.000     0.000     0.000        10\n",
      "            I-QMPREIS      0.000     0.000     0.000         0\n",
      "            B-STRASSE      0.000     0.000     0.000        12\n",
      "            I-STRASSE      0.000     0.000     0.000         4\n",
      "   B-TERRASSENGROESSE      0.000     0.000     0.000         5\n",
      "         B-VERKAEUFER      0.000     0.000     0.000        13\n",
      "         I-VERKAEUFER      0.000     0.000     0.000        11\n",
      "\n",
      "            micro avg      0.760     0.760     0.760       839\n",
      "            macro avg      0.051     0.053     0.049       839\n",
      "         weighted avg      0.601     0.760     0.670       839\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasco\\anaconda3\\envs\\xcs224u\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(\n",
    "    y_test_unfold, y_pred_unfold, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0680fd70",
   "metadata": {},
   "source": [
    "Remove \"B-\" and \"I-\" (in case they are present in labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9a2de8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0,len(annot)):\n",
    "    a = annot[j]\n",
    "    b = a['spans']\n",
    "    if b!=[]: #i.e. only try to add annotations to tokens if there are annotations to begin with\n",
    "        for i in range(0,len(annot[j]['tokens'])):\n",
    "                if annot[j]['tokens'][i]['label'] != \"O\":\n",
    "                    if annot[j]['tokens'][i]['label'][:2]==\"B-\" or annot[j]['tokens'][i]['label'][:2]==\"I-\":\n",
    "                        annot[j]['tokens'][i]['label']=annot[j]['tokens'][i]['label'][2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f22b42",
   "metadata": {},
   "source": [
    "Try bi-directional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "147649d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_mod = TorchRNNSequenceLabeler(\n",
    "    vocab,\n",
    "    early_stopping=True,\n",
    "    eta=0.001,\n",
    "    bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "63ca2332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ORT', 'O', 'O', 'STRASSE', 'O', 'ORT', 'O', 'O', 'FLAECHE', 'O', 'O', 'IMMO_TYP', 'O', 'O', 'O', 'O', 'QMPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'TERRASSENGROESSE', 'O', 'O', 'O', 'O', 'KAEUFER', 'KAEUFER', 'KAEUFER', 'KAEUFER', 'KAEUFER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'VERKAEUFER', 'VERKAEUFER', 'VERKAEUFER', 'O', 'O', 'O', 'O', 'O', 'GESAMTPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERTRAG', 'DATUM_VERTRAG', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERBUECHERUNG', 'DATUM_VERBUECHERUNG', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8413a3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 18. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 2.1157665252685547"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.12 s\n"
     ]
    }
   ],
   "source": [
    "%time _ = seq_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8d5884c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ORT', 'O', 'O', 'STRASSE', 'STRASSE', 'O', 'ORT', 'O', 'O', 'FLAECHE', 'O', 'O', 'IMMO_TYP', 'O', 'O', 'O', 'O', 'QMPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'VERKAEUFER', 'O', 'O', 'O', 'O', 'O', 'GESAMTPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERTRAG', 'DATUM_VERTRAG', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERBUECHERUNG', 'DATUM_VERBUECHERUNG', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'IMMO_TYP', 'O', 'O', 'TERRASSENGROESSE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'TERRASSENGROESSE', 'TERRASSENGROESSE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                  O      0.760     0.893     0.821       643\n",
      "            KAEUFER      0.000     0.000     0.000        18\n",
      "DATUM_VERBUECHERUNG      0.000     0.000     0.000        25\n",
      "      DATUM_VERTRAG      0.000     0.000     0.000        27\n",
      "         VERKAEUFER      0.000     0.000     0.000        24\n",
      "   TERRASSENGROESSE      0.000     0.000     0.000         5\n",
      "        GESAMTPREIS      0.000     0.000     0.000        11\n",
      "            FLAECHE      0.000     0.000     0.000        15\n",
      "           IMMO_TYP      0.000     0.000     0.000        19\n",
      "            QMPREIS      0.000     0.000     0.000        10\n",
      "                ORT      0.000     0.000     0.000        26\n",
      "            STRASSE      0.000     0.000     0.000        16\n",
      "\n",
      "           accuracy                          0.684       839\n",
      "          macro avg      0.063     0.074     0.068       839\n",
      "       weighted avg      0.583     0.684     0.629       839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = seq_mod.predict(X_test)\n",
    "print(y_test[0])\n",
    "print(y_pred[0])\n",
    "\n",
    "labels=seq_mod.classes_\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "\n",
    "# unfold all our data - NOTE: this means we don't care about per sentence results. \n",
    "# i.e. each classification is worth same regardless of sentence in which it occurs\n",
    "y_test_unfold = [y for element in y_test for y in element]\n",
    "y_pred_unfold = [y for element in y_pred for y in element]\n",
    "\n",
    "print(classification_report(\n",
    "    y_test_unfold, y_pred_unfold, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195d592b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchtext2",
   "language": "python",
   "name": "torchtext2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

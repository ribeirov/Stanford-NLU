{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d8a9a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Robert Guthrie\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48596709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.metrics import classification_report, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#from torch_model_base import TorchModelBase\n",
    "#from torch_shallow_neural_classifier import TorchShallowNeuralClassifier\n",
    "from torch_rnn_classifier import TorchRNNDataset, TorchRNNClassifier, TorchRNNModel\n",
    "import utils\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbf2ea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_ix): # converts one list of tokens into one tensor of token ids\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
    "def log_sum_exp(vec):\n",
    "    # Inp: torch array (1,nTags) of next tag scores (accumul transmission + emission); Out: single number tensor\n",
    "    # see crfCalcs.xlsx\n",
    "   # max_score = vec[0, argmax(vec)]\n",
    "    max_score = vec[0, torch.argmax(vec,axis=1)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + \\\n",
    "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
    "\n",
    "def prepare_sequences(seqs, to_ix):\n",
    "    idxs = [prepare_sequence(seq, to_ix) for seq in seqs]\n",
    "    #return torch.tensor(idxs, dtype=torch.long)\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "c6efe494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5410, -0.2934, -2.1788,  0.5684, -1.0845]])\n",
      "tensor([2.0323])\n"
     ]
    }
   ],
   "source": [
    "from torch import manual_seed\n",
    "torch.manual_seed(0)\n",
    "a = torch.randn((1,5))\n",
    "print(a)\n",
    "b = log_sum_exp(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "86b1fbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2514, -1.8709, -0.0724,  0.1736, -2.0898],\n",
      "        [-0.2333, -0.3052, -0.4891, -1.5174, -0.6644]])\n",
      "0\n",
      "tensor([ 0.2514, -1.8709, -0.0724,  0.1736, -2.0898])\n",
      "1\n",
      "tensor([-0.2333, -0.3052, -0.4891, -1.5174, -0.6644])\n"
     ]
    }
   ],
   "source": [
    "c = torch.randn((2,5))\n",
    "print(c)\n",
    "for i, feat in enumerate(c):\n",
    "    print(i)\n",
    "    print(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b19a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM_CRF(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix \n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True)\n",
    "\n",
    "        # Maps the output of the LSTM into tag space.\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
    "       \n",
    "        self.transitions = self.init_transitions()\n",
    "\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_transitions(self): # Matrix of transition parameters. Entry i,j is the score of transitioning *to* i *from* j.\n",
    "        # KEEP\n",
    "        transitions = nn.Parameter(torch.randn(self.tagset_size, self.tagset_size)) # initialize w/ random numbers (5,5) array\n",
    "        # These two statements enforce the constraint that we never transfer\n",
    "        # to the start tag and we never transfer from the stop tag\n",
    "        transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "        transitions.data[:, tag_to_ix[STOP_TAG]] = -10000   \n",
    "        return transitions\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # KEEP\n",
    "        return (torch.randn(2, 1, self.hidden_dim // 2), # here are dividing hidden dim by 2; since bidir end up w/ 2x (=4 tot hid layer)\n",
    "                torch.randn(2, 1, self.hidden_dim // 2))\n",
    "\n",
    "    def _forward_alg(self, feats):\n",
    "        # KEEP\n",
    "        # Inp: feats is tensor (noTokens,noDiffLabelClasses = tagset_size) = (11,5); Out: tensor 1d\n",
    "        # Do the forward algorithm to compute the partition function\n",
    "        init_alphas = torch.full((1, self.tagset_size), -10000.) # Inp: self.tagset_size=5 ; Out: tensor (1,5)=-10000\n",
    "        # START_TAG has all of the score.\n",
    "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0. # updates START_TAG Id of init_alphas[0] to be = 0\n",
    "\n",
    "        # Wrap in a variable so that we will get automatic backprop\n",
    "        forward_var = init_alphas\n",
    "\n",
    "        # Iterate through the sentence\n",
    "        for feat in feats: # iterate through each diff token (feat)\n",
    "            alphas_t = []  # The forward tensors at this timestep\n",
    "            for next_tag in range(self.tagset_size): # iterate through each tag\n",
    "                # broadcast the emission score: it is the same regardless of the previous tag\n",
    "                emit_score = feat[next_tag].view(\n",
    "                    1, -1).expand(1, self.tagset_size) # feat[next_tag] is tensor sngl no. w/ gradFn=\"select_bckwd\"; \n",
    "                # emit score is (1,tagset_size) w/ gradFn=\"ExpandBackward\"\n",
    "                # note: in this formula view(1,-1) squishes sngl no. into (1,1) array and expand(1,5) expands it into (1,5) array\n",
    "                ###########################################################################################\n",
    "                # the ith entry of trans_score is the score of transitioning to next_tag from i\n",
    "                trans_score = self.transitions[next_tag].view(1, -1) # self.transitions is (5,5) torch array; trans_score is (1,5)\n",
    "                # The ith entry of next_tag_var is the value for the\n",
    "                # edge (i -> next_tag) before we do log-sum-exp\n",
    "                next_tag_var = forward_var + trans_score + emit_score # next_tag_var is (1,5)\n",
    "                # The forward variable for this tag is log-sum-exp of all the\n",
    "                # scores.\n",
    "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        alpha = log_sum_exp(terminal_var)\n",
    "        return alpha\n",
    "\n",
    "    def _get_lstm_features(self, sentence):\n",
    "        # Input: sentence is list (noTokens); Output lstm_feats is tensor (noTokens,noDiffLabelClasses = len(tag_to_ix))\n",
    "        self.hidden = self.init_hidden() # self.hidden becomes (a,b) where both are tensors (2,1,2) hidden_dim=4 // 2\n",
    "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1) # embeds is tensor (noTokens,1,embedding_dim) = (11,1,6)\n",
    "        lstm_out, self.hidden = self.lstm(embeds, self.hidden) # self.hidden becomes (a,b) where both are tensors (2,1,2) hidden_dim=4 // 2\n",
    "        # lstm_out is (11,1,4) - last dim is = hidd_dim*2 as bidirect LSTM (NOTE: hidd_dim = self.hidden_dim / 2)\n",
    "        # Note also: by default there is NO BATCHING so lstm_out is (seq, batch, feature) instead of (batch, seq, feature)\n",
    "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim) # \"squishes\" middle redundant dimension: (11,4)\n",
    "        lstm_feats = self.hidden2tag(lstm_out) # FCL that maps from (11,4) to (11,5) where 5 is the tagset space\n",
    "       # print(\"lstm_feats\")\n",
    "       # print(lstm_feats.shape)\n",
    "        return lstm_feats\n",
    "\n",
    "    def _score_sentence(self, feats, tags):\n",
    "        # KEEP\n",
    "        # Gives the score of a provided tag sequence - see crfCalcs.xlsx\n",
    "        score = torch.zeros(1)\n",
    "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags]) # add START_TAG to sentence tags\n",
    "        for i, feat in enumerate(feats): # iterating thru' all tokens of feats; columns are 1 ... nTags\n",
    "            score = score + \\\n",
    "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
    "        return score\n",
    "\n",
    "    def _viterbi_decode(self, feats): # feats is (11,5) i.e. LSTM produced prob of each token being associated w/ each of the 5 tags\n",
    "        # KEEP\n",
    "        backpointers = []\n",
    "\n",
    "        # Initialize the viterbi variables in log space\n",
    "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
    "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "\n",
    "        # forward_var at step i holds the viterbi variables for step i-1\n",
    "        forward_var = init_vvars\n",
    "        for feat in feats:\n",
    "            bptrs_t = []  # holds the backpointers for this step\n",
    "            viterbivars_t = []  # holds the viterbi variables for this step\n",
    "\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
    "                # previous step, plus the score of transitioning\n",
    "                # from tag i to next_tag.\n",
    "                # We don't include the emission scores here because the max\n",
    "                # does not depend on them (we add them in below)\n",
    "                next_tag_var = forward_var + self.transitions[next_tag]\n",
    "                # best_tag_id = argmax(next_tag_var)\n",
    "                best_tag_id = torch.argmax(next_tag_var,axis=1)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "            # Now add in the emission scores, and assign forward_var to the set\n",
    "            # of viterbi variables we just computed\n",
    "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        # Transition to STOP_TAG\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        # best_tag_id = argmax(terminal_var)\n",
    "        best_tag_id = torch.argmax(terminal_var,axis=1)\n",
    "        path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "        # Follow the back pointers to decode the best path.\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        # Pop off the start tag (we dont want to return that to the caller)\n",
    "        start = best_path.pop()\n",
    "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def neg_log_likelihood(self, sentence, tags):\n",
    "        # KEEP\n",
    "        # Inputs: sent_in is list (noTokens); targets is torchArray (noTokens); Ouput: loss is single number\n",
    "        feats = self._get_lstm_features(sentence) # feats is (noTokens,noDiffLabelClasses)\n",
    "        forward_score = self._forward_alg(feats) # fwd score from model (accum. transmissions + emissions (i.e. feats))\n",
    "        gold_score = self._score_sentence(feats, tags) # gold score from self.transitions, feats (emissions), seq of tags in example sentence\n",
    "        return forward_score - gold_score\n",
    "\n",
    "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
    "        # KEEP\n",
    "        # Inp: sentence (1 example) as list of tokenIds; Out: score (1d), tag_seq (noTokens) with forecasted tagId for each token\n",
    "        # Get the emission scores from the BiLSTM\n",
    "        lstm_feats = self._get_lstm_features(sentence) # (noTokens,noDiffLabelClasses)\n",
    "       # print(lstm_feats)\n",
    "\n",
    "        # Find the best path, given the features.\n",
    "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
    "        print(tag_seq)\n",
    "        return score, tag_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41368699",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 4\n",
    "#tol = 1e-05\n",
    "#n_iter_no_change = 10\n",
    "#validation_fraction=0.1\n",
    "\n",
    "# Make up some training data\n",
    "training_data = [(\n",
    "    \"the wall street journal reported today that apple corporation made money\".split(),\n",
    "    \"B I I I O O O B I O O\".split()\n",
    "), (\n",
    "    \"georgia tech is a university in georgia\".split(),\n",
    "    \"B I O O O O B\".split()\n",
    ")]\n",
    "\n",
    "## 5 lines below create dict of (wordToken,wordId)\n",
    "word_to_ix = {}\n",
    "for sentence, tags in training_data:\n",
    "    for word in sentence:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix) # i.e. each successive word added gets a successive index\n",
    "\n",
    "tag_to_ix = {\"B\": 0, \"I\": 1, \"O\": 2, START_TAG: 3, STOP_TAG: 4}\n",
    "\n",
    "vocab = list(set([item for auxList,_ in training_data for item in auxList])) + [\"$UNK\"]\n",
    "\n",
    "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "#model = TorchLSTM_CRFSequenceLabeler(\n",
    "#    len(word_to_ix), \n",
    "#    tag_to_ix, \n",
    "#    EMBEDDING_DIM, \n",
    "#    HIDDEN_DIM,\n",
    "#    vocab,\n",
    "#    early_stopping=True,\n",
    "#    eta=0.001)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "#print(model.parameters().__next__())\n",
    "\n",
    "# Check predictions before training\n",
    "with torch.no_grad():\n",
    "    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    precheck_tags = torch.tensor([tag_to_ix[t] for t in training_data[0][1]], dtype=torch.long)\n",
    "    # print(model(precheck_sent))\n",
    "\n",
    "# Make sure prepare_sequence from earlier in the LSTM section is loaded\n",
    "for epoch in range(1):\n",
    "        #300):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for sentence, tags in training_data:\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is,\n",
    "        # turn them into Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix) # sentence_in is single example (i.e. sentence) with tensor of tokens converted to ids\n",
    "        targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long) # convert labels classes to ids\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        #print(\"sent_in length\"+str(len(sentence_in)))\n",
    "        #print(targets.shape)\n",
    "        #print(sentence_in)\n",
    "        loss = model.neg_log_likelihood(sentence_in, targets) # sent_in is list (noTokens); targets is torchArray (noTokens); # loss is single number\n",
    "        #print(\"loss length\"+str(len(loss))) \n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    #print(epoch)\n",
    "\n",
    "# Check predictions after training\n",
    "with torch.no_grad():\n",
    "    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    # print(model(precheck_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "588cbb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1])]\n",
      "(tensor([3.7316]), [tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1])])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    precheck_sent = prepare_sequence(training_data[1][0], word_to_ix) # convert o tokenIds\n",
    "   # print(precheck_sent)\n",
    "    print(model.forward(precheck_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "52b17543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "a=torch.randn(1)\n",
    "print(a.shape)\n",
    "b=a.view(1,-1).expand(1,5)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b01b442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['the', 'wall', 'street', 'journal', 'reported', 'today', 'that', 'apple', 'corporation', 'made', 'money'], ['B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'O']), (['georgia', 'tech', 'is', 'a', 'university', 'in', 'georgia'], ['B', 'I', 'O', 'O', 'O', 'O', 'B'])]\n",
      "2\n",
      "2\n",
      "['money', 'is', 'a', 'street', 'reported', 'apple', 'university', 'wall', 'tech', 'made', 'that', 'journal', 'the', 'today', 'georgia', 'in', 'corporation', '$UNK']\n"
     ]
    }
   ],
   "source": [
    "print(training_data)\n",
    "X_train = [[item for item in auxList] for auxList,_ in training_data]\n",
    "y_train = [[item for item in auxList] for _,auxList in training_data]\n",
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "097bb374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch_model_base' from 'C:\\\\Users\\\\vasco\\\\DeepLearning-JN\\\\cs224u\\\\base_data\\\\Vasco\\\\torch_model_base.py'>"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload vsm module\n",
    "import torch_rnn_classifier, torch_model_base\n",
    "import importlib\n",
    "importlib.reload(torch_rnn_classifier)\n",
    "importlib.reload(torch_model_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "21508c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_mod = TorchLSTM_CRFSequenceLabeler(\n",
    "    vocab,\n",
    "    early_stopping=True,\n",
    "    eta=0.001)\n",
    "\n",
    "    #len(word_to_ix), \n",
    "    #tag_to_ix, \n",
    "    #EMBEDDING_DIM, \n",
    "    #HIDDEN_DIM,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "e36ce725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'wall', 'street', 'journal', 'reported', 'today', 'that', 'apple', 'corporation', 'made', 'money']\n",
      "['B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "e946e6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7], device='cuda:0')\n",
      "torch.Size([1, 7])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\DeepLearning-JN\\cs224u\\base_data\\Vasco\\torch_model_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    358\u001b[0m                 \u001b[0mX_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m                 \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m                 \u001b[0mbatch_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\xcs224u\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33940/1594745463.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X, seq_lengths)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_lengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# is = 7 when shd be = 1 (batch_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_sent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m        \u001b[1;31m# for auxRow in range(0,len(X)):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m        \u001b[1;31m#     self.forward_sent(X[auxRow])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33940/1594745463.py\u001b[0m in \u001b[0;36mforward_sent\u001b[1;34m(self, sentence)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward_sent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# dont confuse this with _forward_alg above.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;31m# Get the emission scores from the BiLSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mlstm_feats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lstm_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# Find the best path, given the features.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33940/1594745463.py\u001b[0m in \u001b[0;36m_get_lstm_features\u001b[1;34m(self, sentence)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m#print(embeds) #OK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m#lstm_out, self.hidden = self.lstm(embeds, self.hidden)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[0mlstm_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mlstm_feats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden2tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\xcs224u\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\DeepLearning-JN\\cs224u\\base_data\\Vasco\\torch_rnn_classifier.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X, seq_lengths)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_embedding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[1;31m#print(type(X))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m             \u001b[1;31m#print(X.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\xcs224u\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\xcs224u\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m         return F.embedding(\n\u001b[0m\u001b[0;32m    146\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\xcs224u\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   1911\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1912\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1913\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "%time _ = seq_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "d2e1907e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 13, 25, 21, 26,  2, 11, 27, 28, 29, 30, 31,\n",
      "        32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 32, 44, 45, 37, 46, 47,\n",
      "        48, 49, 50, 51, 17, 21, 52, 53,  2, 54, 55, 56, 57, 21, 58, 59, 60, 27,\n",
      "        61, 62, 21, 21, 21])\n",
      "(tensor([545.6737]), [tensor([0]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([0]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([2]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([7]), tensor([7]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([9]), tensor([9]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([11]), tensor([10]), tensor([10]), tensor([11]), tensor([11]), tensor([11])])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    print(precheck_sent)\n",
    "    print(model.forward(precheck_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "400bfa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DORNBIRN', 'In', 'der', 'Schulgasse', 'in', 'Dornbirn', 'hat', 'eine', '71,93', 'Quadratmeter', 'große', 'Wohnung', 'für', 'einen', 'Quadratmeterpreis', 'von', '5533,71', 'Euro', 'den', 'Besitzer', 'gewechselt', '.', 'Dieser', 'beinhaltet', 'auch', 'einen', 'Pkw-Abstellplatz', '.', 'Käufer', 'der', 'Wohnung', 'mit', '9,86', 'Quadratmetern', 'Terrasse', 'ist', 'die', 'ValLiLean', 'Beteiligungs-', 'und', 'Immobilienverwaltungs', 'GmbH', 'Beim', 'Verkäufer', 'handelt', 'es', 'sich', 'um', 'die', 'Karrenblick', 'Projekt', 'GmbH', ' ', 'Der', 'Kaufpreis', 'liegt', 'bei', '398.040', 'Euro', '.', 'Unterzeichnet', 'wurde', 'der', 'Kaufvertrag', 'am', '18.', 'September', '.', 'Die', 'Verbücherung', 'datiert', 'mit', 'Oktober', '2020', '.', '.', '.']\n"
     ]
    }
   ],
   "source": [
    "print(training_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2b95b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 0, 'wall': 1, 'street': 2, 'journal': 3, 'reported': 4, 'today': 5, 'that': 6, 'apple': 7, 'corporation': 8, 'made': 9, 'money': 10, 'georgia': 11, 'tech': 12, 'is': 13, 'a': 14, 'university': 15, 'in': 16}\n"
     ]
    }
   ],
   "source": [
    "print(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "431172f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['the', 'wall', 'street', 'journal', 'reported', 'today', 'that', 'apple', 'corporation', 'made', 'money'], ['B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'O']), (['georgia', 'tech', 'is', 'a', 'university', 'in', 'georgia'], ['B', 'I', 'O', 'O', 'O', 'O', 'B'])]\n"
     ]
    }
   ],
   "source": [
    "print(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1377bd4f",
   "metadata": {},
   "source": [
    "Run with our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40450150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "816d93ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN \n",
    "### NOTE: Make sure to copy most up-to-date annotations2.jsonl file to /Vasco/\n",
    "with open('annotations2.jsonl') as jsonl_file:\n",
    "    # note: after running data-preprocessing.ipynb this file already has token-level labels\n",
    "    lines = jsonl_file.readlines()\n",
    "annot = [json.loads(line) for line in lines]\n",
    "#print(annot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "9515ab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN\n",
    "# now convert annotation tokens into list (sentences) of lists (tokens) format for sklearn_crfsuite.CRF\n",
    "train_sents=[] \n",
    "for j in range(0,len(annot)):\n",
    "    a = annot[j]['tokens']\n",
    "    # Only add sample if there are annotations\n",
    "    if annot[j]['spans']!=[]:\n",
    "        train_sentence = []\n",
    "        for i in range(0,len(a)):\n",
    "            if 'label' in a[i]: # only add element if this sample sentence has been labelled \n",
    "                token_element = (a[i]['text'],a[i]['label'])\n",
    "                train_sentence.append(token_element)\n",
    "        train_sents.append(train_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "ff2ff943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('DORNBIRN', 'ORT'), ('In', 'O'), ('der', 'O'), ('Schulgasse', 'STRASSE'), ('in', 'O'), ('Dornbirn', 'ORT'), ('hat', 'O'), ('eine', 'O'), ('71,93', 'FLAECHE'), ('Quadratmeter', 'O'), ('große', 'O'), ('Wohnung', 'IMMO_TYP'), ('für', 'O'), ('einen', 'O'), ('Quadratmeterpreis', 'O'), ('von', 'O'), ('5533,71', 'QMPREIS'), ('Euro', 'O'), ('den', 'O'), ('Besitzer', 'O'), ('gewechselt', 'O'), ('.', 'O'), ('Dieser', 'O'), ('beinhaltet', 'O'), ('auch', 'O'), ('einen', 'O'), ('Pkw-Abstellplatz', 'O'), ('.', 'O'), ('Käufer', 'O'), ('der', 'O'), ('Wohnung', 'O'), ('mit', 'O'), ('9,86', 'TERRASSENGROESSE'), ('Quadratmetern', 'O'), ('Terrasse', 'O'), ('ist', 'O'), ('die', 'O'), ('ValLiLean', 'KAEUFER'), ('Beteiligungs-', 'KAEUFER'), ('und', 'KAEUFER'), ('Immobilienverwaltungs', 'KAEUFER'), ('GmbH', 'KAEUFER'), ('Beim', 'O'), ('Verkäufer', 'O'), ('handelt', 'O'), ('es', 'O'), ('sich', 'O'), ('um', 'O'), ('die', 'O'), ('Karrenblick', 'VERKAEUFER'), ('Projekt', 'VERKAEUFER'), ('GmbH', 'VERKAEUFER'), (' ', 'O'), ('Der', 'O'), ('Kaufpreis', 'O'), ('liegt', 'O'), ('bei', 'O'), ('398.040', 'GESAMTPREIS'), ('Euro', 'O'), ('.', 'O'), ('Unterzeichnet', 'O'), ('wurde', 'O'), ('der', 'O'), ('Kaufvertrag', 'O'), ('am', 'O'), ('18.', 'DATUM_VERTRAG'), ('September', 'DATUM_VERTRAG'), ('.', 'O'), ('Die', 'O'), ('Verbücherung', 'O'), ('datiert', 'O'), ('mit', 'O'), ('Oktober', 'DATUM_VERBUECHERUNG'), ('2020', 'DATUM_VERBUECHERUNG'), ('.', 'O'), ('.', 'O'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(train_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "67f0a953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put into format expected above\n",
    "all_data = [([a1 for a1,a2 in el],[a2 for a1,a2 in el]) for el in train_sents]\n",
    "#tag_to_ix = {\"B\": 0, \"I\": 1, \"O\": 2, START_TAG: 3, STOP_TAG: 4}\n",
    "tag_to_ix = {'ORT': 0, 'STRASSE': 1, 'FLAECHE': 2, 'IMMO_TYP': 3, 'QMPREIS': 4, 'TERRASSENGROESSE': 5, 'KAEUFER': 6, 'VERKAEUFER': 7, 'GESAMTPREIS': 8, 'DATUM_VERTRAG': 9, 'DATUM_VERBUECHERUNG': 10, 'O': 11, START_TAG: 12, STOP_TAG: 13}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2451d1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "for i in range(0,len(train_sents)):\n",
    "    if len(train_sents[i])==0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "53f7c316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0726b112",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ix = {}\n",
    "for sentence, tags in all_data: # i.e. before splitting training / test data\n",
    "    for word in sentence:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix) # i.e. each successive word added gets a successive index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2d4c69fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training / test.\n",
    "training_data=all_data[:100]\n",
    "test_data=all_data[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "1907038b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nenzing', ':', '50', 'ha']\n",
      "tensor([882, 385, 883, 878])\n",
      "['ORT', 'O', 'O', 'O']\n",
      "(tensor([14.7289], grad_fn=<IndexBackward>), [tensor([0]), tensor([11]), tensor([11]), tensor([11])])\n"
     ]
    }
   ],
   "source": [
    "# generate predictions v2\n",
    "\n",
    "sentences = [a for a,_ in test_data]\n",
    "labels = [b for _,b in test_data]\n",
    "print(sentences[0])\n",
    "print(prepare_sequence(sentences[0], word_to_ix))\n",
    "#test_data_preds = model(prepare_sequence(sentences[0], word_to_ix))\n",
    "#print(test_data_preds)\n",
    "print(labels[0])\n",
    "test_data_preds = [model(prepare_sequence(a, word_to_ix)) for a in sentences]\n",
    "print(test_data_preds[0])\n",
    "test_data_gold = [[tag_to_ix[el] for el in a] for a in labels] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "4b26b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now unfold both gold and preds list of tensors - not necessary for sklearn classification_report\n",
    "#test_data_preds_unfold = [int(item) for sublist in test_data_preds for item in sublist[1]]\n",
    "#test_data_gold_unfold = [int(item) for sublist in test_data_gold for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "7e24e9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'ORT', 1: 'STRASSE', 2: 'FLAECHE', 3: 'IMMO_TYP', 4: 'QMPREIS', 5: 'TERRASSENGROESSE', 6: 'KAEUFER', 7: 'VERKAEUFER', 8: 'GESAMTPREIS', 9: 'DATUM_VERTRAG', 10: 'DATUM_VERBUECHERUNG', 11: 'O', 12: '<START>', 13: '<STOP>'}\n"
     ]
    }
   ],
   "source": [
    "ix_to_tag = {value: key for key, value in tag_to_ix.items()}\n",
    "print(ix_to_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "96d76fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data_preds_unfold_tag = [str(ix_to_tag[el]) for el in test_data_preds_unfold]\n",
    "#test_data_gold_unfold_tag = [str(ix_to_tag[el]) for el in test_data_gold_unfold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "d4271ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_distinct = list(tag_to_ix.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "50228c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'KAEUFER', 'DATUM_VERBUECHERUNG', 'DATUM_VERTRAG', 'VERKAEUFER', 'TERRASSENGROESSE', 'GESAMTPREIS', 'FLAECHE', 'IMMO_TYP', 'QMPREIS', 'ORT', '<START>', '<STOP>', 'STRASSE']\n"
     ]
    }
   ],
   "source": [
    "print(sorted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "ad4b60f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0]), tensor([11]), tensor([11]), tensor([11])]\n"
     ]
    }
   ],
   "source": [
    "print(list(test_data_preds[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a9bb4c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "2b4ff205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't unfold but convert ids to tags:\n",
    "test_data_preds_tag = [[str(ix_to_tag[int(item)]) for item in sublist[1]] for sublist in test_data_preds]\n",
    "test_data_gold_tag = [[str(ix_to_tag[int(item)]) for item in sublist] for sublist in test_data_gold ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "5c43466f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                ORT      0.730     0.540     0.621        50\n",
      "            STRASSE      0.000     0.000     0.000        19\n",
      "            FLAECHE      0.000     0.000     0.000        17\n",
      "           IMMO_TYP      0.000     0.000     0.000        22\n",
      "            QMPREIS      0.000     0.000     0.000        11\n",
      "   TERRASSENGROESSE      0.000     0.000     0.000         5\n",
      "            KAEUFER      0.000     0.000     0.000        22\n",
      "         VERKAEUFER      0.500     0.433     0.464        30\n",
      "        GESAMTPREIS      0.000     0.000     0.000        22\n",
      "      DATUM_VERTRAG      0.632     0.774     0.696        31\n",
      "DATUM_VERBUECHERUNG      0.913     0.724     0.808        29\n",
      "                  O      0.878     0.974     0.923      1107\n",
      "            <START>      0.000     0.000     0.000         0\n",
      "             <STOP>      0.000     0.000     0.000         0\n",
      "\n",
      "          micro avg      0.852     0.852     0.852      1365\n",
      "          macro avg      0.261     0.246     0.251      1365\n",
      "       weighted avg      0.783     0.852     0.815      1365\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasco\\anaconda3\\envs\\xcs224u\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\vasco\\anaconda3\\envs\\xcs224u\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "sorted_labels = sorted( # labels are coming in as id's not names\n",
    "    labels_distinct,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "\n",
    "print(metrics.flat_classification_report(\n",
    "    test_data_gold_tag, test_data_preds_tag, labels=labels_distinct, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "8279bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [el for auxList1,_ in all_data for el in auxList1]\n",
    "vocab = list(set(all_words)) + [\"$UNK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cdc232d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4675,  0.8189, -0.4107],\n",
      "        [ 0.3148, -0.9794,  0.1212]])\n",
      "tensor([-0.1895,  1.6988])\n",
      "tensor([-0.4675,  0.8189, -0.4107])\n",
      "tensor(-0.1895)\n",
      "tensor([ 0.3148, -0.9794,  0.1212])\n",
      "tensor(1.6988)\n"
     ]
    }
   ],
   "source": [
    "a= torch.randn(2,3)\n",
    "c=torch.randn(2)\n",
    "print(a)\n",
    "print(c)\n",
    "for b in range(0,len(a)):\n",
    "    print(a[b])\n",
    "    print(c[b])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "e7123e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_mod = TorchLSTM_CRFSequenceLabeler(\n",
    "    vocab,\n",
    "    early_stopping=True,\n",
    "    eta=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "611e2f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 19. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 2.246312379837036"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.44 s\n"
     ]
    }
   ],
   "source": [
    "%time _ = seq_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "340c58be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ORT', 'O', 'O', 'STRASSE', 'O', 'ORT', 'O', 'O', 'IMMO_TYP', 'O', 'O', 'IMMO_TYP', 'O', 'FLAECHE', 'O', 'O', 'GESAMTPREIS', 'O', 'O', 'O', 'O', 'O', 'IMMO_TYP', 'O', 'FLAECHE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'VERKAEUFER', 'O', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERTRAG', 'DATUM_VERTRAG', 'DATUM_VERTRAG', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERBUECHERUNG', 'DATUM_VERBUECHERUNG', 'O']\n",
      "['VERKAEUFER', 'VERKAEUFER', 'O', 'O', 'O', 'STRASSE', 'O', 'O', 'QMPREIS', 'O', 'QMPREIS', 'QMPREIS', 'STRASSE', 'STRASSE', 'STRASSE', 'STRASSE', 'DATUM_VERBUECHERUNG', 'O', 'QMPREIS', 'O', 'O', 'O', 'O', 'O', 'VERKAEUFER', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERBUECHERUNG', 'DATUM_VERBUECHERUNG', 'O', 'KAEUFER', 'O', 'QMPREIS', 'QMPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'STRASSE', 'O', 'DATUM_VERBUECHERUNG', 'DATUM_VERBUECHERUNG', 'O']\n"
     ]
    }
   ],
   "source": [
    "y_pred = seq_mod.predict(X_test)\n",
    "print(y_test[0])\n",
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "d7a1d692",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 5\n",
    "HIDDEN_DIM = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "b5aa6cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_mod = BiLSTM_CRF_2(\n",
    "    vocab,\n",
    "    tag_to_ix,\n",
    "    EMBEDDING_DIM,\n",
    "    HIDDEN_DIM,\n",
    "    early_stopping=True,\n",
    "    eta=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "ccfc24f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all, y_all = [[a for a,_ in el] for el in train_sents ], [[b for _,b in el] for el in train_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "8bb62912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VR ADDED March 30th\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "train_ratio = 0.75\n",
    "train_test_split = round(0.75*len(X_all) - 0.5) # -0.5 => floor\n",
    "idx = [i for i in range(0,len(X_all))]\n",
    "idx_shuffle = shuffle(idx,random_state=0)\n",
    "X_shuffle, y_shuffle = [X_all[auxIdx] for auxIdx in idx_shuffle], [y_all[auxIdx] for auxIdx in idx_shuffle]\n",
    "\n",
    "X_train, X_test, y_train, y_test = X_shuffle[:train_test_split], X_shuffle[train_test_split:], y_shuffle[:train_test_split], y_shuffle[train_test_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "486a5451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1107\n"
     ]
    }
   ],
   "source": [
    "#print(vocab['$UNK'])\n",
    "index = dict(zip(vocab, range(len(vocab))))\n",
    "print(index['$UNK'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "8a5f4137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ORT', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "1104d9bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_31180/1781751983.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "a=sorted(set(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "6c990aaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'embedding_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\DeepLearning-JN\\cs224u\\base_data\\Vasco\\torch_model_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;31m# Graph:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarm_start\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m             \u001b[1;31m# This device move has to happen before the optimizer is built:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[1;31m# https://pytorch.org/docs/master/optim.html#constructing-it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_31180/3378397507.py\u001b[0m in \u001b[0;36mbuild_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbuild_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         rnn = TorchRNNModel(\n\u001b[0m\u001b[0;32m    162\u001b[0m             \u001b[0mvocab_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m             \u001b[0membedding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\DeepLearning-JN\\cs224u\\base_data\\Vasco\\torch_rnn_classifier.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, vocab_size, embed_dim, embedding, use_embedding, rnn_cell_class, hidden_dim, bidirectional, freeze_embedding)\u001b[0m\n\u001b[0;32m    120\u001b[0m             self.embedding = self._define_embedding(\n\u001b[0;32m    121\u001b[0m                 embedding, vocab_size, self.embed_dim, self.freeze_embedding)\n\u001b[1;32m--> 122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m         self.rnn = rnn_cell_class(\n\u001b[0;32m    124\u001b[0m             \u001b[0minput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'embedding_dim'"
     ]
    }
   ],
   "source": [
    "%time _ = seq_mod.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
